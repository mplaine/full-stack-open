Notes
=====


Part 0: Fundamentals of Web apps
--------------------------------
* Always keep the Developer Console open on your web browser.
  - Disable cache
* Example application (traditional): https://studies.cs.helsinki.fi/exampleapp/
* List of HTTP status codes: https://en.wikipedia.org/wiki/List_of_HTTP_status_codes
 - 1xx informational response
 - 2xx success
 - 3xx redirection
 - 4xx client errors
 - 5xx server errors
* List of HTTP header fields: https://en.wikipedia.org/wiki/List_of_HTTP_header_fields
* UML - Sequence diagrams: https://www.geeksforgeeks.org/unified-modeling-language-uml-sequence-diagrams/
* The sequence diagram visualizes how the browser and server are communicating over the time. The time flows in the diagram from top to bottom, so the diagram starts with the first request that the browser sends to server, followed by the response.
* In traditional web applications, the browser is "dumb". It only fetches HTML data from the server, and all application logic is on the server. A server can be created using Java Spring , Python Flask or Ruby on Rails to name just a few examples.
* Debugging: Use console.log('Your message') to output on the console.
* XMLHttpRequest (XHR): https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest
  - Asynchronous requests (no full page refresh needed)
* Document Object Model (DOM): https://en.wikipedia.org/wiki/Document_Object_Model
  - Application Programming Interface (API) that enables programmatic modification of the element trees corresponding to web pages.
* Cascading Style Sheets (CSS): https://developer.mozilla.org/en-US/docs/Web/CSS
  - CSS rules
  - CSS selectors
* URL redicrection (HTTPS status code 302): https://en.wikipedia.org/wiki/URL_redirection
* AJAX: https://en.wikipedia.org/wiki/Ajax_(programming)
  - Enables the fetching of content to web pages using JavaScript included within the HTML, without the need to rerender the page.
* Single-page application (SPA): https://en.wikipedia.org/wiki/Single-page_application
  - SPA-style websites don't fetch all of their pages separately from the server like our sample application does, but instead comprise only one HTML page fetched from the server, the contents of which are manipulated with JavaScript that executes in the browser.
  - The SPA version of the app does not traditionally send the form data, but instead uses the JavaScript code it fetched from the server.
* Example application (SPA): https://studies.cs.helsinki.fi/exampleapp/spa
* The form's submit event handler immediately calls the method e.preventDefault() to prevent the default handling of form's submit.
* jQuery: https://jquery.com/
  - cross-browser compatibility, helper functions
* SPA frameworks:
  - BackboneJS: http://backbonejs.org/
  - AngularJS: https://angularjs.org/
  - React: https://react.dev/
  - VueJS: https://vuejs.org/
* Full-stack web development = covers all parts of the application, including the frontend, the backend, and the database.
* Node.js, JavaScript runtime environment: https://nodejs.org/en/
* JavaScript fatigue:
  - https://auth0.com/blog/how-to-manage-javascript-fatigue/
  - https://medium.com/@ericclemmons/javascript-fatigue-48d4011b6fc4
* HTML basics: https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/HTML_basics
* CSS basics: https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/CSS_basics
* Forms tutorial: https://developer.mozilla.org/en-US/docs/Learn/HTML/Forms/Your_first_HTML_form
* JavaScript basics: https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/JavaScript_basics
* Mermaid: Mermaid is a Markdown-inspired tool that renders text into diagrams.
  - https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-diagrams
  - https://github.com/mermaid-js/mermaid#sequence-diagram-docs---live-editor
  - components, messages, notes, ...


Part 1: Introduction to React
-----------------------------
* React: https://react.dev/
* Vite: https://vitejs.dev/
* Create a new React application:
  npm create vite@latest part1 -- --template react
* Run the application:
  npm run dev
* Main files: main.jsx, App.jsx (React component)
* Remove unnecessary files, such as App.css, index.css, and the assets directory
* JavaScript arrow functions (part of ES6): https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/Arrow_functions
  const App = () => { ... }
* React components:
  - Evaluated JavaScript parts use { .. }
  - Rendered return values use ( ... )
  - JavaScript at the top and output (HTML) at the bottom
  - Export the component: export default App
  - JSX (HTML inside JavaScript): https://react.dev/learn/writing-markup-with-jsx
  - Under the hood, JSX returned by React components is compiled into JavaScript using Babel (https://babeljs.io/repl/).
  - With JSX, you can easily embed dynamic content by writing appropriate JavaScript within curly braces.
  - Every JSX tag needs to be closed!
  - First letter of React component names must be capitalized.
  - The content of a React component (usually) needs to contain one root element (e.g., <div>...</div>, array [...], fragment <>...</>).
  - Do not render objects as they are not valid as a React child!!
  - Rendering arrays with primitive values is ok
* A core philosophy of React is composing applications from many specialized reusable components.
* Fragment (empty element): https://react.dev/reference/react/Fragment
* Props enable to pass data to compoennts
  - https://react.dev/learn/passing-props-to-a-component
  - <Hello name='George' />
    const Hello = (props) => {
      return (
        <div>
          <p>Hello {props.name}</p>
        </div>
      )
    }
* ESLint tool: https://eslint.org/
  - To validate your ECMAScript (JavaScript) code
  - Configuration: .eslintrc.cjs
* ECMAScript: https://en.wikipedia.org/wiki/ECMAScript
  - As of June 2023, the latest version is ECMAScript 2023 (ES14): https://www.ecma-international.org/ecma-262/
* Browsers do not yet support all of JavaScript's newest features. Due to this fact, a lot of code run in browsers has been transpiled from a newer version of JavaScript to an older, more compatible version.
  - Babel is the most popular tool: https://babeljs.io/
* Node.js (https://nodejs.org/en/) is a JavaScript runtime environment based on Google's Chrome V8 JavaScript engine and works practically anywhere - from servers to mobile phones.
  - The latest versions of Node already understand the latest versions of JavaScript, so the code does not need to be transpiled.
* Variables:
  - const in ES6 (https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/const) does not define a variable but a constant for which the value can no longer be changed.
  - let in ES6 (https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/let) defines a normal variable.
  - var (https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/var) was, for a long time, the only way to define variables. Avoid it in modern apps.
  - https://medium.com/craft-academy/javascript-variables-should-you-use-let-var-or-const-394f7645c88f
  - http://www.jstips.co/en/javascript/keyword-var-vs-let/
  - https://youtu.be/sjyJBL5fkp8
* Arrays:
  - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array
  - length, push, ...
  - Contents can be modified even though it is defined as a const!
  - myArray.forEach(value => { ... }). https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/forEach
  - Use concat in React code to keep the original array unchanged: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/concat
  - map method creates a new array: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/map
    - const m2 = t.map(value => '<li>' + value + '</li>')
* Immutable (unmodifiable) data structures: https://en.wikipedia.org/wiki/Immutable_object
* React often uses techniques from functional programming.
* Destructuring assignment: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment
  - const [first, second, ...rest] = t
* Objects:
  - Object literals: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Grammar_and_types#Object_literals
    const object1 = {
      name: 'Arto Hellas',
      age: 35,
      education: 'PhD',
    }
  - The values of the properties can be of any type, like integers, strings, arrays, objects...
  - The properties of an object are referenced by using the "dot" notation, or by using brackets.
  - Add properties on the fly: object1['secret number'] = 12341
  - Objects can also be defined using so-called constructor functions, which results in a mechanism reminiscent of many other programming languages, e.g. Java's classes.
* Functions:
  - Arrow functions (ES6): const sum = (p1, p2) => { ... return something }
  - If there is just a single parameter, we can exclude the parentheses from the definition.
  - If the function only contains a single expression then the braces are not needed. const square = p => p * p
  - Before arrow functions, the only way to define functions was by using the keyword function.
  - There are two ways to reference the function:
    - One is giving a name in a function declaration.
      - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/function
      - function product(a, b) { ... }
    - The other way to define the function is by using a function expression.
      - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/function
      - const average = function(a, b) { ... }
* Object methods and "this"
  - The keyword this: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/this
  - Methods can be assigned to objects even after the creation of the object:
    user.growOlder = function() {
      this.age += 1
    }
  - setTimeout function: https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/setTimeout
  - Contrary to other languages, in JavaScript the value of this is defined based on how the method is called. When calling the method through a reference, the value of this becomes the so-called global object and the end result is often not what the software developer had originally intended.
  - The value of this in JavaScript is defined based on how the method is being called.
    const arto = {
      name: 'Arto Hellas',
      greet: function() {
        console.log('hello, my name is ' + this.name)
      },
    }
    setTimeout(arto.greet, 1000)
  - There are several mechanisms by which the original this can be preserved. One of these is using a method called bind:
    - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/bind
    - Calling arto.greet.bind(arto) creates a new function where this is bound to point to Arto, independent of where and how the method is being called.
      setTimeout(arto.greet.bind(arto), 1000)
  - Global object: https://developer.mozilla.org/en-US/docs/Glossary/Global_object
  - Avoid these issues by using "this-less" JavaScript.
  - Understand JavaScript's this keyword in depth: https://egghead.io/courses/understand-javascript-s-this-keyword-in-depth
* Classes:
  - There is no class mechanism in JavaScript like the ones in object-oriented programming languages.
  - Simulate classes (ES6): https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes
    class Person {
      constructor(name, age) {
        this.name = name
        this.age = age
      }
      greet() {
        console.log('hello, my name is ' + this.name)
      }
    }
    const adam = new Person('Adam Ondra', 29)
    adam.greet()
  - JavaScript prototypal inheritance: https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Objects/Inheritance
  - JavaScript data structures: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures
  - Classes divide opinions: https://github.com/petsel/not-awesome-es6-classes and https://medium.com/@rajaraodv/is-class-in-es6-the-new-bad-part-6c4e6fe1ee65
  - The ES6 class syntax is used a lot in "old" React and also in Node.js, hence an understanding of it is beneficial even in this course.
  - Use React Hooks to avoid the use of classes: https://react.dev/reference/react
* JavaScript material:
  - Mozilla JavaScript Guide: https://developer.mozilla.org/en-US/docs/Web/JavaScript
  - Re-introduction to JavaScript: https://developer.mozilla.org/en-US/docs/Web/JavaScript/A_re-introduction_to_JavaScript
  - JavaScript in-depth: https://github.com/getify/You-Dont-Know-JS
  - javascript.info: https://javascript.info/
  - Eloquent JavaScript book: https://eloquentjavascript.net/
  - Namaste JavaScript: https://www.youtube.com/playlist?list=PLlasXeu85E9cQ32gLCvAvr9vNaUccPVNP
  - Egghead.io: https://egghead.io/
* Use helper arrow functions within components. It is common to use nested (arrow) functions in JavaScript.
* Destructure values from objects and arrays upon assignment: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment
  const Hello = (props) => { const { name, age } = props ... } -- OR -- const Hello = ({ name, age }) => { ... }
* Page re-rendering using setInterval (bad approach): https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/setInterval
  setInterval(() => {
    refresh()
    counter += 1
  }, 1000)
* Stateful components with the React state hook: https://react.dev/learn/state-a-components-memory
  import { useState } from 'react'
  const App = () => {
    const [ counter, setCounter ] = useState(0)
    setTimeout(
      () => setCounter(counter + 1),
      1000
    )
    return (
      <div>{counter}</div>
    )
  }
  export default App
* The counter variable is assigned the initial value of state which is zero. The variable setCounter is assigned a function that will be used to modify the state.
* When the state modifying function setCounter is called, React re-renders the component which means that the function body of the component function gets re-executed.
* Every time the setCounter modifies the state it causes the component to re-render.
* Mouse events: https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent
* Register an event handler function with React: https://react.dev/learn/responding-to-events
  const handleClick = () => {
    console.log('clicked')
  }
  ...
  <button onClick={handleClick}>plus</button>
* The event handler function can also be defined directly in the value assignment of the onClick-attribute:
  <button onClick={() => setCounter(counter + 1)}>plus</button>
* An event handler is supposed to be either a function or a function reference, not a function call.
* Usually defining event handlers within JSX-templates (mixed JS+HTML code) is not a good idea. Here it's ok, because our event handlers are so simple.
* It's recommended to write React components that are small and reusable across the application and even across projects.
* Lift state up: https://react.dev/learn/sharing-state-between-components
* In React, it’s conventional to use onSomething names for props which take functions which handle events and handleSomething for the actual function definitions which handle those events.
  - https://react.dev/learn/tutorial-tic-tac-toe
* Calling a function that changes the state causes the component to rerender!!
* So, if a user clicks the plus button, the button's event handler changes the value of counter to 1, and the App component is rerendered. This causes its subcomponents Display and Button to also be re-rendered.
* We can define the function using the more compact form of arrow functions if the function defining the component contains only the return statement:
  const Display = ({ counter }) => <div>{counter}</div>
* Naming event handler props: https://react.dev/learn/responding-to-events#naming-event-handler-props
* By convention, event handler props should start with on, followed by a capital letter. For example, the Button component’s onClick prop could have been called onSmash.
* Simplified button component:
  const Button = ({ onSmash, text }) => <button onClick={onSmash}>{text}</button>
* However, be careful to not oversimplify your components, as this makes adding complexity a more tedious task down the road.
* Objects can be used for more complex state management:
  const [clicks, setClicks] = useState({
    left: 0, right: 0
  })
* Object spread syntax (2018): https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Spread_syntax
  const newClicks = { 
    ...clicks, 
    left: clicks.left + 1 
  }
* It is forbidden in React to mutate state directly, since it can result in unexpected side effects: https://stackoverflow.com/a/40309023
  const handleLeftClick = () => {
    clicks.left++  // FORBIDDEN!!!
    setClicks(clicks)
  }
* Changing state has to always be done by setting the state to a new object. If properties from the previous state object are not changed, they need to simply be copied, which is done by copying those properties into a new object and setting that as the new state.
* See when to store a React application state in a more complex data structure: https://react.dev/learn/choosing-the-state-structure
* Initializing a state with an array and modifying it with concat:
  const [allClicks, setAll] = useState([])
  const handleLeftClick = () => {
    setAll(allClicks.concat('L'))
    setLeft(left + 1)
  }
* The concat method, which does not mutate the existing array but rather returns a new copy of the array with the item added to it.
  - Don't use push with arrays!
* A state update in React happens asynchronously, i.e. not immediately but "at some point" before the component is rendered again.
  - The following does NOT work:
    const handleLeftClick = () => {
      setAll(allClicks.concat('L'))
      setLeft(left + 1)
      setTotal(left + right)  // FAILS!!!
    }
  - Fixed code:
    const handleLeftClick = () => {
      setAll(allClicks.concat('L'))
      const updatedLeft = left + 1  // FIX!!!
      setLeft(updatedLeft)
      setTotal(updatedLeft + right) // FIX!!!
    }
* Conditional React rendering: https://react.dev/learn/conditional-rendering
  const History = (props) => {
    if (props.allClicks.length === 0) {
      return (
        <div>...</div>
      )
    }
    return (
      <div>...</div>
    )
  }
* State book (React 16.8.0+): https://react.dev/learn/state-a-components-memory
  - Class components were used before that: https://react.dev/reference/react/Component
* Install React Developer Tools extension to Chrome for easier debugging: https://react.dev/learn/react-developer-tools
* Separate things using comma (not plus) to debug objects:
  console.log('props value is', props)
* Debugging to the console is only one way to debug React applications.
* You can pause the execution of your application code in the Chrome developer console's debugger, by writing the command debugger anywhere in your code.
  https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/debugger
* The useState function (as well as the useEffect function introduced later on in the course) must not be called from inside of a loop, a conditional expression, or any place that is not a function defining a component. This must be done to ensure that the hooks are always called in the same order, and if this isn't the case the application will behave erratically.
* Event handlers must always be a function or a reference to a function. The button will not work if the event handler is set to a variable of any other type.
* When the component (<button onClick={setValue(0)}>button</button>) is rendered the function setValue(0) gets executed which in turn causes the component to be re-rendered. Re-rendering in turn calls setValue(0) again, resulting in an infinite recursion.
* Defining event handlers directly in the attribute of the button is not necessarily the best possible idea.
* Another way to define an event handler is to use a function that returns a function. Very confusing and not advised to be used.
  const hello = () => {
    const handler = () => console.log('hello world')
    return handler
  }
  ...
  <button onClick={hello()}>button</button>
* Do Not Define Components Within Components!!!
  - The biggest problems are because React treats a component defined inside of another component as a new component in every render. This makes it impossible for React to optimize the component.
* Multiple components can be defined, but is not recommended, in one file. For example, App and Button in App.jsx
* The official React documentation: https://react.dev/learn
* Start learning React: https://egghead.io/courses/start-learning-react
* Beginner's guide to React: https://egghead.io/courses/the-beginner-s-guide-to-reactjs
* Web programmers oath:
  - I will have my browser developer console open all the time
  - I progress with small steps
  - I will write lots of console.log statements to make sure I understand how the code behaves and to help pinpointing problems
  - If my code does not work, I will not write more code. Instead I start deleting the code until it works or just return to a state when everything was still working
* You can create a copy of an array like this:
  const points = [1, 4, 6, 3]
  const copy = [...points]
  copy[2] += 1 // increment the value in position 2 by one
* You can create a copy of an object like this:
  const points = { 0: 1, 1: 3, 2: 4, 3: 2 }
  const copy = { ...points }
  copy[2] += 1 // increment the property 2 value by one
* Create a zero-filled array: Array(anecdotes.length).fill(0)
* setMostVotesIndex(updatedVotes.indexOf(Math.max(...updatedVotes)))
* const randomInt = Math.floor(Math.random() * anecdotes.length)
* Objects and functions can be passed as props to a component.
  <Total parts={course.parts} />
* Conditional rendering: (text === 'positive') ? ' %' : ''


Part 2: Communicating with server
---------------------------------
* Debugging React applications: https://fullstackopen.com/en/part1/a_more_complex_state_debugging_react_apps#debugging-react-applications
* Visual Studio Code snippets: https://code.visualstudio.com/docs/editor/userdefinedsnippets#_creating-your-own-snippets
  - Useful snippets: https://marketplace.visualstudio.com/items?itemName=dsznajder.es7-react-js-snippets
  - Example:
    {
      "console.log": {
        "prefix": "clog",
        "body": [
          "console.log('$1')",
        ],
        "description": "Log output to console"
      }
    }
  - Usage: type log and hit Tab to autocomplete.
* The functional programming operators of the JavaScript array, such as find, filter, and map.
* Functional programming in JavaScript: https://www.youtube.com/playlist?list=PL0zVEGEvSaeEd9hlmCXrk5yUyqUag-n84
  - Higher-order functions: https://www.youtube.com/watch?v=BMUiFMZr7vk&list=PL0zVEGEvSaeEd9hlmCXrk5yUyqUag-n84
  - Map: https://www.youtube.com/watch?v=bCqtb-Z5YGQ&list=PL0zVEGEvSaeEd9hlmCXrk5yUyqUag-n84&index=2
  - Reduce basics: https://www.youtube.com/watch?v=Wl98eZpkp-c&t=31s
* Generate React elements from the array of objects using the map function:
  notes.map(note => <li>{note.content}</li>)
* The code generating JavaScript must be wrapped in curly braces in a JSX template.
* The list items, i.e. the elements generated by the map method, must each have a unique key value: an attribute called key.
  <ul>
    {notes.map(note => 
      <li key={note.id}>  // add the key attribute with a unique value!!!
        {note.content}
      </li>
    )}
  </ul>
* More on the usage of key attributes: https://react.dev/learn/preserving-and-resetting-state#option-2-resetting-state-with-a-key
* The map function: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/map
* Map always creates a new array, the elements of which have been created from the elements of the original array by mapping: using the function given as a parameter to the map method.
  - Example: const result = notes.map(note => note.id)
  - Concise form: note => note.id
  - Full form: (note) => { return note.id }
* Anti-pattern: Array Indexes as Keys (not recommended!!!): https://robinpokorny.medium.com/index-as-a-key-is-an-anti-pattern-e0349aece318
  - The indexes can be retrieved by passing a second parameter to the callback function of the map method:
    <ul>
      {notes.map((note, i) => 
        <li key={i}>
          {note.content}
        </li>
      )}
    </ul>
* Destructuring assignment: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment
* Common practice is to declare each component in its own file as an ES6-module.
* Import in JavaScript: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/import
  import ReactDOM from "react-dom/client"
  import Note from './components/Note'
* When importing our own components, their location must be given in relation to the importing file.
* In smaller applications, components are usually placed in a directory called components, which is in turn placed within the src directory. The convention is to name the file after the component. For example, Note.jsx
* Export in JavaScript: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/export
  export default Note
* Install application dependencies:
  npm install
* Start the application:
  npm run start
* More on debugging: Quite often the root of the problem is that the props are expected to be of a different type, or called with a different name than they actually are, and destructuring fails as a result. The problem often begins to solve itself when destructuring is removed and we see what the props contain.
* Note that if you copy a project from one place to another, you might have to delete the node_modules directory and install the dependencies again with the command npm install before you can start the application.
* Generally, it's not recommended that you copy a project's whole contents and/or add the node_modules directory to the version control system.
* The reduce method: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/Reduce
* HTML forms: https://developer.mozilla.org/en-US/docs/Learn/HTML/Forms
  <form onSubmit={addNote}>
    <input />
    <button type="submit">save</button>
  </form> 
* OnSomething event handlers include the event parameter, which is the event that triggers the call to the event handler function.
  const addNote = (event) => {
    event.preventDefault()
    console.log('button clicked', event.target)
  }
* The event handler immediately calls the event.preventDefault() method, which prevents the default action of submitting a form. The default action would, among other things, cause the page to reload.
  - https://developer.mozilla.org/en-US/docs/Web/API/HTMLFormElement/submit_event
* The target of the event stored in event.target.
* Controlling an input with a state variable a.k.a. controlled components: https://react.dev/reference/react-dom/components/input#controlling-an-input-with-a-state-variable
  const [newNote, setNewNote] = useState('placeholder text')
  <input value={newNote} onChange={handleNoteChange} />
* The event handler is called every time a change occurs in the input element.
  const handleNoteChange = (event) => {
    console.log(event.target.value)
    setNewNote(event.target.value)
  }
* Note that we did not need to call the event.preventDefault() method like we did in the onSubmit event handler. This is because no default action occurs on an input change, unlike a form submission.
* Never mutate state directly in React! https://react.dev/learn/updating-objects-in-state#why-is-mutating-state-not-recommended-in-react
* Filtering displayed elements:
  const notesToShow = showAll ? notes : notes.filter(note => note.important === true)
* Conditional operator: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Conditional_Operator
  const result = condition ? val1 : val2
* The filter method: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/filter
  notes.filter(note => note.important)
* When performing comparisons, it's therefore safer to exclusively use val1 === val2.
  https://developer.mozilla.org/en-US/docs/Web/JavaScript/Equality_comparisons_and_sameness
* Toggling a value: The event handler switches the value of showAll from true to false and vice versa:
  () => setShowAll(!showAll)
* Debugging the value of a component temporarily: <div>debug: {newName}</div>
* JavaScript arrays have numerous suitable methods for preventing the user from being able to add a value that already exist in the array.
  - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array
* How to check object equality: https://www.joshbritz.co/posts/why-its-so-hard-to-check-object-equality/
* Alert command: https://developer.mozilla.org/en-US/docs/Web/API/Window/alert
* When you are forming strings that contain values from variables, it is recommended to use a template string (ES6) (https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals):
  `${newName} is already added to phonebook`
* When you are working on new functionality, it's often useful to "hardcode" some dummy data into your application.
* JSON Server to act as a server: https://github.com/typicode/json-server
* Install JSON server globally:
  npm install -g json-server
* Run JSON server (uses port 3000 by default):
  json-server --port 3001 --watch db.json
* Run JSON server without global installation:
  npx json-server --port 3001 --watch db.json
* Format JSON data in the browser: https://chrome.google.com/webstore/detail/jsonview/chklaanhfefbnpoihckbnefhakgolnmc
* Whenever a new note is added to the application, the React code also sends it to the JSON server to make the new note persist in "memory".
* json-server is a handy tool that enables the use of server-side functionality in the development phase without the need to program any of it.
* XMLHttpRequest, HTTP request made using an XHR object: https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest
* The use of XHR is no longer recommended, and browsers already widely support the fetch method, which is based on so-called promises, instead of the event-driven model used by XHR.
* The fetch method: https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/fetch
* Promises: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise
* In XHR, it is worth noting that the code in the event handler is defined before the request is sent to the server. Despite this, the code within the event handler will be executed at a later point in time.
* JavaScript engines, or runtime environments follow the asynchronous model: https://developer.mozilla.org/en-US/docs/Web/JavaScript/EventLoop
  - This requires all IO operations (with some exceptions) to be executed as non-blocking. This means that code execution continues immediately after calling an IO function, without waiting for it to return.
    - https://en.wikipedia.org/wiki/Input/output
* When an asynchronous operation is completed, or, more specifically, at some point after its completion, the JavaScript engine calls the event handlers registered to the operation.
* Currently, JavaScript engines are single-threaded, which means that they cannot execute code in parallel. As a result, it is a requirement in practice to use a non-blocking model for executing IO operations. Otherwise, the browser would "freeze" during, for instance, the fetching of data from a server.
* Another consequence of this single-threaded nature of JavaScript engines is that if some code execution takes up a lot of time, the browser will get stuck for the duration of the execution.
* What the heck is the event loop anyway? https://www.youtube.com/watch?v=8aGhZQkoFbQ
* Web workers allow to run parallelized code: https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers
* The event loop of an individual browser window is, however, still only handled by a single thread: https://medium.com/techtrument/multithreading-javascript-46156179cf9a
* The Axios library for communication between the browser and server: https://github.com/axios/axios
  - It functions like fetch but is somewhat more pleasant to use.
* Nowadays, practically all JavaScript projects are defined using the node package manager, aka npm.
  - https://docs.npmjs.com/getting-started/what-is-npm
* A clear indicator that a project uses npm is the package.json file located at the root of the project
* package.json:
  - scripts: commands to be executed by developers
  - dependencies: app dependencies
  - devDependencies: development dependencies
* Install Axios:
  npm install axios
* npm-commands should always be run in the project root directory, which is where the package.json file can be found.
* Install JSON server as a development dependency using --save-dev:
  npm install json-server --save-dev
  - package.json > scripts:
    "server": "json-server -p3001 --watch db.json"
* Run the JSON server:
  npm run server
* To run json-server and your react app simultaneously, you may need to use two terminal windows. One to keep json-server running and the other to run our React application.
* Axios example that return a promise:
  import axios from 'axios'
  const promise = axios.get('http://localhost:3001/notes')
  console.log(promise)
  const promise2 = axios.get('http://localhost:3001/foobar')
  console.log(promise2)
* Axios' method get returns a promise: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Using_promises
* A Promise is an object representing the eventual completion or failure of an asynchronous operation.
* In other words, a promise is an object that represents an asynchronous operation. A promise can have three distinct states:
  - The promise is pending: It means that the final value (one of the following two) is not available yet.
  - The promise is fulfilled: It means that the operation has been completed and the final value is available, which generally is a successful operation. This state is sometimes also called resolved.
  - The promise is rejected: It means that an error prevented the final value from being determined, which generally represents a failed operation.
* If, and when, we want to access the result of the operation represented by the promise, we must register an event handler to the promise. This is achieved using the method then:
  promise.then(response => {
    console.log(response)
  })
* The response object contains all the essential data related to the response of an HTTP GET request, which would include the returned data, status code, and headers.
* Storing the promise object in a variable is generally unnecessary, and it's instead common to chain the then method call to the axios method call, so that it follows it directly:
  axios
    .get('http://localhost:3001/notes')
    .then(response => {
      const notes = response.data
      console.log(notes)
    })
* The data returned by the server is plain text, basically just one long string. The axios library is still able to parse the data into a JavaScript array, since the server has specified that the data format is application/json; charset=utf-8 (see the previous image) using the content-type header.
* The React Effect hooks: https://react.dev/reference/react#effect-hooks
* The Effect Hook lets you perform side effects on function components. Data fetching, setting up a subscription, and manually changing the DOM in React components are all examples of side effects.
  useEffect(() => {
    console.log('effect')
    axios
      .get('http://localhost:3001/notes')
      .then(response => {
        console.log('promise fulfilled')
        setNotes(response.data)
      })
  }, [])
* As always, a call to a state-updating function triggers the re-rendering of the component.
* Alternative implementation of the Effect hook:
  const hook = () => {
    console.log('effect')
    axios
      .get('http://localhost:3001/notes')
      .then(response => {
        console.log('promise fulfilled')
        setNotes(response.data)
      })
  }
  useEffect(hook, [])
* Now we can see more clearly that the function useEffect takes two parameters. The first is a function, the effect itself.
* By default, effects run after every completed render, but you can choose to fire it only when certain values have changed.
* The second parameter of useEffect is used to specify how often the effect is run. If the second parameter is an empty array [], then the effect is only run along with the first render of the component.
* Run the React frontend application in development mode:
  npm run dev
* The json-server package claims to be a so-called REST or RESTful API in its documentation.
* REST API conventions: https://en.wikipedia.org/wiki/Representational_state_transfer#Applied_to_web_services
* JSON server routes: https://github.com/typicode/json-server#routes
* In REST terminology, we refer to individual data objects, such as the notes in our application, as resources. Every resource has a unique address associated with it - its URL. According to a general convention used by json-server, we would be able to locate an individual note at the resource URL notes/3, where 3 is the id of the resource. The notes URL, on the other hand, would point to a resource collection containing all the notes.
* Get all notes: GET /notes/ -> array of note objects (200)
* Get a specific note: GET /notes/3 -> note object (200)
* Create a new note: POST /notes/ + new note object data -> created note object (201)
* Update an existing note: PUT /notes/3 + updated note object data -> updated note object (200)
* Delete an existing note: DELETE /notes/3 -> - (204)
* Not found: 404
* The data for the new note resource is sent in the body of the request.
* json-server requires all data to be sent in JSON format. What this means in practice is that the data must be a correctly formatted string and that the request must contain the Content-Type request header with the value application/json.
* An important detail to remember is that the concat method does not change the component's original state, but instead creates a new copy of the list.
* Postman, an HTTP client, helps us to debug our server applications: https://www.postman.com
* Find a note: const note = notes.find(n => n.id === id)
* Updated note: const changedNote = { ...note, important: !note.important }
* The array find method: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/find
* The object spread syntax: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Spread_syntax
* Never mutate state directly in React.
* Shallow copy, meaning that the values of the new object are the same as the values of the old object.
  https://en.wikipedia.org/wiki/Object_copying#Shallow_copy
* Update a note:
  axios.put(url, changedNote).then(response => {
    setNotes(notes.map(note => note.id !== id ? note : response.data))
  })
* Single responsibility principle: https://en.wikipedia.org/wiki/Single_responsibility_principle
* Files in the services module handle client-server communication.
  const update = (id, newObject) => {
    const request = axios.put(`${baseUrl}/${id}`, newObject)
    return request.then(response => response.data)
  }
  ... Components using the service:
  import noteService from './services/notes' // pay attention to the fact that the file suffix (.js) is dropped
  noteService
    .getAll()
    .then(notes => {
      setNotes(notes)
    })
* The modified getAll function still returns a promise, as the then method of a promise also returns a promise:
  - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/then
* Promise chaining: https://javascript.info/promise-chaining
* Async and performance book: https://github.com/getify/You-Dont-Know-JS/tree/1st-ed and https://github.com/getify/You-Dont-Know-JS/blob/1st-ed/async%20%26%20performance/ch3.md
* Exporting code from modules:
  export default { 
    getAll: getAll, 
    create: create, 
    update: update 
  }
* Since the names of the keys and the assigned variables are the same, we can write the object definition with a more compact syntax:
  export default { getAll, create, update }
* Compact way to define objects using variables: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Object_initializer#Property_definitions
  - original:
    const person = {
      name: name,
      age: age
    }
  - Compact:
    const person = { name, age }
* When an HTTP request fails, the associated promise is rejected.
* The more common way of adding a handler for rejected promises is to use the catch method: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/catch
  axios
    .get('http://example.com/probably_will_fail')
    .then(response => {
      console.log('success!')
    })
    .catch(error => {
      console.log('fail')
    })
* Promise chaining: https://javascript.info/promise-chaining
* The catch method can be used to define a handler function at the end of a promise chain, which is called once any promise in the chain throws an error and the promise becomes rejected.
* The confirm method: https://developer.mozilla.org/en-US/docs/Web/API/Window/confirm
* Full stack developer's oath:
  - I will have my browser developer console open all the time
  - I will use the network tab of the browser dev tools to ensure that frontend and backend are communicating as I expect
  - I will constantly keep an eye on the state of the server to make sure that the data sent there by the frontend is saved there as I expect
  - I will progress with small steps
  - I will write lots of console.log statements to make sure I understand how the code behaves and to help pinpoint problems
  - If my code does not work, I will not write more code. Instead, I start deleting the code until it works or just return to a state when everything was still working
* CSS processor: https://developer.mozilla.org/en-US/docs/Glossary/CSS_preprocessor
* CSS rules comprise of selectors and declarations. Add index.css under the src/ directory with the content below.
  h1 {
    color: green;
  }
* The selector defines which elements the rule should be applied to. The selector above is h1, which will match all of the h1 header tags in our application.
* Different types of selectors: https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors
  - Class selectors: https://developer.mozilla.org/en-US/docs/Web/CSS/Class_selectors
* The declaration sets the color property to the value green. One CSS rule can contain an arbitrary number of properties. 
* Import the CSS file to main.jsx:
  import './index.css'
* In React we have to use the className attribute instead of the class attribute: https://react.dev/learn#adding-styles
* If the value of the message prop is null, then nothing is rendered to the screen, and in other cases, the message gets rendered inside of a div element.
  const Notification = ({ message }) => {
    if (message === null) {
      return null
    }

    return (
      <div className='error'>
        {message}
      </div>
    )
  }
* Handling errors:
  .catch(error => {
    setErrorMessage(
      `Note '${note.content}' was already removed from server`
    )
    setTimeout(() => {
      setErrorMessage(null)
    }, 5000)
    setNotes(notes.filter(n => n.id !== id))
  })
* React also makes it possible to write styles directly in the code as so-called inline styles: https://react-cn.github.io/react/tips/inline-styles.html
  - https://react.dev/reference/react-dom/components/common#applying-css-styles
  - Example of React inline styles:
    const footerStyle = {
      color: 'green',
      fontStyle: 'italic',
      fontSize: 16
    }
    ...
    <div style={footerStyle}>
* Every CSS property is defined as a separate property of the JavaScript object. Numeric values for pixels can be simply defined as integers. One of the major differences compared to regular CSS, is that hyphenated (kebab case) CSS properties are written in camelCase.
* Inline styles come with certain limitations. For instance, so-called pseudo-classes can't be used straightforwardly.
  - https://developer.mozilla.org/en-US/docs/Web/CSS/Pseudo-classes
* The philosophy of React is, in fact, the polar opposite of the old-school goal of writing CSS, HTML, and JavaScript into their separate files. Since the separation of CSS, HTML, and JavaScript into separate files did not seem to scale well in larger applications, React bases the division of the application along the lines of its logical functional entities.
* The structural units that make up the application's functional entities are React components. A React component defines the HTML for structuring the content, the JavaScript functions for determining functionality, and also the component's styling; all in one place. This is to create individual components that are as independent and reusable as possible.
* If the state would be only saving "one thing", a more proper initial value would be null denoting that there is nothing in the state at the start.
  const [currency, setCurrency] = useState(null)
* // do not render anything if notes is still null
  if (!notes) { 
    return null 
  }
* The second parameter of useEffect is used to specify how often the effect is run: https://react.dev/reference/react/useEffect#parameters
* If the second parameter is an empty array [], it's content never changes and the effect is only run after the first render of the component.
* However, there are situations where we want to perform the effect at other times, e.g. when the state of the component changes in a particular way.
* Exchange rate API: https://www.exchangerate-api.com/
  useEffect(() => { ... }, [currency])
* Prevent requesting the exchange rates just after the first render when the variable currency still has the initial value, i.e. a null value.
  if (currency) { 
    // exchange rates are fetched
  }
* REST countries: https://studies.cs.helsinki.fi/restcountries/
* Open weather map API: https://openweathermap.org/
* You need an api-key to use almost every weather service. Do not save the api-key to source control! Nor hardcode the api-key to your source code. Instead use an environment variable to save the key.
  - https://vitejs.dev/guide/env-and-mode.html
* Assuming the api-key is 54l41n3n4v41m34rv0, when the application is started like so:
  export VITE_SOME_KEY=54l41n3n4v41m34rv0 && npm run dev // For Linux/macOS Bash
  ($env:VITE_SOME_KEY="54l41n3n4v41m34rv0") -and (npm run dev) // For Windows PowerShell
  set "VITE_SOME_KEY=54l41n3n4v41m34rv0" && npm run dev // For Windows cmd.exe
* You can access the value of the key from the import.meta.env object:
  const api_key = import.meta.env.VITE_SOME_KEY
* import { useState, useEffect } from 'react'
* const countriesToShow = (search.length === 0) ? [] : countries.filter(c => c.name.common.toLowerCase().includes(search.toLowerCase()))
* <ul>
    {Object.entries(country.languages).map(([key, value]) => (
      <li key={key}>{value}</li>
    ))}
  </ul>
* {weather &&
    <>...</>
  }
* {courses.map(course => <Course key={course.id} course={course} />)}
* <Total sum={course.parts.reduce((total, part) => total + part.exercises, 0)} />
* if (persons.filter(p => p.name === newName).length > 0) { ... }
* const createPerson = (person) => {
    return axios
      .post(baseUrl, person)
      .then(response => response.data)
  }
* const Notification = ({ notification }) => {
    if (notification === null) {
      return null
    }

    return (
      <div className={'notification' + (notification.type === 'success' ? ' success' : ' error')}>
        {notification.message}
      </div>
    )
  }
  export default Notification


Part 3: Programming a server with NodeJS and Express
----------------------------------------------------
*  NodeJS is a JavaScript runtime based on Google's Chrome V8 JavaScript engine.
   - https://nodejs.org/en/ (v18.13.0+)
   - https://developers.google.com/v8/
* Check Node version: node -v
* browsers don't yet support the newest features of JavaScript, and that is why the code running in the browser must be transpiled with e.g. babel (https://babeljs.io/).
* The newest version of Node supports a large majority of the latest features of JavaScript, so we can use the latest features without having to transpile our code.
* npm is a tool used for managing JavaScript packages: https://www.npmjs.com/
* Create a new template for an application: 
  npm init (answer questions -> generates package.json)
* package.json:
  - scripts (commands)
  - dependencies
  - development dependencies
* Define a script for starting the application server:
  "start": "node index.js"
* Start the application using the script above:
  npm run start
* Start the applcation without the script (not recommended):
  node index.js
* Import Node's built-in web server module:
  const http = require('http')  // Node.js uses so-called CommonJS modules
* Code that runs in the browser uses ES6 modules. Modules are defined with an export and taken into use with an import.
  import http from 'http'
* CommonJS modules: https://en.wikipedia.org/wiki/CommonJS
* Node supports now also the use of ES6 modules, but since the support is not quite perfect yet, we'll stick to CommonJS modules.
  - https://nodejs.org/api/esm.html#modules-ecmascript-modules
* The server can be shut down by pressing Ctrl+C in the console.
* Express (http://expressjs.com/) is by far the most popular library to build a backend server (based on Node.js).
  npm install express
* Transitive dependencies are the depedendencies of a dependency: https://lexi-lambda.github.io/blog/2016/08/24/understanding-the-npm-dependency-model/
* Semantic versioning: https://docs.npmjs.com/getting-started/semantic-versioning
* The caret in the front of ^4.18.2 means that if and when the dependencies of a project are updated, the version of express that is installed will be at least 4.18.2. However, the installed version of express can also have a larger patch number (the last number), or a larger minor number (the middle number). The major version of the library indicated by the first major number must be the same.
* Install dependencies:
  npm install
* Update dependencies:
  npm update
* If the major number of a dependency does not change, then the newer versions should be backwards compatible:
  https://en.wikipedia.org/wiki/Backward_compatibility
* The future versions (5.0.0+) of express may contain changes that would cause our application to no longer work.
* Import Express and create an express application:
  const express = require('express')
  const app = express()
* Define a route to the application:
  app.get('/', (request, response) => {
    response.send('<h1>Hello World!</h1>')
  })
* Request parameter: http://expressjs.com/en/4x/api.html#req
* Response parameter: http://expressjs.com/en/4x/api.html#res
* The send method: http://expressjs.com/en/4x/api.html#res.send
* JSON response: http://expressjs.com/en/4x/api.html#res.json
* Since the parameter is a string, express automatically sets the value of the Content-Type header to be text/html.
* The status code of the response defaults to 200.
* Define another route to the application:
  app.get('/api/notes', (request, response) => {
    response.json(notes)
  })
* Express automatically sets the Content-Type header with the appropriate value of application/json.
* Express automatically transforms data to JSON (no need for JSON.stringify(...))
* JSON is a string and not a JavaScript object: https://en.wikipedia.org/wiki/JSON
* Interactive node-repl: https://nodejs.org/docs/latest-v8.x/api/repl.html
  - Start by typing in "node" in the command line.
  - Exit the shell by typing in ".exit".
* nodemon (https://github.com/remy/nodemon) will watch the files in the directory in which nodemon was started, and if any files change, nodemon will automatically restart your node application.
* Install nodemon:
  npm install --save-dev nodemon
* If you accidentally used the wrong command and the nodemon dependency was added under "dependencies" instead of "devDependencies", then manually change its place in package.json.
* By development dependencies, we are referring to tools that are needed only during the development of the application, e.g. for testing or automatically restarting the application, like nodemon.
* These development dependencies are not needed when the application is run in production mode on the production server (e.g. Fly.io or Heroku).
* Hot reload in frontend development: https://gaearon.github.io/react-hot-loader/getstarted/
* The script for package.json to start the application server in development mode:
  "dev": "nodemon index.js"
* Start the application in development mode using the script above:
  npm run dev
* Start the application in development mode without the script (not recommended):
  node_modules/.bin/nodemon index.js
* Representational State Transfer, aka REST, was introduced in 2000 in Roy Fielding's dissertation (https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm). REST is an architectural style meant for building scalable web applications.
  - Applied to web services: https://en.wikipedia.org/wiki/Representational_state_transfer#Applied_to_web_services
* Singular things, like notes in the case of our application, are called resources in RESTful thinking. Every resource has an associated URL which is the resource's unique address.
* One convention for creating unique addresses is to combine the name of the resource type with the resource's unique identifier.
  - www.example.com/api/notes/10
* We can execute different operations on resources. The operation to be executed is defined by the HTTP verb:
  URL	verb	functionality
  - notes/10	GET	fetches a single resource (200)
  - notes	GET	fetches all resources in the collection (200)
  - notes	POST	creates a new resource based on the request data (201)
  - notes/10	DELETE	removes the identified resource (204)
  - notes/10	PUT	replaces the entire identified resource with the request data (200)
  - notes/10	PATCH	replaces a part of the identified resource with the request data (200)
* Second level of RESTful maturity: https://martinfowler.com/articles/richardsonMaturityModel.html
* CRUD API: https://en.wikipedia.org/wiki/Create,_read,_update_and_delete
* Resource-oriented architecture (not REST): https://en.wikipedia.org/wiki/Resource-oriented_architecture
* Route: http://expressjs.com/en/guide/routing.html
* Route parameters: http://expressjs.com/en/guide/routing.html#route-parameters
  app.get('/api/notes/:id', (request, response) => {
    const id = Number(request.params.id)
    const note = notes.find(note => note.id === id)
    if (note) {
      response.json(note)
    }
    else {
      response.status(404).end()
    }
  })
* If no note is found, the server should respond with the status code 404 not found instead of 200.
  - https://www.rfc-editor.org/rfc/rfc9110.html#name-404-not-found
* Since no data is attached to the response, we use the status method for setting the status and the end method for responding to the request without sending any data.
* Response status method: http://expressjs.com/en/4x/api.html#res.status
* Response end method: http://expressjs.com/en/4x/api.html#res.end
* The if-condition leverages the fact that all JavaScript objects are truthy, meaning that they evaluate to true in a comparison operation. However, undefined is falsy meaning that it will evaluate to false.
  - Truthy: https://developer.mozilla.org/en-US/docs/Glossary/Truthy
  - Falsy: https://developer.mozilla.org/en-US/docs/Glossary/Falsy
* We do not need to display anything (e.g., error message) in the browser because REST APIs are interfaces that are intended for programmatic use, and the error status code is all that is needed.
* Custom error message: https://stackoverflow.com/questions/14154337/how-to-send-a-custom-http-status-message-in-node-express/36507614#36507614
* If deleting the resource is successful, meaning that the note exists and is removed, we respond to the request with the status code 204 no content and return no data with the response.
  - https://www.rfc-editor.org/rfc/rfc9110.html#name-204-no-content
* There's no consensus on what status code should be returned to a DELETE request if the resource does not exist. The only two options are 204 and 404.
* curl: https://curl.haxx.se/
* Postman, HTTP client: https://www.postman.com/
* Visual Studio Code REST client extension: https://marketplace.visualstudio.com/items?itemName=humao.rest-client
  - Make a directory "requests" at the root of the application named requests. We save all the REST client requests in the directory as files that end with the .rest extension.
* WebStorm HTTP Client: https://www.jetbrains.com/help/webstorm/http-client-in-product-code-editor.html
* Adding a note happens by making an HTTP POST request to the address http://localhost:3001/api/notes, and by sending all the information for the new note in the request body in JSON format.
  - Request body: https://www.w3.org/Protocols/rfc2616/rfc2616-sec7.html#sec7
* To access the data easily, we need the help of the express json-parser that we can use with the command app.use(express.json()).
  - JSON parser: https://expressjs.com/en/api.html
  app.post('/api/notes', (request, response) => {
    const note = request.body
    console.log(note)
    response.json(note)
  })
* Without the json-parser, the body property would be undefined. The json-parser takes the JSON data of a request, transforms it into a JavaScript object and then attaches it to the body property of the request object before the route handler is called.
* Thanks to Nodemon any changes we make to the code will restart the application.
* The server will not be able to parse the data correctly without the correct value in the request header content type.
* MIME types: https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types
* How to format Visual Studio Code REST client requests: https://github.com/Huachao/vscode-restclient/blob/master/README.md#usage
* You can add multiple requests in the same file using ### separators:
* The get method of the request object can be used for getting the value of a single header. The request object also has the headers property, that contains all of the headers of a specific request.
* Problems can occur with the VS REST client if you accidentally add an empty line between the top row and the row specifying the HTTP headers. In this situation, the REST client interprets this to mean that all headers are left empty, which leads to the backend server not knowing that the data it has received is in the JSON format.
* The content property may not be empty:
  if (!body.content) {
    return response.status(400).json({ 
      error: 'content missing' 
    })
  }
* Bad request (400) when received data is missing: https://www.rfc-editor.org/rfc/rfc9110.html#name-400-bad-request
* The important property will be given default value false:
  important: Boolean(body.important) || false
* If the data saved in the body variable has the important property, the expression will evaluate its value and convert it to a boolean value. If the property does not exist, then the expression will evaluate to false which is defined on the right-hand side of the vertical lines.
  - To be exact, when the important property is false, then the body.important || false expression will in fact return the false from the right-hand side...
*  Math.max returns the maximum value of the numbers that are passed to it. However, notes.map(n => n.id) is an array so it can't directly be given as a parameter to Math.max. The array can be transformed into individual numbers by using the "three dot" spread syntax ....
   - Math.max(): https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/max
   - The spread syntax: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Spread_syntax
* There can only be one response.send() statement in an Express app route. Once you send a response to the client using response.send(), the request-response cycle is complete and no further response can be sent.
* Generate random IDs with Math.random(): https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/random
  - Use a big enough range for your random values so that the likelihood of creating duplicate ids is small.
* HTTP standard: https://www.rfc-editor.org/rfc/rfc9110.html#name-common-method-properties
* GET requests: In particular, the convention has been established that the GET and HEAD methods SHOULD NOT have the significance of taking an action other than retrieval. These methods ought to be considered "safe".
* Safety means that the executing request must not cause any side effects on the server. By side effects, we mean that the state of the database must not change as a result of the request, and the response must only return data that already exists on the server.
* HEAD request: https://www.rfc-editor.org/rfc/rfc9110.html#name-head
* In practice, HEAD should work exactly like GET but it does not return anything but the status code and response headers. The response body will not be returned when you make a HEAD request.
* Methods can also have the property of "idempotence" in that (aside from error or expiration issues) the side-effects of N > 0 identical requests is the same as for a single request. The methods GET, HEAD, PUT and DELETE share this property.
* This means that if a request does not generate side effects, then the result should be the same regardless of how many times the request is sent.
* POST is the only HTTP request type that is neither safe nor idempotent. If we send 5 different HTTP POST requests to /api/notes with a body of {content: "many same", important: true}, the resulting 5 notes on the server will all have the same content.
* Middleware: http://expressjs.com/en/guide/using-middleware.html
* Middleware are functions that can be used for handling request and response objects.
* In practice, you can use several middlewares at the same time. When you have more than one, they're executed one by one in the order that they were taken into use in express.
  const requestLogger = (request, response, next) => {
    console.log('Method:', request.method)
    console.log('Path:  ', request.path)
    console.log('Body:  ', request.body)
    console.log('---')
    next()
  }
* At the end of the function body, the next function that was passed as a parameter is called. The next function yields control to the next middleware.
* Middleware is taken into use like this:
  app.use(requestLogger)
* Middleware functions are called in the order that they're taken into use with the express server object's use method. Notice that json-parser is taken into use before the requestLogger middleware, because otherwise request.body will not be initialized when the logger is executed!
* Middleware functions have to be taken into use before routes if we want them to be executed before the route event handlers are called. There are also situations where we want to define middleware functions after routes. In practice, this means that we are defining middleware functions that are only called if no route handles the HTTP request.
* Let's add the following middleware after our routes. This middleware will be used for catching requests made to non-existent routes. For these requests, the middleware will return an error message in the JSON format.
  const unknownEndpoint = (request, response) => {
    response.status(404).send({ error: 'unknown endpoint' })
  }

  app.use(unknownEndpoint)
* The morgan middleware to your application for logging: https://github.com/expressjs/morgan
* Note that logging data even in the console can be dangerous since it can contain sensitive data and may violate local privacy law (e.g. GDPR in EU) or business-standard. In this exercise, you don't have to worry about privacy issues, but in practice, try not to log any sensitive data.
* Creating new tokens: https://github.com/expressjs/morgan#creating-new-tokens
* JSON stringify: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify
* const baseUrl = 'http://localhost:3001/api/notes'
* A URL's origin is defined by the combination of protocol (AKA scheme), hostname, and port.
* If the resource is fetched using a URL that doesn't share the same origin(scheme, host, port) as the source HTML, the browser will have to check the Access-Control-Allow-origin response header. If it contains * or the URL of the source HTML, the browser will process the response, otherwise the browser will refuse to process it and throws an error.
* The same-origin policy is a security mechanism implemented by browsers in order to prevent session hijacking among other security vulnerabilities.
* Cross-origin resource sharing (CORS) is a mechanism that allows restricted resources (e.g. fonts) on a web page to be requested from another domain outside the domain from which the first resource was served. A web page may freely embed cross-origin images, stylesheets, scripts, iframes, and videos. Certain "cross-domain" requests, notably Ajax requests, are forbidden by default by the same-origin security policy.
* Same origin policy: https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy
  - Because our server is in localhost port 3001, while our frontend is in localhost port 5173, they do not have the same origin.
* We can allow requests from other origins by using Node's cors middleware: https://github.com/expressjs/cors
* Install cors middleware:
  npm install cors
* Take cors middleware in use and allow for requests from all origins:
  const cors = require('cors')
  app.use(cors())
* CORS: https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS
* The developer-friendly services like PaaS (i.e. Platform as a Service) take care of installing the execution environment (eg. Node.js) and could also provide various services such as databases.
* Heroku (http://heroku.com/) free tier ended on November 27th 2022.
* Fly.io (https://fly.io/) and Render (https://render.com/) offer free plans.
* Fly.io is our "official" hosting service since it can be for sure used also on the parts 11 and 13 of the course. Render will be fine at least for the other parts of this course.
* Render might be a bit easier to use since it does not require any software to be installed on your machine.
* Alternative options for hosting Node.js applications:
  - Cyclic: https://www.cyclic.sh/
  - Replit: https://replit.com/
  - CodeSandBox: https://codesandbox.io/
* Read port from environment variables: https://en.wikipedia.org/wiki/Environment_variable
  const PORT = process.env.PORT || 3001
* Note that you may need to give your credit card number to Fly.io even if you are using only the free tier! At the moment Render can be used without a credit card.
* Fly's flyctl installation guide: https://fly.io/docs/hands-on/install-flyctl/
  - Authentication: fly auth login (or flyctl auth login)
  - Initialization: fly launch
  - Configuration: fly.toml
  - Deployment (incl. redeployment): fly deploy
  - Open the app: fly open
  - Logging: fly logs
  - Machines: fly scale show
  - Enforce one machine: fly scale count 1
  - Ping: fly ping -o personal
* Getting started with Render:
  - Sign in with GitHub: https://dashboard.render.com/
  - Create new web service: New > Web Service
  - Code repository: Public Git repository URL
  - Configurations: name, region, branch (main), root directory, environment (Node), build command (npm install), start command (npm run start)
  - App state: see the dashboard (incl. events, logs, disks, environment, shell, PRs, jobs, metrics, scaling, settings)
* Render documentation: https://render.com/docs/deploys
* According to the documentation every commit to GitHub should redeploy the app. Manual deployment is also possible.
* When the application is deployed, we must create a production build or a version of the application which is optimized for production.
  - Vite (frontend): https://vitejs.dev/guide/build.html
  - npm run build (see https://vitejs.dev/guide/build.html)
  - Creates a directory called "dist" with necessary files
* Minification (one file, scrambled code): https://en.wikipedia.org/wiki/Minification_(programming)
* One option for deploying the frontend is to copy the production build (the dist directory) to the root of the backend repository and configure the backend to show the frontend's main page (the file dist/index.html) as its main page.
  cp -r dist ../backend
* To make express show static content, the page index.html and the JavaScript, etc., it fetches, we need a built-in middleware from Express called static.
  - http://expressjs.com/en/starter/static-files.html
  - app.use(express.static('dist'))
  - Whenever express gets an HTTP GET request it will first check if the dist directory contains a file corresponding to the request's address. If a correct file is found, express will return it.
* Because of our situation, both the frontend and the backend are at the same address, we can declare baseUrl as a relative URL. 
  const baseUrl = '/api/notes'
* After the change, we have to create a new production build of the frontend and copy it to the root of the backend repository.
* If you are using Fly.io, there could be a .dockerignore file that specifies the exclusion of the "./build" directory during deployment. To ensure it gets deployed, consider renaming the ./build directory to ./static_build or an equivalent name.
* Streamlining deploying of the frontend with scripts:
  - Fly.io scripts:
    "scripts": {
      // ...
      "build:ui": "rm -rf dist && cd ../notes-frontend/ && npm run build && cp -r dist ../notes-backend",
      "deploy": "fly deploy",
      "deploy:full": "npm run build:ui && npm run deploy",    
      "logs:prod": "fly logs"
    }
  - Render scripts:
    "scripts": {
      //...
      "build:ui": "rm -rf dist && cd ../frontend && npm run build && cp -r dist ../backend",
      "deploy:full": "npm run build:ui && git add . && git commit -m uibuild && git push"
    }
* Note that the standard shell commands in build:ui do not natively work in Windows. Powershell in Windows works differently.
* Vite server proxy: https://vitejs.dev/config/server-options.html#server-proxy
* Proxy in Vite (vite.config.js) to fix the relative backend URL reference:
  // https://vitejs.dev/config/
  export default defineConfig({
    plugins: [react()],
    server: {
      proxy: {
        '/api': {
          target: 'http://localhost:3001',
          changeOrigin: true,
        },
      }
    },
  })
* If the React code does an HTTP request to a server address at http://localhost:5173 not managed by the React application itself (i.e. when requests are not about fetching the CSS or JavaScript of the application), the request will be redirected to the server at http://localhost:3001.
* Note that with the vite-configuration shown above, only requests that are made to paths starting with /api-are redirected to the server.
* A negative aspect of our approach is how complicated it is to deploy the frontend. Deploying a new version requires generating a new production build of the frontend and copying it to the backend repository.
* Deployment pipeline: https://martinfowler.com/bliki/DeploymentPipeline.html
* Deployment pipeline means an automated and controlled way to move the code from the computer of the developer through different tests and quality checks to the production environment.
* When you deploy your application to Internet, it is worth it to at least in the beginning keep an eye on the logs of the application AT ALL TIMES.
* Make sure the directory dist is not gitignored (.gitignore).
* Debugging Node applications:
  - Printing to the console: https://tenderlovemaking.com/2016/02/05/i-am-a-puts-debuggerer.html and https://swizec.com/blog/javascript-debugging-slightly-beyond-consolelog/
  - Visual Studio Code debugger: Run > Start Debugging
    - Configure launch.json, if needed (Add Configuration..., above VARIABLES menu)
    - See https://code.visualstudio.com/docs/editor/debugging
  - Chrome developer tools: 
    - Pass the --inspect flag to nodemon (-> click the green Node logo in Chrome dev tools):
      nodemon --inspect index.js
  - The stop and fix principle: https://leanscape.io/principles-of-lean-13-jidoka/
* MongoDB is a document (NoSQL) database: https://en.wikipedia.org/wiki/Document-oriented_database
* NoSQL databases > document databases: https://en.wikipedia.org/wiki/NoSQL
* Basics of Databases: https://tikape-s18.mooc.fi/
  - Different types of databases: https://tikape-s18.mooc.fi/part7/
* Collections in MongoDB: https://docs.mongodb.com/manual/core/databases-and-collections/
* Documents in MongoDB: https://docs.mongodb.com/manual/core/document/
* Preferred MongoDB provider (MongoDB Atlas): https://www.mongodb.com/atlas/database
  - Deployment option: Shared (free)
  - Cloud Provider & Region: AWS, Stockholm
  - Security: Authentication: Username and Password
  - IP Access: 0.0.0.0 (access from anywhere)
  - Databases: Connect
  - Driver and version: Node.js 4.0 or later
  - Connection string: MongoDB URI (copy-paste the string shown on the screen)
    - For example, mongodb+srv://fullstack:<password>@cluster0.o1opl.mongodb.net/?retryWrites=true&w=majority
  - View documents: Databases > Browse Collections
* Use the database directly from the backend JavaScript code with the official MongoDB Node.js driver library: https://mongodb.github.io/node-mongodb-native/
* Use the Mongoose library (Object-Document Library, ODM) instead (higher-elvel API): http://mongoosejs.com/index.html
* Install Mongoose:
  npm install mongoose
* Import Mongoose:
  const mongoose = require('mongoose')
  mongoose.set('strictQuery',false)
  mongoose.connect(url)
* We can access the command line parameter like this:
  const password = process.argv[2]  // node mongo.js yourPassword, Mongo will add a new document to the database.
* URL encode MongoDB user password in the URI in case you used special characters, if needed: https://docs.atlas.mongodb.com/troubleshoot-connection/#special-characters-in-connection-string-password
* MongoDB Atlas automatically creates a new database (noteApp) when an application tries to connect to a database that does not exist yet.
  const url =
  `mongodb+srv://fullstack:${password}@cluster0.o1opl.mongodb.net/noteApp?retryWrites=true&w=majority`
* MongoDB Schema: http://mongoosejs.com/docs/guide.html
  const noteSchema = new mongoose.Schema({
    content: String,
    important: Boolean,
  })
* MongoDB model: http://mongoosejs.com/docs/models.html
  const Note = mongoose.model('Note', noteSchema)
* The schema tells Mongoose how the note objects are to be stored in the database.
* The name of the collection will be the lowercase plural notes, because the Mongoose convention is to automatically name collections as the plural (e.g. notes) when the schema refers to them in the singular (e.g. Note).
* Document databases like Mongo are schemaless, meaning that the database itself does not care about the structure of the data that is stored in the database. It is possible to store documents with completely different fields in the same collection.
* The idea behind Mongoose is that the data stored in the database is given a schema at the level of the application that defines the shape of the documents stored in any given collection.
* Note object using the Note model:
  const note = new Note({
    content: 'HTML is Easy',
    important: false,
  })
* Models are so-called constructor functions that create new JavaScript objects based on the provided parameters. Since the objects are created with the model's constructor function, they have all the properties of the model, which include methods for saving the object to the database.
* Save the object to the database:
  note.save().then(result => {
    console.log('note saved!')
    mongoose.connection.close()  // If the connection is not closed, the program will never finish its execution.
  })
* Mixing promises with old-school callbacks (present in MongoDB documentation) in the same code is not recommended.
* Retrieve objects from the database using the find method: https://mongoosejs.com/docs/api/model.html#model_Model-find
* The parameter of the method is an object expressing search conditions. Since the parameter is an empty object{}, we get all of the notes stored in the notes collection.
* Mongo search query syntax: https://docs.mongodb.com/manual/reference/operator/
* Do not include the password in the file that you commit and push to GitHub! Pass the password as a command-line argument:
  node mongo.js yourpassword
* Get the command-line parameters from the process.env variable:
  https://nodejs.org/docs/latest-v8.x/api/process.html#process_process_argv
* Do not close the connection in the wrong place! The correct place for closing the database connection is at the end of the callback function:
  Person
    .find({})
    .then(persons=> {
      // ...
      mongoose.connection.close()
    })
* If you define a model with the name Person, mongoose will automatically name the associated collection as people.
* Updated route handler:
  app.get('/api/notes', (request, response) => {
    Note.find({}).then(notes => {
      response.json(notes)
    })
  })
* Modify the toJSON method of the schema to return data in the desired format: https://stackoverflow.com/questions/7034848/mongodb-output-id-instead-of-id
  - https://mongoosejs.com/docs/guide.html#options
  - https://mongoosejs.com/docs/guide.html#toJSON
  - https://mongoosejs.com/docs/api.html#document_Document-toObject
  - https://mongoosejs.com/docs/api/document.html#transform
  noteSchema.set('toJSON', {
    transform: (document, returnedObject) => {
      returnedObject.id = returnedObject._id.toString()
      delete returnedObject._id
      delete returnedObject.__v
    }
  })
* Even though the _id property of Mongoose objects looks like a string, it is in fact an object.
* Move/extract the Mongoose-specific code into its own module.
* Put models in node.js in the models directory.
* Defining Node modules: https://nodejs.org/docs/latest-v8.x/api/modules.html
* The public interface of the module is defined by setting a value to the module.exports variable.
  module.exports = mongoose.model('Note', noteSchema)
* The other things defined inside of the module, like the variables mongoose and url will not be accessible or visible to users of the module.
* Importing the module happens by adding the following line to index.js:
  const Note = require('./models/note')
* It's not a good idea to hardcode the address of the database into the code, so instead the address of the database is passed to the application via the MONGODB_URI environment variable.
  const url = process.env.MONGODB_URI
* Define the value of an environment variable:
  MONGODB_URI=address_here npm run dev
* A more sophisticated way is to use the dotenv (https://github.com/motdotla/dotenv#readme) library. You can install the library with the command:
  npm install dotenv
* To use the library, we create a .env file at the root of the project. The environment variables are defined inside of the file, and it can look like this:
  MONGODB_URI=mongodb+srv://fullstack:<password>@cluster0.o1opl.mongodb.net/noteApp?retryWrites=true&w=majority
  PORT=3001
* The .env file should be gitignored right away since we do not want to publish any confidential information publicly online!!!
* The environment variables defined in the .env file can be taken into use with the expression require('dotenv').config() and you can reference them in your code just like you would reference normal environment variables, with the familiar process.env.MONGODB_URI syntax.
* It's important that dotenv gets imported before the note model is imported. This ensures that the environment variables from the .env file are available globally before the code from the other modules is imported.
* Because GitHub is not used with Fly.io, the file .env also gets to the Fly.io servers when the app is deployed. Because of this, the env variables defined in the file will be available there.
* However, a better option is to prevent .env from being copied to Fly.io by creating in the project root the file .dockerignore, with the following contents ".env".
  - Set the env value from the command line with the command:
    fly secrets set MONGODB_URI="mongodb+srv://fullstack:<password>@cluster0.o1opl.mongodb.net/noteApp?retryWrites=true&w=majority"
* When using Render, the database url is given by defining the proper env in the dashboard:
  Environment > MONGODB_URI key + Value
* Updated route handler:
  app.post('/api/notes', (request, response) => {
    const body = request.body

    if (body.content === undefined) {
      return response.status(400).json({ error: 'content missing' })
    }

    const note = new Note({
      content: body.content,
      important: body.important || false,
    })

    note.save().then(savedNote => {
      response.json(savedNote)
    })
  })
* Updated route handler for retrieving a specific note:
  app.get('/api/notes/:id', (request, response) => {
    Note.findById(request.params.id).then(note => {
      response.json(note)
    })
  })
* When the backend gets expanded, it's a good idea to test the backend first with the browser, Postman or the VS Code REST client.
* If a note with the given id doesn't exist, the server will respond to the request with the HTTP status code 404 not found. In addition let's implement a simple catch block to handle cases where the promise returned by the findById method is rejected:
  app.get('/api/notes/:id', (request, response) => {
    Note.findById(request.params.id)
      .then(note => {

        if (note) {
          response.json(note)
        } else {
          response.status(404).end()
        }
      })

      .catch(error => {
        console.log(error)  // for logging and debugging purposes
        response.status(400).send({ error: 'malformatted id' })
      })
  })
* Return HTTP status code 400 when the request could not be understood by the server due to malformed syntax. The client SHOULD NOT repeat the request without modifications.
* When dealing with Promises, it's almost always a good idea to add error and exception handling. Otherwise, you will find yourself dealing with strange bugs.
* Move error handling into a dedicated middleware.
* We have written the code for the error handler among the rest of our code. This can be a reasonable solution at times, but there are cases where it is better to implement all error handling in a single place. This can be particularly useful if we want to report data related to errors to an external error-tracking system like Sentry (https://sentry.io/welcome/) later on.
  app.get('/api/notes/:id', (request, response, next) => {
    ...
    .catch(error => next(error))
  })
* The error that is passed forward is given to the next function as a parameter. If next was called without a parameter, then the execution would simply move onto the next route or middleware. If the next function is called with a parameter, then the execution will continue to the error handler middleware.
* Express error handlers are middleware that are defined with a function that accepts four parameters.
* Error handling: https://expressjs.com/en/guide/error-handling.html
  app.use(errorHandler) // this has to be the last loaded middleware
* The execution order of middleware is the same as the order that they are loaded into express with the app.use function. For this reason, it is important to be careful when defining middleware.
* The json-parser middleware should be among the very first middleware loaded into Express.
  app.use(express.json())
* It's also important that the middleware for handling unsupported routes is next to the last middleware that is loaded into Express, just before the error handler.
  app.use(unknownEndpoint)
* Since the unknown endpoint handler responds to all requests with 404 unknown endpoint, no routes or middleware will be called after the response has been sent by unknown endpoint middleware. The only exception to this is the error handler which needs to come at the very end, after the unknown endpoints handler.
* Delete a note from the database is with the findByIdAndDelete method: https://mongoosejs.com/docs/api/model.html#Model.findByIdAndDelete()
  app.delete('/api/notes/:id', (request, response, next) => {
    Note.findByIdAndDelete(request.params.id)
      .then(result => {
        response.status(204).end()
      })
      .catch(error => next(error))
  })
* Update a note in the database is with the findByIdAndUpdate method: https://mongoosejs.com/docs/api/model.html#model_Model-findByIdAndUpdate
  app.put('/api/notes/:id', (request, response, next) => {
    const body = request.body

    const note = {
      content: body.content,
      important: body.important,
    }

    Note.findByIdAndUpdate(request.params.id, note, { new: true })
      .then(updatedNote => {
        response.json(updatedNote)
      })
      .catch(error => next(error))
  })
* By default, the updatedNote parameter of the event handler receives the original document without the modifications: https://mongoosejs.com/docs/api/model.html#model_Model-findByIdAndUpdate
  - The optional { new: true } parameter, which will cause our event handler to be called with the new modified document instead of the original.
* A true full stack developer's oath:
  - I will have my browser developer console open all the time
  - I will use the network tab of the browser dev tools to ensure that frontend and backend are communicating as I expect
  - I will constantly keep an eye on the state of the server to make sure that the data sent there by the frontend is saved there as I expect
  - I will keep an eye on the database: does the backend save data there in the right format
  - I progress with small steps
  - I will write lots of console.log statements to make sure I understand how the code behaves and to help pinpoint problems
  - If my code does not work, I will not write more code. Instead, I start deleting the code until it works or just return to a state when everything was still working
* The validity of the note is checked in the route handler:
  if (body.content === undefined) {
    return response.status(400).json({ error: 'content missing' })
  }
* One smarter way of validating the format of the data before it is stored in the database is to use the validation functionality available in Mongoose.
  - https://mongoosejs.com/docs/validation.html
    const noteSchema = new mongoose.Schema({
    content: {
      type: String,
      minLength: 5,
      required: true
    },
    important: Boolean
  })
* Built-in validators: https://mongoosejs.com/docs/validation.html#built-in-validators
* Custom validators: https://mongoosejs.com/docs/validation.html#custom-validators
* If we try to store an object in the database that breaks one of the constraints, the operation will throw an exception. 
* Pass any potential exceptions to the error handler middleware:
  .catch(error => next(error))
* Expand the error handler to deal with these validation errors:
  else if (error.name === 'ValidationError') {
    return response.status(400).json({ error: error.message })
  }
* Validations are not run by default when findOneAndUpdate and related methods are executed. Fix the issue:
  app.put('/api/notes/:id', (request, response, next) => {

    const { content, important } = request.body

    Note.findByIdAndUpdate(
      request.params.id, 

      { content, important },
      { new: true, runValidators: true, context: 'query' } // !!!
    ) 
      .then(updatedNote => {
        response.json(updatedNote)
      })
      .catch(error => next(error))
  })
* For production, we have to set the database URL in the service that is hosting our app:
  fly secrets set MONGODB_URI='mongodb+srv://fullstack:<password>@cluster0.o1opl.mongodb.net/noteApp?retryWrites=true&w=majority'
* Mongoose validation: https://mongoosejs.com/docs/validation.html
* Code linting: https://en.wikipedia.org/wiki/Lint_(software)
* Generically, lint or a linter is any tool that detects and flags errors in programming languages, including stylistic errors. The term lint-like behavior is sometimes applied to the process of flagging suspicious language usage. Lint-like tools generally perform static analysis of source code.
* Statistic program analysis: https://en.wikipedia.org/wiki/Static_program_analysis
  - Checkstyle: https://checkstyle.sourceforge.io/
* The current leading tool for static analysis (aka "linting") in JavaScript is ESlint: https://eslint.org/
* Install ESling as a development dependency:
  npm install eslint --save-dev
* Initialize a default ESlint configuration (the configuration will be saved in the .eslintrc.js file):
  npx eslint --init
* Some configurations:
  'env': { 'node': true, ... }
  'extends': 'eslint:recommended',
* Change the rule regarding the indentation level to two spaces:
  "indent": ["error", 2]
* Inspect and validate files (not recommended):
  npx eslint index.js
* It is recommended to add a dedicated script for linting:
  "lint": "eslint ."
* Check (lint) all files:
  npm run lint
* Also the files in the dist directory get checked when the command is run. We do not want this to happen, and we can accomplish this by creating an .eslintignore file in the project's root with the following contents "dist".
* A better alternative to executing the linter from the command line is to configure an eslint-plugin to the editor, that runs the linter continuously. By using the plugin you will see errors in your code immediately.
* More information about the Visual Studio Code ESLint extension: https://marketplace.visualstudio.com/items?itemName=dbaeumer.vscode-eslint
  - Underlines style violation with a red line, which makes errors easy to spot and fix right away.
* ESLint rules (take in use in .eslintrc.js): https://eslint.org/docs/rules/
* Our default configuration takes a bunch of predetermined rules into use from eslint:recommended:
  'extends': 'eslint:recommended'
* Many companies define coding standards that are enforced throughout the organization through the ESlint configuration file. It is not recommended to keep reinventing the wheel over and over again, and it can be a good idea to adopt a ready-made configuration from someone else's project into yours. Recently many projects have adopted the Airbnb Javascript style guide by taking Airbnb's ESlint configuration into use.
  - Airbnb JavaScript style guide and ESlint configuration: https://github.com/airbnb/javascript and https://github.com/airbnb/javascript/tree/master/packages/eslint-config-airbnb
* Backend project structure:
  - dist/
    - assets/*.css, *.js
    - index.html
  - models/*.js (mongoose)
  - requests/*.rest
  - .env and .env.example
  - .eslintignore
  - .eslintrc.js
  - .gitignore
  - index.js
  - package.json
* Add headers immediately after the method and URL definition in *.rest files (no empty lines between them).
* All backend scripts:
  "scripts": {
    "start": "node index.js",
    "dev": "nodemon index.js",
    "test": "echo \"Error: no test specified\" && exit 1",
    "build:ui": "rm -rf dist && cd ../phonebook-frontend && npm run build && cp -r dist ../phonebook-backend",
    "deploy:full": "npm run build:ui && git add . && git commit -m uibuild && git push",
    "lint": "eslint ."
  },
* 200 success
* 201 created
* 204 no content
* 400 bad client request
* 404 not found
* 409 conflict (already exists)
* Frontend project structure:
  - dist/
    - assets/*.css, *.js
    - index.html
  - public/vite.svg
  - src/
    - components/*.jsx
    - services/*.js (Axios)
    - App.jsx
    - index.css
    - main.jsx
  - .eslintrc.cjs
  - .gitignore
  - index.html
  - package.json
  - vite.config.js (proxy)
* All frontend scripts:
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "lint": "eslint . --ext js,jsx --report-unused-disable-directives --max-warnings 0",
    "preview": "vite preview"
  },
* Frontend and backend have different ESLint configurations!
* Show a notification on success/error for five seconds.


Part 4: Testing Express servers, user administration
----------------------------------------------------
* Project structure (best practices):
  ├── index.js
  ├── app.js
  ├── dist
  │   └── ...
  ├── controllers
  │   └── notes.js
  ├── models
  │   └── note.js
  ├── package-lock.json
  ├── package.json
  ├── utils
  │   ├── config.js
  │   ├── logger.js
  │   └── middleware.js  
* Separate all printing to the console to its own module utils/logger.js:
  const info = (...params) => {
    console.log(...params)
  }

  const error = (...params) => {
    console.error(...params)
  }

  module.exports = {
    info, error
  }
* Extracting logging into its own module is a good idea in more ways than one. If we wanted to start writing logs to a file or send them to an external logging service like graylog (https://www.graylog.org/) or papertrail (https://papertrailapp.com/) we would only have to make changes in one place.
* Separate the handling of environment variables to its own module utils/config.js file:
  require('dotenv').config()

  const PORT = process.env.PORT
  const MONGODB_URI = process.env.MONGODB_URI

  module.exports = {
    MONGODB_URI,
    PORT
  }
* Access the environment variables in other modules:
  const config = require('./utils/config')
  logger.info(`Server running on port ${config.PORT}`)
* Now the Express app and the code taking care of the web server are separated from each other following the best practices.
  - https://dev.to/nermineslimane/always-separate-app-and-server-files--1nc7
* One of the advantages of this method is that the application can now be tested at the level of HTTP API calls without actually making calls via HTTP over the network, this makes the execution of tests faster.
* The route handlers have also been moved into a dedicated module. The event handlers of routes are commonly referred to as controllers, and for this reason we have created a new controllers directory. All of the routes related to notes are now in the notes.js module under the controllers directory.
  const notesRouter = require('express').Router()
  const Note = require('../models/note')

  notesRouter.get('/', (request, response) => {
    Note.find({}).then(notes => {
      response.json(notes)
    })
  })
  ...
  module.exports = notesRouter
* Express router: http://expressjs.com/en/api.html#router
* A router object is an isolated instance of middleware and routes. You can think of it as a “mini-application,” capable only of performing middleware and routing functions. Every Express application has a built-in app router.
* The router is in fact a middleware, that can be used for defining "related routes" in a single place, which is typically placed in its own module.
* The app.js file that creates the actual application takes the router into use as shown below:
  const notesRouter = require('./controllers/notes')
  app.use('/api/notes', notesRouter)
* The router we defined earlier is used if the URL of the request starts with /api/notes. For this reason, the notesRouter object must only define the relative parts of the routes, i.e. the empty path / or just the parameter /:id.
* The custom middleware has been moved to a new utils/middleware.js module:
  ...
  module.exports = { requestLogger, unknownEndpoint, errorHandler }
* The note.js file under the models directory only defines the Mongoose schema for notes.
* The responsibility of establishing the connection to the database has been given to the app.js module.
* The project structure simply follows some of the best practices you can come across on the internet.
* In Visual Studio Code, if you right-click on a variable in the location it is exported from and select "Find All References", it will show you everywhere the variable is imported.
  - However, if you assign an object directly to module.exports, it will not work. A workaround is to assign the object you want to export to a named variable and then export the named variable. It also will not work if you destructure where you are importing; you have to import the named variable and then destructure, or just use dot notation to use the functions contained in the named variable.
* Install Mongoose 7.6.5:
  npm install mongoose@7.6.5
* If you're having issues with content.body being undefined for seemingly no reason, make sure you didn't forget to add app.use(express.json()) near the top of the file.
* Unit tests are for testing separate functions.
* Reduce method: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/Reduce
* Functional JavaScript on YouTube: https://www.youtube.com/watch?v=BMUiFMZr7vk&list=PL0zVEGEvSaeEd9hlmCXrk5yUyqUag-n84
* Jest testing library by Facebook: https://jestjs.io/
  - Successor of Mocha: https://mochajs.org/
* Jest is a natural choice for this course, as it works well for testing backends, and it shines when it comes to testing React applications.
* Install Jest:
  npm install --save-dev jest
* Define a script for testing:
  "test": "jest --verbose"
* Jest configuration (package.json) for backend testing:
  {
    //...
    "jest": {
      "testEnvironment": "node"
    }
  }
* Create test files *.test.js in a separate directory called "tests".
* Let's get rid of the complaints by adding "jest": true to the env property in the .eslintrc.js file.
* Individual test cases are defined with the test function. The first parameter of the function is the test description as a string. The second parameter is a function, that defines the functionality for the test case. 
  test('reverse of a', () => {
    const result = reverse('a')

    expect(result).toBe('a')
  })
* Verify the results with the expect (https://jestjs.io/docs/expect#expectvalue) function. Expect wraps the resulting value into an object that offers a collection of matcher functions, that can be used for verifying the correctness of the result. Since in this test case we are comparing two strings, we can use the toBe matcher.
* Jest expects by default that the names of test files contain .test. In this course, we will follow the convention of naming our tests files with the extension .test.js.
* Describe blocks can be used for grouping tests into logical collections. 
  describe('average', () => {
    // tests
  })
* Describe blocks are necessary when we want to run some shared setup or teardown operations for a group of tests.
* It's recommended to put the tests inside of a describe block so that the test report output gets grouped nicely.
* Debugging tests: https://jestjs.io/docs/en/troubleshooting
* You can run a single test with the only method: https://jestjs.io/docs/api#testonlyname-fn-timeout
* Another way of running a single test (or describe block) is to specify the name of the test to be run with the -t flag:
  npm run test -- -t 'when list has only one blog, equals the likes of that'
* Run a single test file:
  npm run test tests/blogs.test.js
* Run all test files:
  npm run test
* When you are comparing objects, the toEqual method is probably what you want to use, since the toBe tries to verify that the two values are the same value, and not just that they contain the same properties.
  - https://jestjs.io/docs/en/expect#toequalvalue (for objects)
  - https://jestjs.io/docs/en/expect#tobevalue (for values)
* Lodash helper library: https://lodash.com/
* If the backend does not contain any complicated logic, it doesn't make sense to write unit tests for it.
* Unit testing: https://en.wikipedia.org/wiki/Unit_testing
* In some situations, it can be beneficial to implement some of the backend tests by mocking the database instead of using a real database. One library that could be used for this is mongodb-memory-server: https://github.com/nodkz/mongodb-memory-server
* Integration testing encompasses multiple components of the system that are being tested a a group. For example, the backend and the database through a REST API.
* The convention in Node is to define the execution mode of the application with the NODE_ENV environment variable. In our current application, we only load the environment variables defined in the .env file if the application is not in production mode.
* It is common practice to define separate modes for development and testing.
* We also added the runInBand (https://jestjs.io/docs/cli#--runinband) option to the npm script that executes the tests to prevent Jest from running tests in parallel.
* cross-env (https://www.npmjs.com/package/cross-env) makes the script cross-platform compatible, including Windows.
* Install cross-env as an application-level dependency (needed in production):
  npm install cross-env
* Updated scripts in package.json:
  "scripts": {
    "start": "cross-env NODE_ENV=production node index.js",
    "dev": "cross-env NODE_ENV=development nodemon index.js",
    // ...
    "test": "cross-env NODE_ENV=test jest --verbose --runInBand",
  },
* Define the application (utils/config.js) to use, e.g., a separate test database, when it is running tests.
  const MONGODB_URI = process.env.NODE_ENV === 'test' 
    ? process.env.TEST_MONGODB_URI
    : process.env.MONGODB_URI
* We can create our separate test database in MongoDB Atlas. This is not an optimal solution in situations where many people are developing the same application. Test execution in particular typically requires a single database instance that is not used by tests that are running concurrently.
  - It would be better to run our tests using a database that is installed and running on the developer's local machine. 
  - MongoDB in memory: https://docs.mongodb.com/manual/core/inmemory/
  - Docker containers: https://www.docker.com/
* The .env file has separate variables for the database addresses of the development and test databases:
  MONGODB_URI=mongodb+srv://fullstack:<password>@cluster0.o1opl.mongodb.net/noteApp?retryWrites=true&w=majority
  PORT=3001
  TEST_MONGODB_URI=mongodb+srv://fullstack:<password>@cluster0.o1opl.mongodb.net/testNoteApp?retryWrites=true&w=majority
* Our own config module could be replace with node-config (https://github.com/lorenwest/node-config) in larger applications/in the future.
* Install supertest to help in writing tests for testing the API:
  npm install --save-dev supertest
* Tests are placed in *.test.js files in the "tests" directory. For example, tests/note_api.test.js
  const mongoose = require('mongoose')
  const supertest = require('supertest')
  const app = require('../app')

  const api = supertest(app)

  test('notes are returned as json', async () => {
    await api
      .get('/api/notes')
      .expect(200)
      .expect('Content-Type', /application\/json/)
  })

  afterAll(async () => {
    await mongoose.connection.close()
  })
* The desired value is now defined as regular expression or in short regex. The regex starts and ends with a slash /, because the desired string application/json also contains the same slash, it is preceded by a \ so that it is not interpreted as a regex termination character.
  .expect('Content-Type', /application\/json/)
* In principle, the test could also have been defined as a string, but the value of the header must be exactly the same. The actual value of the header is application/json; charset=utf-8, and it would not match that.
* The async/await syntax is related to the fact that making a request to the API is an asynchronous operation. The async/await syntax can be used for writing asynchronous code with the appearance of synchronous code.
  - https://jestjs.io/docs/asynchronous
* Once all the tests (there is currently only one) have finished running we have to close the database connection used by Mongoose. 
  - afterAll method: https://jestjs.io/docs/api#afterallfn-timeout
  afterAll(async () => {
    await mongoose.connection.close()
  })
* Extend the default Jest test timeout of 5000 ms, if needed:
  test('notes are returned as json', async () => {
    ...
  }, 10000)
* Another way to extend timeouts is using bufferTimeoutMS at the top, right after the require statements:
  mongoose.set("bufferTimeoutMS", 30000)
* The tests only use the Express application defined in the app.js file (thanks to the separation between app.js and index.js), which does not listen to any ports.
* Supertest takes care that the application being tested is started at the port that it uses internally.
* Expact value: https://jestjs.io/docs/expect#expectvalue
* Let us modify the logger so that it does not print to the console in test mode:
  const info = (...params) => {
    if (process.env.NODE_ENV !== 'test') { 
      console.log(...params)
    }
  }
  ...
* To make our tests more robust, we have to reset the database and generate the needed test data in a controlled manner before we run the tests.
* Jest offers many other functions (https://jestjs.io/docs/setup-teardown) that can be used for executing operations once before any test is run or every time before a test is run.
* Initialize the database before every test with the beforeEach function (https://jestjs.io/docs/en/api.html#beforeeachfn-timeout). By doing this, we ensure that the database is in the same state before every test is run.
  beforeEach(async () => {
    await Note.deleteMany({})
    let noteObject = new Note(initialNotes[0])
    await noteObject.save()
    noteObject = new Note(initialNotes[1])
    await noteObject.save()
  })
* The toContain method (https://jestjs.io/docs/expect#tocontainitem) is used for checking that the note given to it as a parameter is in the list of notes returned by the API.
* When we are writing tests, it is usually wise to only execute one or two tests. Jest offers a few different ways of accomplishing this, one of which is the only metho (https://jestjs.io/docs/en/api#testonlyname-fn-timeout). If tests are written across many files, this method is not great.
* A better option is to specify the tests that need to be run as parameters of the npm test command:
  npm test -- tests/note_api.test.js
* The -t option can be used for running tests with a specific name. The provided parameter can refer to the name of the test or the describe block. The parameter can also contain just a part of the name:
  npm test -- -t "a specific note is within the returned notes"
* The async/await syntax that was introduced in ES7 makes it possible to use asynchronous functions that return a promise in a way that makes the code look synchronous.
* Callback hell: http://callbackhell.com/
* By chaining promises (https://javascript.info/promise-chaining) we could keep the situation somewhat under control, and avoid callback hell by creating a fairly clean chain of then method calls.
  Note.find({})
    .then(notes => {
      return notes[0].deleteOne()
    })
    .then(response => {
      console.log('the first note is removed')
      // more code here
    })
* Generator functions (ES6): https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Generator
* The async and await keywords introduced in ES7 bring the same functionality as the generators (https://github.com/getify/You-Dont-Know-JS/blob/1st-ed/async%20%26%20performance/ch4.md#iterating-generators-asynchronously), but in an understandable and syntactically cleaner way to the hands of all citizens of the JavaScript world.
  const notes = await Note.find({})
  const response = await notes[0].deleteOne()
  console.log('the first note is removed')
* Await operator: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/await
* To use the await operator with asynchronous operations, they have to return a promise. This is not a problem as such, as regular asynchronous functions using callbacks are easy to wrap around promises.
* The await keyword can't be used just anywhere in JavaScript code. Using await is possible only inside of an async function (https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/async_function).
  const main = async () => {
    const notes = await Note.find({})
    console.log('operation returned the following notes', notes)

    const response = await notes[0].deleteOne()
    console.log('the first note is removed')
  }
* As all of the asynchronous operations are currently done inside of a function, it is enough to change the route handler functions into async functions:
  notesRouter.get('/', async (request, response) => { 
    const notes = await Note.find({})
    response.json(notes)
  })
* When code gets refactored, there is always the risk of regression (https://en.wikipedia.org/wiki/Regression_testing), meaning that existing functionality may break.
* Add common test functions to a dedicated file called tests/test_helper.js
* With async/await the recommended way of dealing with exceptions is the old and familiar try/catch mechanism:
  try {
    const savedNote = await note.save()
    response.status(201).json(savedNote)
  } catch(exception) {
    next(exception)
  }
* The catch block simply calls the next function, which passes the request handling to the error handling middleware.
* Async/await unclutters the code a bit, but the 'price' is the try/catch structure required for catching exceptions. 
* The express-async-errors library (https://github.com/davidbanham/express-async-errors) allows to eliminate the catch from methods.
* Install express-async-errors:
  npm install express-async-errors
* Use express-async-errors:
  require('express-async-errors')
* The 'magic' of the library allows us to eliminate the try-catch blocks completely. Also, because of the library, we do not need the next(exception) call anymore.
  notesRouter.delete('/:id', async (request, response) => {
    await Note.findByIdAndDelete(request.params.id)
    response.status(204).end()
  })
* If an exception occurs in an async route, the execution is automatically passed to the error handling middleware.
* Every iteration of the forEach loop generates an asynchronous operation, and beforeEach won't wait for them to finish executing. In other words, the await commands defined inside of the forEach loop are not in the beforeEach function, but in separate functions that beforeEach will not wait for.
* One way of fixing this is to wait for all of the asynchronous operations to finish executing with the Promise.all method: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/all
* The Promise.all method can be used for transforming an array of promises into a single promise, that will be fulfilled once every promise in the array passed to it as a parameter is resolved. The last line of code await Promise.all(promiseArray) waits until every promise for saving a note is finished, meaning that the database has been initialized.
* The returned values of each promise in the array can still be accessed when using the Promise.all method. If we wait for the promises to be resolved with the await syntax const results = await Promise.all(promiseArray), the operation will return an array that contains the resolved values for each promise in the promiseArray, and they appear in the same order as the promises in the array.
* Promise.all executes the promises it receives in parallel.
* The for...of block, that guarantees a specific execution order:
  beforeEach(async () => {
    await Note.deleteMany({})

    for (let note of helper.initialNotes) {
      let noteObject = new Note(note)
      await noteObject.save()
    }
  })
* The asynchronous nature of JavaScript can lead to surprising behavior, and for this reason, it is important to pay careful attention when using the async/await syntax. Even though the syntax makes it easier to deal with promises, it is still necessary to understand how promises work!
* A true full stack developer's oath:
  - I will have my browser developer console open all the time
  - I will use the network tab of the browser dev tools to ensure that frontend and backend are communicating as I expect
  - I will constantly keep an eye on the state of the server to make sure that the data sent there by the frontend is saved there as I expect
  - I will keep an eye on the database: does the backend save data there in the right format
  - I will progress in small steps
  - I will write lots of console.log statements to make sure I understand how the code and the tests behave and to help pinpoint problems
  - If my code does not work, I will not write more code. Instead, I start deleting the code until it works or just return to a state when everything was still working
  - If a test does not pass, I make sure that the tested functionality for sure works in the application
* It's worth noting that the toContain (https://jestjs.io/docs/expect#tocontainitem) method uses the === operator for comparing and matching elements, which means that it is often not well-suited for matching objects. In most cases, the appropriate method for verifying objects in arrays is the toContainEqual (https://jestjs.io/docs/expect#tocontainequalitem) matcher.
* If you find yourself using async/await and then methods in the same code, it is almost guaranteed that you are doing something wrong. Use one or the other and don't mix the two.
* It is often better to not execute all of your tests, only execute the ones you are working on.
* Verifying the existence of a property is easily done with Jest's toBeDefined matcher: https://jestjs.io/docs/en/expect#tobedefined
* The grouping and organization of tests using describe() improves readability and maintainability.
  describe('addition of a new note', () => {
    test('succeeds with valid data', async () => { ... })
  })
* This way of testing the API, by making HTTP requests and inspecting the database with Mongoose, is by no means the only nor the best way of conducting API-level integration tests for server applications. There is no universal best way of writing tests, as it all depends on the application being tested and available resources.
* Like with all document databases, we can use object IDs in Mongo to reference documents in other collections. This is similar to using foreign keys in relational databases.
* Traditionally document databases like Mongo do not support join queries that are available in relational databases, used for aggregating data from multiple tables. However, starting from version 3.2. Mongo has supported lookup aggregation queries: https://docs.mongodb.com/manual/reference/operator/aggregation/lookup/
* If we need functionality similar to join queries, we will implement it in our application code by making multiple queries. In certain situations, Mongoose can take care of joining and aggregating data, which gives the appearance of a join query. However, even in these situations, Mongoose makes multiple queries to the database in the background.
* If we were using a relational database the note would contain a reference key to the user who created it. In document databases, we can do the same thing.
* Document databases do not demand the foreign key to be stored in the note resources, it could also be stored in the users collection, or even both.
* Since users can have many notes, the related ids are stored in an array in the notes field.
* Document databases also offer a radically different way of organizing the data: In some situations, it might be beneficial to nest the entire notes array as a part of the documents in the users collection.
  - In this schema, notes would be tightly nested under users and the database would not generate ids for them.
  - The chosen schema must support the use cases of the application the best.
* Paradoxically, schema-less databases like Mongo require developers to make far more radical design decisions about data organization at the beginning of the project than relational databases with schemas. On average, relational databases offer a more or less suitable way of organizing data for many applications.
* The ids of the notes are stored within the user document as an array of Mongo ids:
  notes: [
    {
      type: mongoose.Schema.Types.ObjectId,
      ref: 'Note'
    }
  ],
* The type of the field is ObjectId that references note-style documents. Mongo does not inherently know that this is a field that references notes, the syntax is purely related to and defined by Mongoose.
* In stark contrast to the conventions of relational databases, references are now stored in both documents: the note references the user who created it, and the user has an array of references to all of the notes created by them.
* Users have a unique username, a name and something called a passwordHash. The password hash is the output of a one-way hash function applied to the user's password. It is never wise to store unencrypted plain text passwords in the database!
  - https://en.wikipedia.org/wiki/Cryptographic_hash_function
* Install bcrypt for generating the password hashes:
  npm install bcrypt
* The password sent in the request is not stored in the database. We store the hash of the password that is generated with the bcrypt.hash function:
  const saltRounds = 10
  const passwordHash = await bcrypt.hash(password, saltRounds)
* The fundamentals of storing passwords: https://codahale.com/how-to-safely-store-a-password/
* The magic number of salt rounds: https://github.com/kelektiv/node.bcrypt.js/#a-note-on-rounds
* In test-driven development (TDD), tests for new functionality are written before the functionality is implemented.
  - https://en.wikipedia.org/wiki/Test-driven_development
* Mongoose does not have a built-in validator for checking the uniqueness of a field. Fortunately there is a ready-made solution for this, the mongoose-unique-validator library: https://www.npmjs.com/package/mongoose-unique-validator
* Install mongoose-unique-validator:
  npm install mongoose-unique-validator
* Use mongoose-unique-validator:
  const uniqueValidator = require('mongoose-unique-validator')
  ...
  const userSchema = mongoose.Schema({
    username: {
      type: String,
      required: true,
      unique: true
    },
    ...
  })
  userSchema.plugin(uniqueValidator)
* The user password should be never returned by any request!
* We would like our API to work in such a way, that when an HTTP GET request is made to the /api/users route, the user objects would also contain the contents of the user's notes and not just their id. In a relational database, this functionality would be implemented with a join query.
* Mongoose accomplishes the join by doing multiple queries, which is different from join queries in relational databases which are transactional, meaning that the state of the database does not change during the time that the query is made. With join queries in Mongoose, nothing can guarantee that the state between the collections being joined is consistent, meaning that if we make a query that joins the user and notes collections, the state of the collections may change during the query.
* Mongoose populate method: http://mongoosejs.com/docs/populate.html
  usersRouter.get('/', async (request, response) => {
    const users = await User.find({}).populate('notes')
    response.json(users)
  })
* The parameter given to the populate method defines that the ids referencing note objects in the notes field of the user document will be replaced by the referenced note documents.
* We can use the populate parameter for choosing the fields we want to include from the documents. In addition to the field id we are now only interested in content and important:
  usersRouter.get('/', async (request, response) => {
    const users = await User.find({}).populate('notes', { content: 1, important: 1 })
    response.json(users)
  })
* It's important to understand that the MongoDB database does not know that the ids stored in the user field of the notes collection reference documents in the user collection.
  - The functionality of the populate method of Mongoose is based on the fact that we have defined "types" to the references in the Mongoose schema with the ref option.
* Token-based authentication: https://www.digitalocean.com/community/tutorials/the-ins-and-outs-of-token-based-authentication#how-token-based-works
  1. User fills in login form with username and password
  2. Login button pressed
  3. HTTP POST /api/login {username, password}
  4. Backend generates a TOEK Nthat identifies the user
  5. TOKEN returned as message body
  6. Browser saves the TOKEN
  7. User creates a note
  8. Create note button pressed
  9. HTTP POST /api/notes {content} TOKEN in header
  10. Backend identifies the user from the TOKEN
  11. 201 created
* Install the jsonwebtoken library:
  npm install jsonwebtoken
* The code for login functionality goes to the file controllers/login.js.
* Check the user's password:
  const passwordCorrect = user === null ? false : await bcrypt.compare(password, user.passwordHash)
* If the user is not found, or the password is incorrect, the request is responded with the status code 401 unauthorized. The reason for the failure is explained in the response body:
  if (!(user && passwordCorrect)) {
    return response.status(401).json({
      error: 'invalid username or password'
    })
  }
* If the password is correct, a token is created with the method jwt.sign. The token contains the username and the user id in a digitally signed form:
  const userForToken = {
    username: user.username,
    id: user._id,
  }
  const token = jwt.sign(userForToken, process.env.SECRET)
* The token has been digitally signed using a string from the environment variable SECRET as the secret. The digital signature ensures that only parties who know the secret can generate a valid token. The value for the environment variable must be set in the .env file.
* A successful request is responded to with the status code 200 OK. The generated token and the username of the user are sent back in the response body:
  response
    .status(200)
    .send({ token, username: user.username, name: user.name })
* Limit the creation of new notes to logged-in users only.
* There are several ways of sending the token from the browser to the server. We will use the Authorization header. The header also tells which authentication scheme is used. This can be necessary if the server offers multiple ways to authenticate. Identifying the scheme tells the server how the attached credentials should be interpreted.
* The Bearer scheme: https://swagger.io/docs/specification/authentication/bearer-authentication/
* In practice, this means that if the token is, for example, the string eyJhbGciOiJIUzI1NiIsInR5c2VybmFtZSI6Im1sdXVra2FpIiwiaW, the Authorization header will have the value:
  Bearer eyJhbGciOiJIUzI1NiIsInR5c2VybmFtZSI6Im1sdXVra2FpIiwiaW
* Usage:
  const jwt = require('jsonwebtoken')
  const getTokenFrom = request => {
    const authorization = request.get('authorization')
    if (authorization && authorization.startsWith('Bearer ')) {
      return authorization.replace('Bearer ', '')
    }
    return null
  }
  ...
  const decodedToken = jwt.verify(getTokenFrom(request), process.env.SECRET)
  if (!decodedToken.id) {
    return response.status(401).json({ error: 'token invalid' })
  }
* If the token is missing or it is invalid, the exception JsonWebTokenError is raised. We need to extend the error handling middleware to take care of this particular case:
  else if (error.name ===  'JsonWebTokenError') {
    return response.status(401).json({ error: error.message })
  }
* If the object decoded from the token does not contain the user's identity (decodedToken.id is undefined), error status code 401 unauthorized is returned and the reason for the failure is explained in the response body.
* If the application has multiple interfaces requiring identification, JWT's validation should be separated into its own middleware. An existing library like express-jwt (https://www.npmjs.com/package/express-jwt) could also be used.
* Token authentication is pretty easy to implement, but it contains one problem. Once the API user, eg. a React app gets a token, the API has a blind trust to the token holder. What if the access rights of the token holder should be revoked?
  - The easier one is to limit the validity period of a token:
    // token expires in 60*60 seconds, that is, in one hour
    const token = jwt.sign(
      userForToken, 
      process.env.SECRET,
      { expiresIn: 60*60 }
    )
* The error handling middleware should be extended to give a proper error in the case of an expired token:
  else if (error.name === 'TokenExpiredError') {
    return response.status(401).json({
      error: 'token expired'
    })
  }
* The shorter the expiration time, the more safe the solution is. So if the token gets into the wrong hands or user access to the system needs to be revoked, the token is only usable for a limited amount of time. On the other hand, a short expiration time forces a potential pain to a user, one must login to the system more frequently.
* The other solution is to save info about each token to the backend database and to check for each API request if the access rights corresponding to the tokens are still valid. With this scheme, access rights can be revoked at any time. This kind of solution is often called a server-side session.
  - The negative aspect of server-side sessions is the increased complexity in the backend and also the effect on performance since the token validity needs to be checked for each API request to the database. Database access is considerably slower compared to checking the validity of the token itself. That is why it is quite common to save the session corresponding to a token to a key-value database such as Redis (https://redis.io/) that is limited in functionality compared to eg. MongoDB or relational database but extremely fast in some usage scenarios.
* When server-side sessions are used, the token is quite often just a random string, that does not include any information about the user as it is quite often the case when jwt-tokens are used. For each API request, the server fetches the relevant information about the identity of the user from the database. It is also quite usual that instead of using Authorization-header, cookies are used as the mechanism for transferring the token between the client and the server.
* Usernames, passwords and applications using token authentication must always be used over HTTPS: https://en.wikipedia.org/wiki/HTTPS
* Node HTTPS server: https://nodejs.org/api/https.html
* Node HTTP server: https://nodejs.org/docs/latest-v8.x/api/http.html
* Fly.io routes all traffic between a browser and the Fly.io server over HTTPS.
* Do not save passwords to the database as clear text, but use the bcrypt library.
* In case of problems with bcrypt on Windows, use bcryptjs instead: https://www.npmjs.com/package/bcryptjs
* If you used the same solution, refactor taking the token to a middleware. The middleware should take the token from the Authorization header and place it into the token field of the request object.
* In other words, if you register this middleware in the app.js file before all routes:
  app.use(middleware.tokenExtractor)
* A normal middleware function is a function with three parameters, that at the end calls the last parameter next to move the control to the next middleware:
  const tokenExtractor = (request, response, next) => {
    // code that extracts the token
    next()
  }
* If you want to compare the id of the object fetched from the database and a string id, a normal comparison operation does not work. The id fetched from the database must be parsed into a string first.
  if ( blog.user.toString() === userid.toString() ) ...
* It is possible to register a middleware only for a specific set of routes:
  1. All routes: app.use(middleware.userExtractor)
  2. Specific route: app.use('/api/blogs', middleware.userExtractor, blogsRouter)
  3. Specific operation: router.post('/', middleware.userExtractor, async (request, response) => { ... })
* How to set Authorization header to post request: https://github.com/ladjs/supertest/issues/398


Part 5: Testing React apps
--------------------------
* Install application dependencies from package.json:
  npm install
* Start the backend in development mode using a script in package.json:
  npm run dev
* Start the frontend in development mode using a script in package.json:
  npm run dev
* The event handlers are simple: An object is given to them as a parameter, and they destructure the field target from the object and save its value to the state.
  (event) => setUsername(event.target.value)
  ({ target }) => setUsername(target.value)
* Logical AND operator in React (https://react.dev/learn/conditional-rendering#logical-and-operator-). If user is null, then (&&) render the login form, otherwise, render nothing:
  { user === null && loginForm() }
* Truthy: https://developer.mozilla.org/en-US/docs/Glossary/Truthy
* Falsy: https://developer.mozilla.org/en-US/docs/Glossary/Falsy
* Conditional operator in React (https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Conditional_Operator). If user is null, then render the login form, otherwise, render the note form:
  { user === null ? loginForm() : noteForm() }
* Embed a JavaScript variable into a string using the `...` quotemarks:
  token = `Bearer ${newToken}`
* Create a new note:
  const create = async newObject => {
    const config = {
      headers: { Authorization: token },
    }
    const response = await axios.post(baseUrl, newObject, config)
    return response.data
  }
* async/await syntax (ES7)
* .then()/.error() (Promises) syntax (ES6)
* Use either async/await or .then()/.error() (Promises) syntax, never both mixed
* Save the token to the browser's local storage.
* Local Storage is a key-value database (https://en.wikipedia.org/wiki/Key-value_database) in the browser.
* Using the browser's local storage:
  window.localStorage.setItem('name', 'juha tauriainen')
  window.localStorage.getItem('name')
  window.localStorage.removeItem('name')
  window.localStorage.clear()  // clear local storage completely!
* Values in the local storage are persisted even when the page is re-rendered. The storage is origin-specific (https://developer.mozilla.org/en-US/docs/Glossary/Origin) so each web application has its own storage.
* Values saved to the storage are DOMstrings (https://docs.w3cub.com/dom/domstring), so we cannot save a JavaScript object as it is.
* The object has to be parsed to JSON first, with the method JSON.stringify. Correspondingly, when a JSON object is read from the local storage, it has to be parsed back to JavaScript with JSON.parse.
* Stringify a JavaScript object:
  JSON.stringify(userObject)
* Parse a JavaScript object:
  JSON.parse(userString)
* View localStorage on Chrome: https://developers.google.com/web/tools/chrome-devtools/storage/localstorage
* React API Reference: https://react.dev/reference/react
* An empty array as the parameter of the UseEffect() React hook ensures that the effect is executed only when the component is rendered for the first time:
  useEffect(() => { ... }, [])
  https://react.dev/reference/react/useEffect#parameters
* There are two solutions to cope with the situation when the API access of the token holder to the API needs to be revoked. The first one is to limit the validity period of a token. This forces the user to re-login to the app once the token has expired. The other approach is to save the validity information of each token to the backend database. This solution is often called a server-side session.
* Cross Site Scripting (XSS): https://owasp.org/www-community/attacks/xss/
* An XSS attack is possible if the application would allow a user to inject arbitrary JavaScript code (e.g. using a form) that the app would then execute. When using React sensibly it should not be possible since React sanitizes all text that it renders, meaning that it is not executing the rendered content as JavaScript.
  - https://legacy.reactjs.org/docs/introducing-jsx.html#jsx-prevents-injection-attacks
* If one wants to play safe, the best option is to not store a token in local storage. This might be an option in situations where leaking a token might have tragic consequences.
* It has been suggested that the identity of a signed-in user should be saved as httpOnly cookies, so that JavaScript code could not have any access to the token. The drawback of this solution is that it would make implementing SPA applications a bit more complex. One would need at least to implement a separate page for logging in.
  - https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#restrict_access_to_cookies
* However, it is good to notice that even the use of httpOnly cookies does not guarantee anything. It has even been suggested that httpOnly cookies are not any safer than the use of local storage.
  - https://academind.com/tutorials/localstorage-vs-cookies-xss/
* Minimize the rist of XSS: https://cheatsheetseries.owasp.org/cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html
* Visibility of the login form in App.jsx:
  const [loginVisible, setLoginVisible] = useState(false)
  ...
  const loginForm = () => {
    const hideWhenVisible = { display: loginVisible ? 'none' : '' }
    const showWhenVisible = { display: loginVisible ? '' : 'none' }
    return (
      <div>
        <div style={hideWhenVisible}>
          <button onClick={() => setLoginVisible(true)}>log in</button>
        </div>
        <div style={showWhenVisible}>
          <LoginForm ...
          ...
    )
  }
* CSS display property: https://developer.mozilla.org/en-US/docs/Web/CSS/display
* The "question mark" ternary operator: const hideWhenVisible = { display: loginVisible ? 'none' : '' }
* The code related to managing the visibility of the login form could be considered to be its own logical entity, and for this reason, it would be good to extract it from the App component into a separate component -> a new Togglable component.
  <Togglable buttonLabel="reveal">
    <p>this line is at start hidden</p>
    <p>also this is hidden</p>
  </Togglable>
* The contents above are children of Togglable.
  import { useState } from 'react'

  const Togglable = (props) => {
    const [visible, setVisible] = useState(false)

    const hideWhenVisible = { display: visible ? 'none' : '' }
    const showWhenVisible = { display: visible ? '' : 'none' }

    const toggleVisibility = () => {
      setVisible(!visible)
    }

    return (
      <div>
        <div style={hideWhenVisible}>
          <button onClick={toggleVisibility}>{props.buttonLabel}</button>
        </div>
        <div style={showWhenVisible}>
          {props.children}
          <button onClick={toggleVisibility}>cancel</button>
        </div>
      </div>
    )
  }

  export default Togglable
* props.children: https://react.dev/learn/passing-props-to-a-component#passing-jsx-as-children
  - Refers to the child components of the component
  - Unlike the "normal" props we've seen before, children is automatically added by React and always exists.
* Sometimes, you want the state of two components to always change together. To do it, remove state from both of them, move it to their closest common parent, and then pass it down to them via props. This is known as lifting state up, and it’s one of the most common things you will do writing React code.
* Sharing state between components: https://react.dev/learn/sharing-state-between-components
* Event handling can be done within the component, but the function to perform the task is given through props.
* The ref mechanism of React: https://react.dev/learn/referencing-values-with-refs
  import { useState, useEffect, useRef } from 'react'
  const App = () => {
    // ...
    const noteFormRef = useRef()
    const noteForm = () => (
      <Togglable buttonLabel='new note' ref={noteFormRef}>
        <NoteForm createNote={addNote} />
      </Togglable>
    )
    // ...
  }
* The useRef hook: https://react.dev/reference/react/useRef
* Togglable component:
  import { useState, forwardRef, useImperativeHandle } from 'react'
  const Togglable = forwardRef((props, refs) => {
    ...
    useImperativeHandle(refs, () => {
      return {
        toggleVisibility
      }
    })
    ...
* The function that creates the component is wrapped inside of a forwardRef (https://react.dev/reference/react/forwardRef) function call. This way the component can access the ref that is assigned to it.
* The useImperativeHandle hook: https://react.dev/reference/react/useImperativeHandle
* The useImperativeHandle function is a React hook, that is used for defining functions in a component, which can be invoked from outside of the component.
  - We could have accomplished the same functionality with slightly cleaner code using "old React" class-based components.
* Manipulating the DOM with refs: https://react.dev/learn/manipulating-the-dom-with-refs
* The updated full stack developer's oath:
  - I will have my browser developer console open all the time
  - I will use the network tab of the browser dev tools to ensure that frontend and backend are communicating as I expect
  - I will constantly keep an eye on the state of the server to make sure that the data sent there by the frontend is saved there as I expect
  - I will keep an eye on the database: does the backend save data there in the right format
  - I progress with small steps
  - When I suspect that there is a bug in the frontend, I make sure that the backend works for sure
  - When I suspect that there is a bug in the backend, I make sure that the frontend works for sure
  - I will write lots of console.log statements to make sure I understand how the code and the tests behave and to help pinpoint problems
  - If my code does not work, I will not write more code. Instead, I start deleting the code until it works or just return to a state when everything was still working
  - If a test does not pass, I make sure that the tested functionality for sure works in the application
* The sort method: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/sort
* The window.confirm function: https://developer.mozilla.org/en-US/docs/Web/API/Window/confirm
* Enforce that when the Togglable component is used, the button label text prop must be given a value.
* The expected and required props of a component can be defined with the prop-types package: https://github.com/facebook/prop-types
* Install prop-types:
  npm install prop-types
* We can define the buttonLabel prop as a mandatory or required string-type prop as shown below:
  import PropTypes from 'prop-types'
  const Togglable = React.forwardRef((props, ref) => {
    // ..
  })
  Togglable.propTypes = {
    buttonLabel: PropTypes.string.isRequired
  }
* It is extremely unprofessional to leave any red output in the browser console.
* the ESlint code style tool can be used both in the backend and the frontend.
* Vite has installed ESlint to the project by default, so all that's left for us to do is define our desired configuration in the .eslintrc.cjs file.
* Install eslint-plugin-jest for testing the frontnend: https://www.npmjs.com/package/eslint-plugin-jest
  npm install --save-dev eslint-plugin-jest
* Update .eslintrc.cjs with appropriate configurations.
* If you are using Visual Studio Code together with ESLint plugin, you might need to add a workspace setting for it to work. If you are seeing Failed to load plugin react: Cannot find module 'eslint-plugin-react' additional configuration is needed. Adding the line "eslint.workingDirectories": [{ "mode": "auto" }] to settings.json in the workspace seems to work. See here for more information: https://github.com/microsoft/vscode-eslint/issues/880#issuecomment-578052807
* Create .eslintignore (https://eslint.org/docs/user-guide/configuring#ignoring-files-and-directories) with the following content to skip certain files and directories:
  node_modules
  dist
  .eslintrc.cjs
* Perform linting in the frontend:
  npm run Lint
* Add a display name to the Togglable component to get rid of an error:
  Togglable.displayName = 'Togglable'
* In addition to Jes (http://jestjs.io/), we also need another testing library that will help us render components for testing purposes. The current best option for this is react-testing-library which has seen rapid growth in popularity in recent times.
* Install development dependencies:
  npm install --save-dev @testing-library/react @testing-library/jest-dom jest jest-environment-jsdom @babel/preset-env @babel/preset-react
* Update package.json as follows:
  {
    "scripts": {
      // ...
      "test": "jest"
    }
    // ...
    "jest": {
      "testEnvironment": "jsdom"
    }
  }
* Update .babelrc as follows:
  {
    "presets": [
      "@babel/preset-env",
      ["@babel/preset-react", { "runtime": "automatic" }]
    ]
  }
* Tests (e.g., Note.test.js) are written in the same directory as the component itself.
* Render the component using the render function: https://testing-library.com/docs/react-testing-library/api#render
  render(<Note note={note} />)
* Normally React components are rendered to the DOM. The render method we used renders the components in a format that is suitable for tests without rendering them to the DOM.
* We can use the object screen (https://testing-library.com/docs/queries/about#screen) to access the rendered component. 
* The getByText method: https://testing-library.com/docs/queries/bytext
  const element = screen.getByText('Component testing is done with react-testing-library')
  expect(element).toBeDefined()
* Run all frontend tests:
  npm run test
* The console may issue a warning if you have not installed Watchman. Watchman is an application developed by Facebook that watches for changes that are made to files. The program speeds up the execution of tests and at least starting from macOS Sierra, running tests in watch mode issues some warnings to the console, that can be removed by installing Watchman.
  - https://facebook.github.io/watchman/
* Two different conventions for the test file's location: https://medium.com/@JeffLombardJr/organizing-tests-in-jest-17fc431ff850
  - The current standard places them in the same directory as the component being tested. (configured by default in applications created by create-react-app)
  - The other convention is to store the test files "normally" in a separate test directory.
* Searching for content in a component:
  - using getByText: https://testing-library.com/docs/queries/bytext
  - using querySelector with CSS selectors: https://developer.mozilla.org/en-US/docs/Web/API/Document/querySelector and https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors
    const div = container.querySelector('.note')
  - using getByTestId with data attributes: https://testing-library.com/docs/queries/bytestid/ and https://developer.mozilla.org/en-US/docs/Web/HTML/Global_attributes/data-*
* Screen debugging: https://testing-library.com/docs/dom-testing-library/api-debugging#screendebug
  screen.debug()
  screen.debug(element)
* The user-event library allows to simulate user input: https://testing-library.com/docs/user-event/intro
* Install user-event:
  npm install --save-dev @testing-library/user-event
* Example of using user-event:
  import userEvent from '@testing-library/user-event'
  ...
  const mockHandler = jest.fn()
  render(
    <Note note={note} toggleImportance={mockHandler} />
  )
  const user = userEvent.setup()
  const button = screen.getByText('make not important')
  await user.click(button)
  expect(mockHandler.mock.calls).toHaveLength(1)
* Mock event handler function: https://facebook.github.io/jest/docs/en/mock-functions.html
* A session (https://testing-library.com/docs/user-event/setup/) is started to interact with the rendered component:
  const user = userEvent.setup()
* The click method: https://testing-library.com/docs/user-event/convenience/#click
* Mock objects and functions are commonly used stub components in testing that are used for replacing dependencies of the components being tested. Mocks make it possible to return hardcoded responses, and to verify the number of times the mock functions are called and with what parameters.
* Mock objects and functions: https://en.wikipedia.org/wiki/Mock_object
* The beforeEach function gets called before each test, which then renders the Togglable component and saves the field container of the return value.
* The toHaveStyle method for checking present CSS styles: https://www.npmjs.com/package/@testing-library/jest-dom#tohavestyle
* We can also simulate text input with the type method of the userEvent: https://testing-library.com/docs/user-event/utility#type
  await user.type(input, 'testing a form...')
* Get access to the input field using the function getByRole: https://testing-library.com/docs/queries/byrole
  const input = screen.getByRole('textbox')
  const inputs = screen.getAllByRole('textbox')
* Don't rely on the order of the input fields, but rather access them by their ID, placeholder text, or class name.
  const input = container.querySelector('#note-input')
* The getByPlaceHolderText method: https://testing-library.com/docs/queries/byplaceholdertext
  const input = screen.getByPlaceholderText('write note content here')
* The most flexible way of finding elements in tests is the method querySelector of the container object, which is returned by render.
* Command getByText looks for an element that has the same text that it has as a parameter, and nothing more. If we want to look for an element that contains the text, we could use an extra option:
  const element = screen.getByText('Does not work anymore :', { exact: false })
  const element = await screen.findByText('Does not work anymore :')
* It is important to notice that, unlike the other ByText commands, findByText returns a promise!
* There are situations where yet another form of the command queryByText is useful. The command returns the element but it does not cause an exception if the element is not found.
* We could eg. use the command to ensure that something is not rendered to the component:
  const element = screen.queryByText('do not want this thing to be rendered')
  expect(element).toBeNull()
* Test coverage: https://jestjs.io/blog/2020/01/21/jest-25#v8-code-coverage
  npm test -- --coverage --collectCoverageFrom='src/**/*.{jsx,js}'
* A quite primitive HTML report will be generated to the coverage/lcov-report directory. The report will tell us the lines of untested code in each component.
* Add CSS classes to the component to help the testing as necessary.
* Unit testing is useful at times, but even a comprehensive suite of unit tests is not enough to validate that the application works as a whole.
* Integration testing tests the collaboration of multiple components.
  - Backend + database
  - Frontend + API: Difficult as we would have to for example mock data from the server
* Types of testing:
  - Unit testing (one component, frontend or backend)
  - Integration testing (multiple components)
  - e2e/system testing (all components)
* Snapshot testing with Jest: https://facebook.github.io/jest/docs/en/snapshot-testing.html
* The interesting feature of snapshot testing is that developers do not need to define any tests themselves, it is simple enough to adopt snapshot testing.
  - The fundamental principle is to compare the HTML code defined by the component after it has changed to the HTML code that existed before it was changed.
* Snapshot tests notify the developer if the HTML code of the component changes. The developer has to tell Jest if the change was desired or undesired. If the change to the HTML code is unexpected, it strongly implies a bug, and the developer can become aware of these potential issues easily thanks to snapshot testing.
* System testing: https://en.wikipedia.org/wiki/System_testing
  - Selenium: http://www.seleniumhq.org/
  - Headless browsers (e.g. Chrome in headless mode): https://en.wikipedia.org/wiki/Headless_browser
* E2E tests are potentially the most useful category of tests because they test the system through the same interface as real users use.
* Configuring E2E tests is more challenging than unit or integration tests. They also tend to be quite slow, and with a large system, their execution time can be minutes or even hours. This is bad for development because during coding it is beneficial to be able to run tests as often as possible in case of code regressions (https://en.wikipedia.org/wiki/Regression_testing).
* Flaky (unreliable) e2e tests: https://hackernoon.com/flaky-tests-a-war-that-never-ends-9aa32fdef359
* End to end testing with Cypress: https://www.cypress.io/
* Cypress tests are run completely within the browser. Other libraries run the tests in a Node process, which is connected to the browser through an API.
* Install Cypress in the frontend:
  npm install --save-dev cypress
* Configure Cypress in package.json:
  {
    // ...
    "scripts": {
      "dev": "vite --host",
      // ...
      "cypress:open": "cypress open"
    },
    // ...
  }
* Without '--host', Cypress can not access the app.
* Unlike the frontend's unit tests, Cypress tests can be in the frontend or the backend repository, or even in their separate repository.
* The tests require the tested system to be running. Unlike our backend integration tests, Cypress tests do not start the system when they are run!!!
  - Terminal 1: Start frontend
  - Terminal 2: Start backend
  - Terminal 3: Start tests
* Add an npm script to the backend package.json, which starts it in test mode, or so that NODE_ENV is test:
  "start:test": "NODE_ENV=test node index.js"
* Start Cypress:
  npm run cypress:open
  > E2E Testing > Create new spec > test file cypress/e2e/note_app.cy.js
* Running a test shows how the application behaves in real-time as the test is run.
* The structure of the test should look familiar. They use describe blocks to group different test cases, just like Jest. The test cases have been defined with the it method. Cypress borrowed these parts from the Mocha (https://mochajs.org/) testing library it uses under the hood.
* cy.visit command: https://docs.cypress.io/api/commands/visit
* cy.contains command: https://docs.cypress.io/api/commands/contains
* cy.click command: https://docs.cypress.io/api/commands/click
* cy.get command: https://docs.cypress.io/api/commands/get
* cy.type command: https://docs.cypress.io/api/commands/type
* cy.request command: https://docs.cypress.io/api/commands/request
* cy.should command: https://docs.cypress.io/api/commands/should
* cy.parent command: https://docs.cypress.io/api/commands/parent
* cy.find command: https://docs.cypress.io/api/commands/find
* cy.as command: https://docs.cypress.io/api/commands/as
* cy.then command: https://docs.cypress.io/api/commands/then
* cy.eq command: https://docs.cypress.io/api/commands/eq
* Do not use arrow functions with Cypress as Mocha warns they might cause some issues in certain situations: https://mochajs.org/#arrow-functions
* Install eslint-plugin-cypress to get rid of Visual Studio Code linting errors:
  npm install eslint-plugin-cypress --save-dev
* Update .eslintrc.cjs:
  "env": {
    "cypress/globals": true,
    ...
  },
  "plugins": ["react", "jest", "cypress"],
* Example test:
  describe('Note app', function() {
    beforeEach(function() {
      cy.visit('http://localhost:5173')
    })
    it('user can login', function () {
      cy.contains('log in').click()
      cy.get('input:first').type('mluukkai')
      cy.get('input:last').type('salainen')
    })
  })
* Give our inputs unique ids and use those to find them.
  cy.get('#login-button').click()
* Cypress runs the tests in the order they are in the code.
* If the tests need to be able to modify the server's database, the situation immediately becomes more complicated. Ideally, the server's database should be the same each time we run the tests, so our tests can be reliably and easily repeatable.
* As with unit and integration tests, with E2E tests it is best to empty the database and possibly format it before the tests are run. The challenge with E2E tests is that they do not have access to the database.
* The solution is to create API endpoints for the backend tests. We can empty the database using these endpoints. Let's create a new router for the tests inside the controllers folder, in the testing.js file
  const testingRouter = require('express').Router()
  const Note = require('../models/note')
  const User = require('../models/user')

  testingRouter.post('/reset', async (request, response) => {
    await Note.deleteMany({})
    await User.deleteMany({})

    response.status(204).end()
  })

  module.exports = testingRouter
* Add it to the backend App.jsx *only if* the application is run in test-mode:
  if (process.env.NODE_ENV === 'test') {
    const testingRouter = require('./controllers/testing')
    app.use('/api/testing', testingRouter)
  }
* After the changes, an HTTP POST request to the /api/testing/reset endpoint empties the database. Make sure your backend is running in test mode by starting it with this command (previously configured in the package.json file):
  npm run start:test
* Reset the database in a Cypress test:
  cy.request('POST', 'http://localhost:3001/api/testing/reset')
* When developing a new test or when debugging a broken test, we can define the test with it.only instead of it, so that Cypress will only run the required test. When the test is working, we can remove .only:
  it.only('login fails with wrong password', function() {
    // ...
  })
* A list of most common assertions: https://docs.cypress.io/guides/references/assertions.html#Common-Assertions
* Examples of using should:
  cy.get('.error').should('contain', 'wrong credentials') 
  cy.get('.error').should('have.css', 'color', 'rgb(255, 0, 0)')
  cy.get('.error').should('have.css', 'border-style', 'solid')
* Cypress requires the colors to be given as rgb: https://rgbcolorcode.com/color/red
* Chaining with and: https://docs.cypress.io/api/commands/and.html
  cy.get('.error')
    .should('contain', 'wrong credentials')
    .and('have.css', 'color', 'rgb(255, 0, 0)')
    .and('have.css', 'border-style', 'solid')
* The command should is most often used by chaining it after the command get (or another similar command that can be chained).
  cy.get('html').should('not.contain', 'Matti Luukkainen logged in')
  cy.contains('Matti Luukkainen logged in').should('not.exist')
* The cy.get('html') used in the test practically means the visible content of the entire application.
* Note: Some CSS properties behave differently on Firefox: https://github.com/cypress-io/cypress/issues/9349
* Each test starts from zero! Tests do not start from the state where the previous tests ended.
* Fully test the login flow – but only once. So instead of logging in a user using the form in the beforeEach block, Cypress recommends that we bypass the UI and do an HTTP request to the backend to log in. The reason for this is that logging in with an HTTP request is much faster than filling out a form.
  - https://docs.cypress.io/guides/end-to-end-testing/testing-your-app#Fully-test-the-login-flow-but-only-once
  - https://docs.cypress.io/guides/getting-started/testing-your-app.html#Bypassing-your-UI
* Under the hood cy.request, like all Cypress commands, are promises.
  cy.request('POST', 'http://localhost:3001/api/login', {
      username: 'mluukkai', password: 'salainen'
    }).then(response => {
      localStorage.setItem('loggedNoteappUser', JSON.stringify(response.body))
      cy.visit('http://localhost:5173')
    })
* Custom Cypress commands: https://docs.cypress.io/api/cypress-api/custom-commands.html
* Define custom commands in cypress/support/commands.js. For example:
  Cypress.Commands.add('login', ({ username, password }) => {
    cy.request('POST', 'http://localhost:3001/api/login', {
      username, password
    }).then(({ body }) => {
      localStorage.setItem('loggedNoteappUser', JSON.stringify(body))
      cy.visit('http://localhost:5173')
    })
  })
* Using the above custom command:
  cy.login({ username: 'mluukkai', password: 'salainen' })
* Define the baseUrl for the application in the Cypress pre-generated configuration file cypress.config.js: https://docs.cypress.io/guides/references/configuration
  const { defineConfig } = require("cypress")
  module.exports = defineConfig({
    e2e: {
      setupNodeEvents(on, config) {...},
      baseUrl: 'http://localhost:5173',
      env: {
        BACKEND: 'http://localhost:3001/api'
      }
    },
  })
* All the commands in the tests use the address of the application can be transformed as follows:
  - From: cy.visit('http://localhost:5173' )
  - To: cy.visit('')
* Environment variables in Cypress: https://docs.cypress.io/guides/guides/environment-variables
* Cypress documentation recommends defining other addresses such as backend URL used by the tests as environment variables.
* Examples of use of the environment variables in Cypress:
  cy.request('POST', `${Cypress.env('BACKEND')}/testing/reset`)
  cy.request('POST', `${Cypress.env('BACKEND')}/users`, user)
* Cypress Test Runner: https://docs.cypress.io/guides/core-concepts/test-runner.html
  - Interactive, i.e., allow to select specific test phases and see how the UI looks like at the point of time.
* When coding tests, you should visually check in the test runner that the tests use the right components!
* cy.get here always searches from the whole page, but cy.find starts from the given element:
  cy.contains('second note').parent().find('button').click()
* Use the as command to create reusable, named elements:
  cy.contains('second note').parent().find('button').as('theButton')
  cy.get('@theButton').click()
  cy.get('@theButton').should('contain', 'make not important')
* When Cypress runs a test, it adds each cy command to an execution queue. When the code of the test method has been executed, Cypress will execute each command in the queue one by one.
* Cypress commands always return undefined.
* An attempt to start the debugger would not stop the code between executing the commands, but before any commands have been executed.
* Cypress commands are like promises, so if we want to access their return values, we have to do it using the then command.
  it('then example', function() {
    cy.get('button').then( buttons => {
      console.log('number of buttons', buttons.length)
      cy.wrap(buttons[0]).click()
    })
  })
* Stopping the test execution with the debugger is possible. The debugger starts only if Cypress test runner's developer console is open.
  - https://docs.cypress.io/api/commands/debug.html
* Cypress command line: https://docs.cypress.io/guides/guides/command-line.html
* Update scripts to include Cypress command line:
  "test:e2e": "cypress run"
* Videos of the test execution will be saved to cypress/videos/, so you should probably git ignore this directory. It is also possible to turn off the making of videos: https://docs.cypress.io/guides/guides/screenshots-and-videos#Videos
* Cypress documentation: https://docs.cypress.io/guides/overview/why-cypress.html#In-a-nutshell
  - Introduction to Cypress: https://docs.cypress.io/guides/core-concepts/introduction-to-cypress.html#Cypress-Can-Be-Simple-Sometimes
* Note that you might end up having problems if you click a like button many times in a row. It might be that cypress does the clicking so fast that it does not have time to update the app state in between the clicks. One remedy for this is to wait for the number of likes to update in between all clicks.
* Manipulate likes:
  cy.get('.blog').contains(lastBlog.title).parent().as('lastBlog')
  const nClicks = 4
  for (let i = 1; i <= nClicks; i++) {
    cy.get('@lastBlog').contains('like').click().then(response => {
      cy.get('@lastBlog').contains(`likes ${_.last(expectedInitialLikes) + i}`)
    })
  }
* Check each blog:
  cy.get('.blog').each(($el, index) => {
    cy.wrap($el).as('blog')
    cy.get('@blog').contains('view').click()
    cy.get('@blog').contains(`likes ${expectedInitialLikes[index]}`)
  })


Part 6: Advanced state management
---------------------------------
* When applications grow larger, state management should be moved outside React components using for instance the Redux library.
* Redux is the most popular solution for managing the state of React applications.
* React state management conventions recommend to place the state and the functions for handling it in higher level of the component structure of the application.
  https://react.dev/learn/sharing-state-between-components
* Quite often most of the app state and state altering functions reside directly in the root component. The state and its handler methods have then been passed to other components with props. This works up to a certain point, but when applications grow larger, state management becomes challenging.
* Facebook's Flux-architecture makes state management of React apps easier.
  https://facebookarchive.github.io/flux/docs/in-depth-overview
* In Flux, the state is separated from the React components and into its own stores. State in the store is not changed directly, but with different actions.
* When an action changes the state of the store, the views are rerendered:
  Action -> Dispatcher -> Store -> View
* If some action on the application, for example pushing a button, causes the need to change the state, the change is made with an action. This causes re-rendering the view again:
  Action 1 -> Dispatcher -> Store -> View -> Action 2 -> Dispatcher -> ...
* Flux offers a standard way for how and where the application's state is kept and how it is modified.
* The Redux library replaces Flux, also at Facebook: https://redux.js.org/
* Install Redux:
  npm install redux
* As in Flux, in Redux the state is also stored in a store:
  https://redux.js.org/basics/store
* The whole state of the application is stored in one JavaScript object in the store.
  - If the state is complicated, different things in the state would be saved as separate fields of the object.
* The state of the store is changed with actions (https://redux.js.org/basics/actions). Actions are objects, which have at least a field determining the type of the action. If there is data involved with the action, other fields can be declared as needed.
  {
    type: 'INCREMENT'
  }
* The impact of the action to the state of the application is defined using a reducer. In practice, a reducer is a function that is given the current state and an action as parameters. It returns a new state.
  const counterReducer = (state = 0, action) => {
    switch (action.type) {
      case 'INCREMENT':
        return state + 1
      case 'DECREMENT':
        return state - 1
      case 'ZERO':
        return 0
      default: // if none of the above matches, code comes here
        return state
    }
  }
* The first parameter is the state in the store. The reducer returns a new state based on the action type. So, e.g. when the type of Action is INCREMENT, the state gets the old value plus one. If the type of Action is ZERO the new value of state is zero.
* The switch statement (https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/switch) is the most common approach to writing a reducer.
* Reducer is never supposed to be called directly from the application's code. Reducer is only given as a parameter to the createStore-function which creates the store:
  import { createStore } from 'redux'
  const counterReducer = (state = 0, action) => {
    // ...
  }
  const store = createStore(counterReducer)
* The store now uses the reducer to handle actions, which are dispatched or 'sent' to the store with its dispatch method (https://redux.js.org/api/store#dispatchaction).
  store.dispatch({ type: 'INCREMENT' })
* You can find out the state of the store using the method getState: https://redux.js.org/api/store#getstate
  console.log(store.getState())
* The third important method the store has is subscribe (https://redux.js.org/api/store#subscribelistener), which is used to create callback functions the store calls whenever an action is dispatched to the store.
* Print every change in the store to the console:
  store.subscribe(() => {
    const storeNow = store.getState()
    console.log(storeNow)
  })
* When the state in the store is changed, React is not able to automatically rerender the application. Thus we have registered a function renderApp, which renders the whole app, to listen for changes in the store with the store.subscribe method.
  const renderApp = () => {
    root.render(<App />)
  }
  renderApp()
  store.subscribe(renderApp)
* We have to immediately call the renderApp method. Without the call, the first rendering of the app would never happen.
* Instead of the function createStore, it is recommended to use the slightly more "advanced" function configureStore, and we will also use it when we have achieved the basic functionality of Redux.
  https://redux.js.org/introduction/why-rtk-is-redux-today
* "deprecated" createStore() vs. recommended configureStore() in Redux: https://stackoverflow.com/questions/71944111/redux-createstore-is-deprecated-cannot-get-state-from-getstate-in-redux-ac
* The general convention is that actions have exactly two fields, type telling the type and payload containing the data included with the Action.
* The following reducer breaks the basic assumption of Redux reducer that reducers must be pure functions: https://en.wikipedia.org/wiki/Pure_function
  const noteReducer = (state = [], action) => {
    if (action.type === 'NEW_NOTE') {
      state.push(action.payload)  // BAD!!!
      return state
    }
    return state
  }
* Pure functions are such, that they do not cause any side effects and they must always return the same response when called with the same parameters.
* We added a new note to the state with the method state.push(action.payload) which changes the state of the state-object. This is not allowed. The problem is easily solved by using the concat method, which creates a new array, which contains all the elements of the old array and the new element:
  const noteReducer = (state = [], action) => {
    if (action.type === 'NEW_NOTE') {
      return state.concat(action.payload)
    }
    return state
  }
* A reducer state must be composed of immutable (https://en.wikipedia.org/wiki/Immutable_object) objects. If there is a change in the state, the old object is not changed, but it is replaced with a new, changed, object. This is exactly what we did with the new reducer: the old array is replaced with the new one.
* Install Jest (+ edit .babelrc, package.json, and .eslintrc.cjs):
  npm install --save-dev jest @babel/preset-env @babel/preset-react eslint-plugin-jest
* The "rc" part in for example .babelrc stands for "runcom", which I believe can be expanded to "run commands". In fact, this is exactly what the file contains, commands that bash should run.
* Difference between .js, .cjs, and .mjs: https://dev.to/nipu/js-cjs-and-mjs-defference-5f21#:~:text=CommonJS%20is%20a%20module%20system,exports%20syntax.
  - .js (JavaScript)
  - .cjs (CommonJS, require and module.exports)
  - .mjs (ECMAScript Modules, import and export)
* The deep-freeze library (https://www.npmjs.com/package/deep-freeze) can be used to ensure that the reducer has been correctly defined as an immutable function.
* Install deep-freeze:
  npm install --save-dev deep-freeze
* Move each reducer's code to its own module file. For example, src/reducers/noteReducer.js
* The deepFreeze(state) command ensures that the reducer does not change the state of the store given to it as a parameter. If the reducer uses the push command to manipulate the state, the test will not pass.
* The JavaScript array spread syntax: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Spread_operator
  - The same result as using the Array's conat function.
  - Example:
    const numbers = [1, 2, 3]
    [...numbers, 4, 5] // [1, 2, 3, 4, 5]
    [numbers, 4, 5]    // [[1, 2, 3], 4, 5]
* The JavaScript array destructing syntax: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment
  const numbers = [1, 2, 3, 4, 5, 6]
  const [first, second, ...rest] = numbers
  console.log(first)  // prints 1
  console.log(second) // prints 2
  console.log(rest)   // prints [3, 4, 5, 6]
* It is noteworthy that we have not bound the state of the form fields to the state of the App component like we have previously done. React calls this kind of form uncontrolled.
  https://react.dev/reference/react-dom/components/input#controlling-an-input-with-a-state-variable
  https://goshakkk.name/controlled-vs-uncontrolled-inputs-react/
* Uncontrolled forms have certain limitations (for example, dynamic error messages or disabling the submit button based on input are not possible).
* Because the field has a name, we can access the content via the event object event.target.note.value.
  <form onSubmit={addNote}>
        <input name="note" />
* React components don't need to know the Redux action types and forms. Let's separate creating actions into separate functions.
* Functions that create actions are called action creators:
  https://redux.js.org/tutorials/fundamentals/part-7-standard-patterns#action-creators
* The App component does not have to know anything about the inner representation of the actions anymore, it just gets the right action by calling the creator function:
  const App = () => {
    const toggleImportance = (id) => {
     store.dispatch(toggleImportanceOf(id))
    }
* There are multiple ways to share the Redux store with components. First, we will look into the newest, and possibly the easiest way is using the hooks API of the react-redux library.
  - The hooks API: https://react-redux.js.org/api/hooks
  - React Redux library: https://react-redux.js.org/
* Install react-redux:
  npm install react-redux
* Usage of react-redux:
  import { Provider } from 'react-redux'
  // ...
  ReactDOM.createRoot(document.getElementById('root')).render(
    <Provider store={store}>
      <App />
    </Provider>
  )
* The application is now defined as a child of a Provider (https://react-redux.js.org/api/provider) component provided by the react-redux library. The application's store is given to the Provider as its attribute store.
* Defining the action creators has been moved to the file reducers/noteReducer.js where the reducer is defined.
  // ...
  export const toggleImportanceOf = (id) => {
    return {
      type: 'TOGGLE_IMPORTANCE',
      payload: { id }
    }
  }
  export default noteReducer
* The module now has multiple export commands:
  https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/export
* If the application has many components which need the store, the App component must pass store as props to all of those components.
* A module can have only one default export, but multiple "normal" exports:
  export const createNote = (content) => {
    // ...
  }

  export const toggleImportanceOf = (id) => { 
    // ...
  }
* Normally (not as defaults) exported functions can be imported with the curly brace syntax:
  import { createNote } from './../reducers/noteReducer'
* Previously the code dispatched actions by calling the dispatch method of the Redux store. Now it does it with the dispatch function from the useDispatch hook:
  import { useSelector, useDispatch } from 'react-redux'
  const App = () => {
    const dispatch = useDispatch()
    // ...
    const toggleImportance = (id) => {
      dispatch(toggleImportanceOf(id))
    }
    // ...
  }
* The useDispatch hook provides any React component access to the dispatch function of the Redux store defined in main.jsx. This allows all components to make changes to the state of the Redux store.
* The component can access the notes stored in the store with the useSelector-hook (https://react-redux.js.org/api/hooks#useselector) of the react-redux library.
  import { useSelector, useDispatch } from 'react-redux'
  const App = () => {
    // ...
    const notes = useSelector(state => state) // return the whole state
    // ...
  }
* useSelector receives a function as a parameter. The function either searches for or selects data from the Redux store.
  (state) => { return state }
* Usually, selector functions are a bit more interesting and return only selected parts of the contents of the Redux store. We could for example return only notes marked as important:
  const importantNotes = useSelector(state => state.filter(note => note.important))
* Unlike in the React code we did without Redux, the event handler for changing the state of the app (which now lives in Redux) has been moved away from the App to a child component.
* The logic for changing the state in Redux is still neatly separated from the whole React part of the application.
* Note, responsible for rendering a single note, is very simple and is not aware that the event handler it gets as props dispatches an action. These kinds of components are called presentational in React terminology.
  https://medium.com/@dan_abramov/smart-and-dumb-components-7ca2f9a7c7d0
  const Note = ({ note, handleClick }) => {
    return(
      // ...
    )
  }
* Notes, on the other hand, is a container component, as it contains some application logic: it defines what the event handlers of the Note components do and coordinates the configuration of presentational components, that is, the Notes.
  https://medium.com/@dan_abramov/smart-and-dumb-components-7ca2f9a7c7d0
  const Notes = () => {
    const dispatch = useDispatch()
    const notes = useSelector(state => state)
    return(
      // ...
    )
  }
* Presentational components: Are concerned with how things look.
* Container components: Are concerned with how things work.
* In the case of the state object having many properties (e.g., {notes: [...], filter: 'IMPORTANT'}), it is good to define separate reducers for the state of different properties.
* const filterReducer = (state = 'ALL', action) => {
    switch (action.type) {
      case 'SET_FILTER':
        return action.payload
      default:
        return state
    }
  }
* The data structure of a reducer's return value needs to match the given initial state.
* We can create the actual reducer for our application by combining the two existing reducers with the combineReducers function: https://redux.js.org/api/combinereducers
  import { createStore, combineReducers } from 'redux'
  import { Provider } from 'react-redux' 
  import App from './App'
  import noteReducer from './reducers/noteReducer'
  import filterReducer from './reducers/filterReducer'
  const reducer = combineReducers({
    notes: noteReducer,
    filter: filterReducer
  })
  const store = createStore(reducer)
* By simulating the creation of a note and changing the state of the filter in this fashion, the state of the store gets logged to the console after every change that is made to the store:
  store.subscribe(() => console.log(store.getState()))
* Important: The combined reducer works in such a way that every action gets handled in every part of the combined reducer. Typically only one reducer is interested in any given action, but there are situations where multiple reducers change their respective parts of the state based on the same action.
* Return notes from a specific property of the combined state object:
  const notes = useSelector(state => state.notes)
* Return filtered notes:
  const notes = useSelector(({ filter, notes }) => {
    if ( filter === 'ALL' ) {
      return notes
    }
    return filter  === 'IMPORTANT' 
      ? notes.filter(note => note.important)
      : notes.filter(note => !note.important)
  })
* Redux's configuration and state management implementation requires quite a lot of effort. This is manifested for example in the reducer and action creator-related code which has somewhat repetitive boilerplate code.
* Redux Toolkit (https://redux-toolkit.js.org/) is a library that solves these common Redux-related problems. The library for example greatly simplifies the configuration of the Redux store and offers a large variety of tools to ease state management.
* Install Redux Toolkit:
  npm install @reduxjs/toolkit
* Instead of Redux's createStore function, let's create the store using Redux Toolkit's configureStore function: https://redux-toolkit.js.org/api/configureStore
  import { configureStore } from '@reduxjs/toolkit'
  const store = configureStore({
    reducer: {
      notes: noteReducer,
      filter: filterReducer
    }
  })
* With the Redux Toolkit, we don't need the combineReducers function to create the reducer for the store. We will soon see that the configureStore function has many additional benefits such as the effortless integration of development tools and many commonly used libraries without the need for additional configuration.
* With Redux Toolkit, we can easily create reducer and related action creators using the createSlice function. We can use the createSlice function to refactor the reducer and action creators in the reducers/noteReducer.js file in the following manner:
  import { createSlice } from '@reduxjs/toolkit'
  const noteSlice = createSlice({
    name: 'notes',
    initialState,
    reducers: {
      createNote(state, action) {
        const content = action.payload
        state.push({
          content,
          important: false,
          id: generateId(),
        })
      },
      toggleImportanceOf(state, action) {
        const id = action.payload
        const noteToChange = state.find(n => n.id === id)
        const changedNote = { 
          ...noteToChange, 
          important: !noteToChange.important 
        }
        return state.map(note =>
          note.id !== id ? note : changedNote 
        )     
      }
    },
  })
* The createSlice function's name parameter defines the prefix which is used in the action's type values. For example, the createNote action defined later will have the type value of notes/createNote. It is a good practice to give the parameter a value which is unique among the reducers. This way there won't be unexpected collisions between the application's action type values. The initialState parameter defines the reducer's initial state. The reducers parameter takes the reducer itself as an object, of which functions handle state changes caused by certain actions. Note that the action.payload in the function contains the argument provided by calling the action creator:
  dispatch(createNote('Redux Toolkit is awesome!'))
* This dispatch call responds to dispatching the following object:
  dispatch({ type: 'notes/createNote', payload: 'Redux Toolkit is awesome!' })
* Redux Toolkit utilizes the Immer library with reducers created by createSlice function, which makes it possible to mutate the state argument inside the reducer. Immer uses the mutated state to produce a new, immutable state and thus the state changes remain immutable. Note that state can be changed without "mutating" it, as we have done with the toggleImportanceOf action. In this case, the function returns the new state. Nevertheless mutating the state will often come in handy especially when a complex state needs to be updated.
  createNote(state, action) {
    const content = action.payload
    state.push({ // normally this would violate the reducers' immutability principle, but here it is ok as we are using Redux Toolkit
      content,
      important: false,
      id: generateId(),
    })
  }
* The createSlice function returns an object containing the reducer as well as the action creators defined by the reducers parameter. The reducer can be accessed by the noteSlice.reducer property, whereas the action creators by the noteSlice.actions property. We can produce the file's exports in the following way:
  const noteSlice = createSlice(/* ... */)
  export const { createNote, toggleImportanceOf } = noteSlice.actions
  export default noteSlice.reducer
* We need to alter the action type names in the tests due to the conventions of ReduxToolkit:
  type: 'NEW_NOTE' -> type: 'notes/createNote'
* Print Redux Toolkit state to the console within reducers:
  console.log(JSON.parse(JSON.stringify(state)))
* Redux DevTools (https://chrome.google.com/webstore/detail/redux-devtools/lmhkpmbekcpmknklioeibfkpmmfibljd) is a Chrome addon that offers useful development tools for Redux. It can be used for example to inspect the Redux store's state and dispatch actions through the browser's console.
* When the store is created using Redux Toolkit's configureStore function, no additional configuration is needed for Redux DevTools to work.
* Install json-server:
  npm install json-server --save-dev
* Run the json-server:
  npm run server
* Install Axios:
  npm install axios
* Dispatching multiple actions seems a bit impractical. Let's add an action creator setNotes which can be used to directly replace the notes array.
  const noteSlice = createSlice({
    name: 'notes',
    initialState: [],
    reducers: {
      setNotes(state, action) {
        return action.payload
      }
      // ...
* Initialize the notes state based on the data received from the server (main.jsx):
  import noteReducer, { setNotes } from './reducers/noteReducer'
  // ...
  noteService.getAll().then(notes =>
    store.dispatch(setNotes(notes))
  )
* Await only works inside async functions, and the code in main.jsx is not inside a function, so due to the simple nature of the operation, we'll abstain from using async this time.
* Move the initialization of the notes into the App component, and, as usual, when fetching data from a server, we'll use the effect hook:
  import { useEffect } from 'react'
  // ...
  import noteService from './services/notes'
  import { setNotes } from './reducers/noteReducer'
  import { useDispatch } from 'react-redux'

  const App = () => {

    const dispatch = useDispatch()
    useEffect(() => {
      noteService
        .getAll().then(notes => dispatch(setNotes(notes)))
    }, [dispatch]) // note the added dispatch!!!
    // ...
* Abstract away the communication with the server from the components so that they don't have to do anything else but call the appropriate action creator. 
  const NewNote = () => {
    const dispatch = useDispatch()    
    const addNote = async (event) => {
      event.preventDefault()
      const content = event.target.note.value
      event.target.note.value = ''
      dispatch(createNote(content)) // !!!
    }
    // ...
  }
* In this implementation, both components would dispatch an action without the need to know about the communication between the server that happens behind the scenes.
* These kinds of async actions can be implemented using the Redux Thunk library (https://github.com/reduxjs/redux-thunk). The use of the library doesn't need any additional configuration or even installation when the Redux store is created using the Redux Toolkit's configureStore function.
* With Redux Thunk it is possible to implement action creators which return a function instead of an object. The function receives Redux store's dispatch and getState methods as parameters. This allows for example implementations of asynchronous action creators, which first wait for the completion of a certain asynchronous operation and after that dispatch some action, which changes the store's state.
* The solution is elegant. The initialization logic for the notes has been completely separated from the React component.
  export const createNote = content => {
    return async dispatch => {
      const newNote = await noteService.createNew(content)
      dispatch(appendNote(newNote))
    }
  }
* First, an asynchronous operation is executed, after which the action changing the state of the store (appendNote) is dispatched.
* Redux Toolkit offers a multitude of tools to simplify asynchronous state management. Suitable tools for this use case are for example the createAsyncThunk function and the RTK Query API.
  - createAsyncThunk: https://redux-toolkit.js.org/api/createAsyncThunk
  - RTK Query API: https://redux-toolkit.js.org/rtk-query/overview
* The React Query library is an alternative way to store and manage data retrieved from the server. The latest version of the library is also called TanStack Query, but we stick to the familiar name.
* Install React Query:
  npm install @tanstack/react-query
* Usage React Query in main.jsx:
  import { QueryClient, QueryClientProvider } from '@tanstack/react-query'
  import App from './App'
  const queryClient = new QueryClient()
  ReactDOM.createRoot(document.getElementById('root')).render(
    <QueryClientProvider client={queryClient}>
      <App />
    </QueryClientProvider>
  )
* Data retrieval example:
  import { useQuery } from '@tanstack/react-query'
  import axios from 'axios'
  const App = () => {
    // ...
    const result = useQuery({
      queryKey: ['notes'],
      queryFn: () => axios.get('http://localhost:3001/notes').then(res => res.data)
    })
    console.log(JSON.parse(JSON.stringify(result)))
    if ( result.isLoading ) {
      return <div>loading data...</div>
    }
    const notes = result.data
    return (
      // ...
    )
  }
* The Axios method call is now wrapped in a query (https://tanstack.com/query/latest/docs/react/guides/queries) formed with the useQuery function (https://tanstack.com/query/latest/docs/react/reference/useQuery). The first parameter of the function call is a string notes which acts as a key (https://tanstack.com/query/latest/docs/react/guides/query-keys) to the query defined, i.e. the list of notes.
* The return value of the useQuery function is an object that indicates the status of the query.
* The first time the component is rendered, the query is still in loading state, i.e. the associated HTTP request is pending.
* When the request is completed, the component is rendered again. The query is in the state success on the second rendering, and the field data of the query object contains the data returned by the request, i.e. the list of notes that is rendered on the screen.
* So the application retrieves data from the server and renders it on the screen without using the React hooks useState and useEffect used in chapters 2-5 at all. The data on the server is now entirely under the administration of the React Query library, and the application does not need the state defined with React's useState hook at all!
* To create a new note, a mutation (https://tanstack.com/query/latest/docs/react/guides/mutations) is defined using the function useMutation (https://tanstack.com/query/latest/docs/react/reference/useMutation):
  const newNoteMutation = useMutation({ mutationFn: createNote })
* The parameter is the function we added to the file requests.js, which uses Axios to send a new note to the server.
* The event handler addNote performs the mutation by calling the mutation object's function mutate and passing the new note as a parameter:
  newNoteMutation.mutate({ content, important: true })
* In order to render a new note as well, we need to tell React Query that the old result of the query whose key is the string notes should be invalidated (https://tanstack.com/query/latest/docs/react/guides/invalidations-from-mutations).
  import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query'
  import { getNotes, createNote } from './requests'
  const App = () => {
    const queryClient = useQueryClient()
    const newNoteMutation = useMutation({
      mutationFn: createNote, 
      onSuccess: () => {
        queryClient.invalidateQueries({ queryKey: ['notes'] })
      },
    })
    // ...
  }
* When we change the importance of a note, invalidating the query notes is enough for the application data to be updated:
  onSuccess: () => {
    queryClient.invalidateQueries('notes')
  },
* The consequence of this, of course, is that after the PUT request that causes the note change, the application makes a new GET request to retrieve the query data from the server:
* If necessary, it is also possible to optimize performance by manually updating the query state maintained by React Query.
  https://tanstack.com/query/latest/docs/react/guides/updates-from-mutation-responses
  onSuccess: (newNote) => {
    const notes = queryClient.getQueryData(['notes'])
    queryClient.setQueryData(['notes'], notes.concat(newNote))
  }
* That is, in the onSuccess callback, the queryClient object first reads the existing notes state of the query and updates it by adding a new note, which is obtained as a parameter of the callback function.
* By reading the documentation, we notice that the default functionality of React Query's queries is that the queries (whose status is stale) are updated when window focus, i.e. the active element of the application's user interface, changes. If we want, we can turn off the functionality by creating a query as follows:
  const App = () => {
    // ...
    const result = useQuery({
      queryKey: ['notes'],
      queryFn: getNotes,
      refetchOnWindowFocus: false
    })
    // ...
  }
* The rule of thumb is that rerendering happens at least whenever there is a need for it, i.e. when the state of the query changes. You can read more about it e.g. here.
  https://tkdodo.eu/blog/react-query-render-optimizations
* React Query is a versatile library that, based on what we have already seen, simplifies the application. Does React Query make more complex state management solutions such as Redux unnecessary? No. React Query can partially replace the state of the application in some cases, but as the documentation states:
  - React Query is a server-state library, responsible for managing asynchronous operations between your server and client
  - Redux, etc. are client-state libraries that can be used to store asynchronous data, albeit inefficiently when compared to a tool like React Query
* So React Query is a library that maintains the server state in the frontend, i.e. acts as a cache for what is stored on the server. React Query simplifies the processing of data on the server, and can in some cases eliminate the need for data on the server to be saved in the frontend state.
* Most React applications need not only a way to temporarily store the served data, but also some solution for how the rest of the frontend state (e.g. the state of forms or notifications) is handled.
* So even if the application uses React Query, some kind of solution is usually needed to manage the rest of the frontend state (for example, the state of forms). Quite often, the state created with useState is a sufficient solution. Using Redux is of course possible, but there are other alternatives.
* React's built-in useReducer (https://react.dev/reference/react/useReducer) hook provides a Redux-like state management mechanism.
* The hook useReducer provides a mechanism to create a state for an application. The parameter for creating a state is the reducer function that handles state changes, and the initial value of the state:
  const [counter, counterDispatch] = useReducer(counterReducer, 0)
* The reducer function that handles state changes is similar to Redux's reducers, i.e. the function gets as parameters the current state and the action that changes the state. The function returns the new state updated based on the type and possible contents of the action:
  const counterReducer = (state, action) => {
    switch (action.type) {
      case "INC":
          return state + 1
      case "DEC":
          return state - 1
      case "ZERO":
          return 0
      default:
          return state
    }
  }
* In our example, actions have nothing but a type. If the action's type is INC, it increases the value of the counter by one, etc. Like Redux's reducers, actions can also contain arbitrary data, which is usually put in the action's payload field.
* The function useReducer returns an array that contains an element to access the current value of the state (first element of the array), and a dispatch function (second element of the array) to change the state:
  const [counter, counterDispatch] = useReducer(counterReducer, 0)
  // ...
  <button onClick={() => counterDispatch({ type: "INC" })}>+</button>
* If we want to split the application into several components, the value of the counter and the dispatch function used to manage it must also be passed to the other components. One solution would be to pass these as props in the usual way.
* The solution works, but is not optimal. If the component structure gets complicated, e.g. the dispatcher should be forwarded using props through many components to the components that need it, even though the components in between in the component tree do not need the dispatcher. This phenomenon is called prop drilling.
* React's built-in Context API: https://react.dev/learn/passing-data-deeply-with-context
* React's context is a kind of global state of the application, to which it is possible to give direct access to any component app.
* The context is created with React's hook createContext (https://react.dev/reference/react/createContext). Let's create a context in the file CounterContext.jsx:
  import { createContext } from 'react'
  const CounterContext = createContext()
  export default CounterContext
* The App component can now provide a context to its child components as follows:
  import CounterContext from './CounterContext'
  const App = () => {
    const [counter, counterDispatch] = useReducer(counterReducer, 0)
    return (
      <CounterContext.Provider value={[counter, counterDispatch]}>
        <Display />
        <div>
          <Button type='INC' label='+' />
          <Button type='DEC' label='-' />
          <Button type='ZERO' label='0' />
        </div>
      </CounterContext.Provider>
    )
  }
* As can be seen, providing the context is done by wrapping the child components inside the CounterContext.Provider component and setting a suitable value for the context.
* Other components now access the context using the useContext hook:
  import { useContext } from 'react'
  import CounterContext from './CounterContext'

  const Display = () => {
    const [counter, dispatch] = useContext(CounterContext)
    return <div>
      {counter}
    </div>
  }

  const Button = ({ type, label }) => {
    const [counter, dispatch] = useContext(CounterContext)
    return (
      <button onClick={() => dispatch({ type })}>
        {label}
      </button>
    )
  }
* Move everything related to the counter from App.jsx to CounterContext.jsx:
  import { createContext, useReducer } from 'react'

  const counterReducer = (state, action) => {
    switch (action.type) {
      case "INC":
          return state + 1
      case "DEC":
          return state - 1
      case "ZERO":
          return 0
      default:
          return state
    }
  }

  const CounterContext = createContext()

  export const CounterContextProvider = (props) => {
    const [counter, counterDispatch] = useReducer(counterReducer, 0)
    return (
      <CounterContext.Provider value={[counter, counterDispatch] }>
        {props.children}
      </CounterContext.Provider>
    )
  }

  export default CounterContext
* The file now exports, in addition to the CounterContext object corresponding to the context, the CounterContextProvider component, which is practically a context provider whose value is a counter and a dispatcher used for its state management.
* Updated main.jsx:
  import ReactDOM from 'react-dom/client'
  import App from './App'
  import { CounterContextProvider } from './CounterContext'
  ReactDOM.createRoot(document.getElementById('root')).render(
    <CounterContextProvider>
      <App />
    </CounterContextProvider>
  )
* Now the context defining the value and functionality of the counter is available to all components of the application.
* The entire state of the application, i.e. the value of the counter and the code for managing it, is now isolated in the file CounterContext, which provides components with well-named and easy-to-use auxiliary functions for managing the state.
* The helper functions useCounterValue and useCounterDispatch are defined as custom hooks (https://react.dev/learn/reusing-logic-with-custom-hooks), because calling the hook function useContext is possible (https://legacy.reactjs.org/docs/hooks-rules.html) only from React components or custom hooks. Custom hooks are JavaScript functions whose name must start with the string use.
  import { createContext, useReducer, useContext } from 'react'
  const CounterContext = createContext()
  // ...
  export const useCounterValue = () => {
    const counterAndDispatch = useContext(CounterContext)
    return counterAndDispatch[0]
  }
* Redux does not have to be used in its entirety in an application. It may make sense, for example, to manage the form state outside of Redux, especially in situations where the state of a form does not affect the rest of the application. It is also perfectly possible to use Redux and React Query together in the same application.
* State management solutions:
  - React hooks (useState and useEffect)
    - Pros: simple
    - Cons: prop drilling
  - React Query with React context
    - Pros: server-state library, solves prop drilling
    - Cons: unintuitive syntax
  - React Toolkit (Redux)
    - Pros: client-state library, solves prop drilling, most popular, robust
    - Notes: uses redux for statement management and react-redux for sharing the state between React components
* A better solution for notifications:
  - App.jsx:
    import { useNotification } from './NotificationContext'
    // ... (within App)
    const setNotification = useNotification()
    // ... (within onSuccess)
    setNotification(`anecdote '${updatedAnecdote.content}' voted`, 5)
  - NotificationContext.js:
      export const useNotification = () => {
        const notificationValueAndDispatch = useContext(NotificationContext)
        const notificationDispatch = notificationValueAndDispatch[1]
        return (message, duration) => {
          notificationDispatch({ type: "SHOW", payload: message })
          setTimeout(() => {
            notificationDispatch({ type: "HIDE" })
          }, duration)
        }
      }


Part 7: React router, custom hooks, styling app with CSS and webpack
--------------------------------------------------------------------
* In single-page apps, we are always on the same page. The Javascript code run by the browser creates an illusion of different "pages". If HTTP requests are made when switching views, they are only for fetching JSON-formatted data, which the new view might require for it to be shown.
* Each view should preferably have its own address, e.g. to make bookmarking possible. The back button doesn't work as expected for our application either, meaning that back doesn't move you to the previously displayed view of the application, but somewhere completely different.
* React has the React Router (https://reactrouter.com/) library which provides an excellent solution for managing navigation in a React application.
* Install React Router:
  npm install react-router-dom
* Example use of React Router:
  import {
    BrowserRouter as Router,
    Routes, Route, Link
  } from 'react-router-dom'
  const App = () => {
    const padding = {
      padding: 5
    }
    return (
      <Router>
        <div>
          <Link style={padding} to="/">home</Link>
          <Link style={padding} to="/notes">notes</Link>
          <Link style={padding} to="/users">users</Link>
        </div>
        <Routes>
          <Route path="/notes" element={<Notes />} />
          <Route path="/users" element={<Users />} />
          <Route path="/" element={<Home />} />
        </Routes>
        <div>
          <i>Note app, Department of Computer Science 2023</i>
        </div>
      </Router>
    )
  }
* Routing, or the conditional rendering of components based on the URL in the browser, is used by placing components as children of the Router component, meaning inside Router tags.
* Notice that, even though the component is referred to by the name Router, we are talking about BrowserRouter:
  https://reactrouter.com/en/main/router-components/browser-router
* BrowserRouter is a Router that uses the HTML5 history API (pushState, replaceState and the popState event) to keep your UI in sync with the URL.
* Normally the browser loads a new page when the URL in the address bar changes. However, with the help of the HTML5 history API, BrowserRouter enables us to use the URL in the address bar of the browser for internal "routing" in a React application. So, even if the URL in the address bar changes, the content of the page is only manipulated using Javascript, and the browser will not load new content from the server. Using the back and forward actions, as well as making bookmarks, is still logical like on a traditional web page.
* Inside the router, we define links that modify the address bar with the help of the Link (https://reactrouter.com/en/main/components/link) component. For example:
  <Link to="/notes">notes</Link>
* Components rendered based on the URL of the browser are defined with the help of the component Route (https://reactrouter.com/en/main/route/route). For example:
  <Route path="/notes" element={<Notes />} />
* Wrap the components to be rendered based on the URL with a Routes (https://reactrouter.com/en/main/components/routes) component:
  <Routes>
    <Route path="/notes" element={<Notes />} />
    <Route path="/users" element={<Users />} />
    <Route path="/" element={<Home />} />
  </Routes>
* The Routes works by rendering the first component whose path matches the URL in the browser's address bar.
* Define the route rendering a specific note "express style" by marking the parameter with a colon - :id
  <Route path="/notes/:id" element={<Note notes={notes} />} />
* Definition of the Note component:
  import {
    // ...
    useParams
  } from 'react-router-dom'
  const Note = ({ notes }) => {
    const id = useParams().id
    // ...
* The Note component can access the URL parameter (the id of the note to be displayed) with the useParams function of the React Router.
* The option to navigate to the Login view is rendered conditionally in the menu:
  {user
    ? <em>{user} logged in</em>
    : <Link style={padding} to="/login">login</Link>
  }
* With the useNavigate (https://reactrouter.com/en/main/hooks/use-navigate) function of the React Router, the browser's URL can be changed programmatically.
  import {
    // ...
    useNavigate
  } from 'react-router-dom'
  const Login = (props) => {
    const navigate = useNavigate()
    const onSubmit = (event) => {
      event.preventDefault()
      props.onLogin('mluukkai')
      navigate('/')
    }
    // ...
* With user login, we call navigate('/') which causes the browser's URL to change to / and the application renders the corresponding component Home.
* Both useParams and useNavigate are hook functions, just like useState and useEffect which we have used many times now. 
* Hook functions must not be called from inside of a loop, a conditional expression, or any place that is not a function defining a component. This must be done to ensure that the hooks are always called in the same order, and if this isn't the case the application will behave erratically.
  - Create-react-app has been configured to warn you if you break these rules, for example, by calling a hook function from a conditional statement.
* If a user isn't logged in, the Users component is not rendered. Instead, the user is redirected using the component Navigate to the login view:
  <Route path="/users" element={user ? <Users /> : <Navigate replace to="/login" />} />
* In reality, it would perhaps be better to not even show links in the navigation bar requiring login if the user is not logged into the application.
* One way to modify the application so that the Note component receives only the note that it should display would be to use React Router's useMatch hook to figure out the id of the note to be displayed in the App component.
* It is not possible to use the useMatch hook in the component which defines the routed part of the application. Let's move the use of the Router components from App:
  ReactDOM.createRoot(document.getElementById('root')).render(
    <Router>
      <App />
    </Router>
  )
* Updated App component:
  import {
    // ...
    useMatch
  } from 'react-router-dom'
  const App = () => {
    // ...
    const match = useMatch('/notes/:id')
    const note = match
      ? notes.find(note => note.id === Number(match.params.id))
      : null
    return (
      <div>
        <div>
          <Link style={padding} to="/">home</Link>
          // ...
        </div>
        <Routes>
          <Route path="/notes/:id" element={<Note note={note} />} />
* Every time the component is rendered, so practically every time the browser's URL changes, the following command is executed:
  const match = useMatch('/notes/:id')
* If the URL matches /notes/:id, the match variable will contain an object from which we can access the parameterized part of the path, the id of the note to be displayed, and we can then fetch the correct note to display.
  const note = match
    ? notes.find(note => note.id === Number(match.params.id))
    : null
* React offers 15 different built-in hooks (https://react.dev/reference/react), of which the most popular ones are the useState and useEffect hooks that we have already been using extensively.
  - State Hooks:
    - useState
    - useReducer
  - Context Hooks:
    - useContext
  - Ref Hooks:
    - useRef
    - useImperativeHandle
  - Effect Hooks:
    - useEffect
    - useLayoutEffect
    - useIntertionEffect
  - Performance Hooks:
    - useTransition
    - useDeferredValue
  - Resource Hooks:
    - use
  - Other Hooks:
    - useDebugValue
    - useId
    - useSyncExternalStore
* Within the last couple of years, many React libraries have begun to offer hook-based APIs.
* Custom Hooks by React libraries:
  - react-redux:
    - useSelector
    - useDispatch
  - react-router-dom
    - useMatch
    - useNavigate
    - useParams
* Hooks are not normal functions, and when using those we have to adhere to certain rules or limitations (https://legacy.reactjs.org/docs/hooks-rules.html). Let's recap the rules of using hooks, copied verbatim from the official React documentation:
  - Don’t call Hooks inside loops, conditions, or nested functions.
    - Instead, always use Hooks at the top level of your React function.
  - Don’t call Hooks from regular JavaScript functions. Instead, you can:
    - Call Hooks from React function components.
    - Call Hooks from custom Hooks
* There's an existing ESlint plugin that can be used to verify that the application uses hooks correctly:
  https://www.npmjs.com/package/eslint-plugin-react-hooks
* Install ESLint plugin to enforce the Rules of Hooks:
  npm install eslint-plugin-react-hooks --save-dev
* Basic configuration:
  {
    "extends": [
      // ...
      "plugin:react-hooks/recommended"
    ]
  }
* Building your own Hooks lets you extract component logic into reusable functions.
  https://react.dev/learn/reusing-logic-with-custom-hooks
* Custom hooks are regular JavaScript functions that can use any other hooks, as long as they adhere to the rules of hooks (https://fullstackopen.com/en/part1/a_more_complex_state_debugging_react_apps#rules-of-hooks). Additionally, the name of custom hooks must start with the word use.
* Custom counter hook:
  import { useState } from 'react'
  const App = () => {
    const [counter, setCounter] = useState(0)

    return (
      <div>
        <div>{counter}</div>
        <button onClick={() => setCounter(counter + 1)}>
          plus
        </button>
        <button onClick={() => setCounter(counter - 1)}>
          minus
        </button>      
        <button onClick={() => setCounter(0)}>
          zero
        </button>
      </div>
    )
  }

  // from the above to the below --->

  const useCounter = () => {
    const [value, setValue] = useState(0)
    const increase = () => {
      setValue(value + 1)
    }
    const decrease = () => {
      setValue(value - 1)
    }
    const zero = () => {
      setValue(0)
    }
    return {
      value, 
      increase,
      decrease,
      zero
    }
  }
* Our custom hook uses the useState hook internally to create its state. The hook returns an object, the properties of which include the value of the counter as well as functions for manipulating the value.
* Usage of the custom hook:
  const App = () => {
    const counter = useCounter()
    return (
      <div>
        <div>{counter.value}</div>
        <button onClick={counter.increase}>
          plus
        </button>
        <button onClick={counter.decrease}>
          minus
        </button>      
        <button onClick={counter.zero}>
          zero
        </button>
      </div>
    )
  }
* The same hook could be reused in the application that was keeping track of the number of clicks made to the left and right buttons:
  const App = () => {
    const left = useCounter()
    const right = useCounter()
    return (
      <div>
        {left.value}
        <button onClick={left.increase}>left</button>
        <button onClick={right.increase}>right</button>
        {right.value}
      </div>
    )
  }
* Custom useField hook that simplifies the state management of the form:
  const useField = (type) => {
    const [value, setValue] = useState('')
    const onChange = (event) => {
      setValue(event.target.value)
    }
    return {
      type,
      value,
      onChange
    }
  }
* The hook function receives the type of the input field as a parameter. The function returns all of the attributes required by the input: its type, value and the onChange handler.
* Example usage of the useField custom hook:
  const App = () => {
    const name = useField('text')
    // ...
    return (
      <div>
        <form>
          <input type={name.type} value={name.value} onChange={name.onChange} /> 
          // ...
        </form>
      </div>
    )
  }
* Spread attributes can be used to simplify things a bit further. Since the name object has exactly all of the attributes that the input element expects to receive as props, we can pass the props to the element using the spread syntax in the following way:
  <input {...name} /> 
* The following two ways of passing props to a component achieve the exact same result:
  <Greeting firstName='Arto' lastName='Hellas' />
  // vs.
  const person = {
    firstName: 'Arto',
    lastName: 'Hellas'
  }
  <Greeting {...person} />
* Final, and simplified, form format:
  const App = () => {
    const name = useField('text')
    const born = useField('date')
    const height = useField('number')
    return (
      <div>
        <form>
          name: <input  {...name} /><br/>
          birthdate: <input {...born} /><br />
          height: <input {...height} />
        </form>
        <div>{name.value} {born.value} {height.value}</div>
      </div>
    )
  }
* Custom hooks are not only a tool for reuse; they also provide a better way for dividing our code into smaller modular parts.
* More about hooks:
  - Awesome React Hooks Resources: https://github.com/rehooks/awesome-react-hooks
  - Easy to understand React Hook recipes by Gabe Ragland: https://usehooks.com/
  - Why Do React Hooks Rely on Call Order?: https://overreacted.io/why-do-hooks-rely-on-call-order/
* The spread syntax:
  const originalObject = { enabled: true, darkMode: false }
  const secondObject = { ...originalObject }
* Rest parameters and the spread syntax:
  const originalObject = { enabled: true, darkMode: false }
  const { darkMode, ...rest } = originalObject
  console.log(rest) // excludes darkMode
  const newObject = (({ darkMode, ...rest }) => rest)(originalObject) // alternative: oneliner
* Adding styles to React applications:
  - Old-school single CSS file
  - Inline styles
  - Ready-made UI libraries
* One of the first widely popular UI frameworks was the Bootstrap toolkit (https://getbootstrap.com/) created by Twitter which may still be the most popular framework.
* Usually, UI frameworks are used by including the CSS stylesheets and JavaScript code of the framework in the application.
* Many UI frameworks have React-friendly versions where the framework's "components" have been transformed into React components. There are a few different React versions of Bootstrap like reactstrap (http://reactstrap.github.io/) and react-bootstrap (https://react-bootstrap.github.io/).
* MaterialUI: https://mui.com/
* React Bootstrap: https://react-bootstrap.github.io/
* Install react-bootstrap:
  npm install react-bootstrap
* Add a link for loading the CSS stylesheet for Bootstrap (https://react-bootstrap.github.io/docs/getting-started/introduction#stylesheets) inside of the head tag in the public/index.html file of the application:
  <head>
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css"
      integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM"
      crossorigin="anonymous"
    />
    // ...
  </head>
* In Bootstrap, all of the contents of the application are typically rendered inside a container. In practice this is accomplished by giving the root div element of the application the container class attribute:
  <div className="container">
* Import React Bootstrap components:
  import { Table, Form, Button } from 'react-bootstrap'
* React Bootstrap provides a built-in Table component, so there is no need to define CSS classes separately:
  <Table striped>
    ...
  </Table>
* Bootstrap forms: https://getbootstrap.com/docs/4.1/components/forms/
* React Bootstrap provides built-in components for creating forms (although the documentation for them is slightly lacking):
  let Login = (props) => {
    // ...
    return (
      <div>
        <h2>login</h2>
        <Form onSubmit={onSubmit}>
          <Form.Group>
            <Form.Label>username:</Form.Label>
            <Form.Control
              type="text"
              name="username"
            />
          </Form.Group>
          <Form.Group>
            <Form.Label>password:</Form.Label>
            <Form.Control
              type="password"
            />
          </Form.Group>
          <Button variant="primary" type="submit">
            login
          </Button>
        </Form>
      </div>
    )
  }
* Render the notification message as a Bootstrap Alert component (https://getbootstrap.com/docs/4.1/components/alerts/). Once again, the React Bootstrap library provides us with a matching React component (https://react-bootstrap.github.io/docs/components/alerts/):
  <div className="container">
    {(message &&
      <Alert variant="success">
        {message}
      </Alert>
    )}
    // ...
  </div>
* Alter the application's navigation menu to use Bootstrap's Navbar component. The React Bootstrap library provides us with matching built-in components.
* Bootstrap and a large majority of existing UI frameworks produce responsive designs (https://en.wikipedia.org/wiki/Responsive_web_design), meaning that the resulting applications render well on a variety of different screen sizes.
* The MaterialUI (https://mui.com/) React library, which implements the Material Design (https://material.io/) visual language developed by Google.
* Install MaterialUI React library:
  npm install @mui/material @emotion/react @emotion/styled
* Render the contents of the whole application within a Container:
  import { Container } from '@mui/material'
  const App = () => {
    // ...
    return (
      <Container>
        // ...
      </Container>
    )
  }
* Render the list of notes as a table (https://mui.com/material-ui/react-table/#simple-table):
  <TableContainer component={Paper}>
    <Table>
      <TableBody>
        // ...
      </TableBody>
    </Table>
  </TableContainer>
* With Material UI, each component has to be imported separately:
  import {
    Container,
    Table,
    TableBody,
    TableCell,
    TableContainer,
    TableRow,
    Paper,
  } from '@mui/material'
* Make the login form in the Login view better using the TextField (https://mui.com/material-ui/react-text-field/) and Button (https://mui.com/material-ui/api/button/) components:
  <form onSubmit={onSubmit}>
    <div>
      <TextField label="username" />
    </div>
    <div>
      <TextField label="password" type='password' />
    </div>
    <div>
      <Button variant="contained" color="primary" type="submit">
        login
      </Button>
    </div>
  </form>
* The notification displayed on login can be done using the Alert (https://mui.com/material-ui/react-alert/) component, which is quite similar to Bootstrap's equivalent component:
  <div>
    {(message &&
      <Alert severity="success">
        {message}
      </Alert>
    )}
  </div>
* Implement navigation using the AppBar component:
  <AppBar position="static">
    <Toolbar>
      <IconButton edge="start" color="inherit" aria-label="menu">
      </IconButton>
      <Button color="inherit">
        <Link to="/">home</Link>
      </Button>
      // ...
    </Toolbar>
  </AppBar>copy
* Use component props to define how the root element of a MaterialUI component is rendered. For example:
  <Button color="inherit" component={Link} to="/">
    home
  </Button>
* https://www.npmtrends.com/ tracks the popularity of different npm-libraries.
* Instead of using the React Bootstrap library, we could have just as well used Bootstrap directly by defining CSS classes for our application's HTML elements. Instead of defining the table with the Table component:
  <Table striped>
    // ...
  </Table>
* We could have used a regular HTML table and added the required CSS class:
  <table className="table striped">
    // ...
  </table>
* In addition to making the frontend code more compact and readable, another benefit of using React UI framework libraries is that they include the JavaScript that is needed to make specific components work. Some Bootstrap components require a few unpleasant JavaScript dependencies (https://getbootstrap.com/docs/4.1/getting-started/introduction/#js) that we would prefer not to include in our React applications.
* Some potential downsides to using UI frameworks through integration libraries instead of using them "directly" are that integration libraries may have unstable APIs and poor documentation.
* Here are some other UI frameworks for your consideration:
  - https://bulma.io/
  - https://ant.design/
  - https://get.foundation/
  - https://chakra-ui.com/
  - https://tailwindcss.com/
  - https://semantic-ui.com/
  - https://mantine.dev/
  - https://react.fluentui.dev/
  - https://storybook.js.org
  - https://www.primefaces.org/primereact/
  - https://v2.grommet.io
  - https://blueprintjs.com
  - https://evergreen.segment.com
  - https://www.radix-ui.com/
  - https://react-spectrum.adobe.com/react-aria/index.html
  - https://master.co/
  - https://www.radix-ui.com/
  - https://nextui.org/
  - https://daisyui.com/
  - https://ui.shadcn.com/
  - https://www.tremor.so/
  - https://headlessui.com/
* 5 ways to style React components: https://blog.bitsrc.io/5-ways-to-style-react-components-in-2019-30f1ccc2b5b
* The styled components library (https://www.styled-components.com/) offers an interesting approach for defining styles through tagged template literals (https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals#tagged_templates) that were introduced in ES6.
* Install styled-components:
  npm install styled-components
* import styled from 'styled-components'
  const Button = styled.button`
    background: Bisque;
    font-size: 1em;
    margin: 1em;
    padding: 0.25em 1em;
    border: 2px solid Chocolate;
    border-radius: 3px;
  `
  const Input = styled.input`
    margin: 0.25em;
  `
* The syntax for defining the styles is quite interesting, as the CSS rules are defined inside of backticks.
* Usage of styled components:
  <Button type="submit" primary=''>login</Button>
  <Input type='password' />
* Styled components have seen consistent growth in popularity in recent times, and quite a lot of people consider it to be the best way of defining styles in React applications.
* Create React App (https://github.com/facebookincubator/create-react-app) was developed, which eliminated configuration-related problems.
* Vite (https://vitejs.dev/), which is also used in the course, has recently replaced Create React App in new applications.
* Both Vite and Create React App use bundlers to do the actual work. We will now familiarize ourselves with the bundler called Webpack (https://webpack.js.org/) used by Create React App.
* Webpack was by far the most popular bundler for years. Recently, however, there have been several new generation bundlers such as esbuild used by Vite, which are significantly faster and easier to use than Webpack. However, e.g. esbuild (https://esbuild.github.io/) still lacks some useful features (such as hot reload of the code in the browser).
* Even though ES6 modules are defined in the ECMAScript standard, the older browsers do not know how to handle code that is divided into modules.
* For this reason, code that is divided into modules must be bundled for browsers, meaning that all of the source code files are transformed into a single file that contains all of the application code.
* Bundling of an application is performed with the "npm run build" command.
* Under the hood, the npm script bundles the source, and this produces the following collection of files in the dist directory:
  ├── assets
  │   ├── index-d526a0c5.css
  │   ├── index-e92ae01e.js
  │   └── react-35ef61ed.svg
  ├── index.html
  └── vite.svg
* In practice, bundling is done so that we define an entry point for the application, which typically is the index.js file. When webpack bundles the code, it includes not only the code from the entry point but also the code that is imported by the entry point, as well as the code imported by its import statements, and so on.
* Webpack project structure (used by Create React App, the precessor of Vite):
  ├── build
  ├── package.json
  ├── src
  │   └── index.js
  └── webpack.config.js
* Install webpack:
  npm install --save-dev webpack webpack-cli
* Define the functionality of webpack in the webpack.config.js file.
  - An object for config will suffice in many situations, but we will later need certain features that require the definition to be done as a function.
  - Define a new npm script called build that will execute the bundling with webpack:
    "build": "webpack --mode=development"
  - The entry (https://webpack.js.org/concepts/#entry) property of the configuration object specifies the file that will serve as the entry point for bundling the application.
  - The output (https://webpack.js.org/concepts/#output) property defines the location where the bundled code will be stored. The target directory must be defined as an absolute path, which is easy to create with the path.resolve method. We also use __dirname which is a variable in Node that stores the path to the current directory.
* When we execute the npm run build command, our application code will be bundled by webpack. The operation will produce a new main.js file that is added under the build directory.
* Transform the application into a minimal React application by installing the required libraries:
  npm install react react-dom
* By default, webpack only knows how to deal with plain JavaScript. Although we may have become unaware of it, we are using JSX (https://facebook.github.io/jsx/) for rendering our views in React.
* Use loaders (https://webpack.js.org/concepts/loaders/) to inform webpack of the files that need to be processed before they are bundled.
* Configure a loader to our application that transforms the JSX code into regular JavaScript:
  const config = () => {
    return {
      // ...
      module: {
        rules: [
          {
            test: /\.js$/,
            loader: 'babel-loader',
            options: {
              presets: ['@babel/preset-react'],
            },
          },
        ],
      },
    }
  }
* Loaders are defined under the module property in the rules array.
* The definition of a single loader consists of three parts:
  - The test property specifies that the loader is for files that have names ending with .js.
  - The loader property specifies that the processing for those files will be done with babel-loader.
  - The options property is used for specifying parameters for the loader, which configure its functionality.
* Install the loader and its required packages as a development dependency:
  npm install @babel/core babel-loader @babel/preset-react --save-dev
* It's worth noting that if the bundled application's source code uses async/await, the browser will not render anything on some browsers. Googling the error message in the console (https://stackoverflow.com/questions/33527653/babel-6-regeneratorruntime-is-not-defined) will shed some light on the issue. With the previous solution (https://babeljs.io/docs/en/babel-polyfill/) being deprecated we now have to install two more missing dependencies, that is core-js (https://www.npmjs.com/package/core-js) and regenerator-runtime (https://www.npmjs.com/package/regenerator-runtime):
  npm install core-js regenerator-runtime
* You need to import those dependencies at the top of the index.js file:
  import 'core-js/stable/index.js'
  import 'regenerator-runtime/runtime.js'
* The process of transforming code from one form of JavaScript to another is called transpiling (https://en.wiktionary.org/wiki/transpile). The general definition of the term is to compile source code by transforming it from one language to another.
* We are transpiling the code containing JSX into regular JavaScript with the help of babel (https://babeljs.io/), which is currently the most popular tool for the job.
* Most browsers do not support the latest features that were introduced in ES6 and ES7, and for this reason, the code is usually transpiled to a version of JavaScript that implements the ES5 standard.
* The transpilation process that is executed by Babel is defined with plugins. In practice, most developers use ready-made presets (https://babeljs.io/docs/plugins/) that are groups of pre-configured plugins.
* Transpile source code to regular JavaScript: https://babeljs.io/docs/plugins/preset-react/
* Add the @babel/preset-env (https://babeljs.io/docs/plugins/preset-env/) plugin that contains everything needed to take code using all of the latest features and transpile it to code that is compatible with the ES5 standard:
  presets: ['@babel/preset-env', '@babel/preset-react']
* Install @babel/preset-react:
  npm install @babel/preset-env --save-dev
* As we can see, variables are declared with the var keyword as ES5 JavaScript does not understand the const keyword. Arrow functions are also not used, which is why the function definition used the function keyword.
* Import an external CSS style from the index.js file:
  import './index.css'
* When using CSS, we have to use css (https://webpack.js.org/loaders/css-loader/) and style (https://webpack.js.org/loaders/style-loader/) loaders:
  rules: [
    // ...
    {
      test: /\.css$/,
      use: ['style-loader', 'css-loader'],
    },
  ],
* The job of the css loader (https://webpack.js.org/loaders/css-loader/) is to load the CSS files and the job of the style loader (https://webpack.js.org/loaders/style-loader/) is to generate and inject a style element that contains all of the styles of the application.
* With this configuration, the CSS definitions are included in the main.js file of the application. For this reason, there is no need to separately import the CSS styles in the main index.html file of the application.
* If needed, the application's CSS can also be generated into its own separate file by using the mini-css-extract-plugin (https://github.com/webpack-contrib/mini-css-extract-plugin).
* Install style-loader css-loader:
  npm install style-loader css-loader --save-dev
* Install webpack-dev-server for a better development experience:
  npm install --save-dev webpack-dev-server
* Include a new script:
  "start": "webpack serve --mode=development"
* Add a new devServer property to the configuration object in the webpack.config.js file:
  const config = {
    // ...
    devServer: {
      static: path.resolve(__dirname, 'build'),
      compress: true,
      port: 3000,
    },
  }
* The npm start command will now start the dev-server at port 3000, meaning that our application will be available by visiting http://localhost:3000 in the browser. When we make changes to the code, the browser will automatically refresh the page.
* Webpack can generate a so-called source map (https://webpack.js.org/configuration/devtool/) for the bundle, which makes it possible to map errors that occur during the execution of the bundle to the corresponding part in the original source code.
* The source map can be generated by adding a new devtool property to the configuration object with the value 'source-map':
  const config = {
    // ...
    devtool: 'source-map',
  }
* Webpack has to be restarted when we make changes to its configuration. It is also possible to make webpack watch for changes made to itself but we will not do that this time.
* Generating the source map also makes it possible to use the Chrome debugger.
* If we inspect the contents of the bundle file, we notice that it could be greatly optimized in terms of file size by removing all of the comments. There's no point in manually optimizing these files, as there are many existing tools for the job.
* The optimization process for JavaScript files is called minification. One of the leading tools intended for this purpose is UglifyJS (http://lisperator.net/uglifyjs/).
* Starting from version 4 of webpack, the minification plugin does not require additional configuration to be used. It is enough to modify the npm script in the package.json file to specify that webpack will execute the bundling of the code in production mode:
  "build": "webpack --mode=production"
* When we bundle the application again, the size of the resulting main.js decreases substantially. All of the comments and even unnecessary whitespace and newline characters have been removed, and variable names have been replaced with a single character.
* Webpack's configuration function has two parameters, env and argv. We can use the latter to find out the mode defined in the npm script:
  const config = (env, argv) => {
      // ...
    }
  }
* Now, if we want, we can set Webpack to work differently depending on whether the application's operating environment, or mode, is set to production or development.
* We can also use webpack's DefinePlugin (https://webpack.js.org/plugins/define-plugin/) for defining global default constants that can be used in the bundled code. Let's define a new global constant BACKEND_URL that gets a different value depending on the environment that the code is being bundled for:
  const path = require('path')
  const webpack = require('webpack')
  const config = (env, argv) => {
    console.log('argv', argv.mode)
    const backend_url = argv.mode === 'production'
      ? 'https://notes2023.fly.dev/api/notes'
      : 'http://localhost:3001/notes'
    return {
      // ...
      plugins: [
        new webpack.DefinePlugin({
          BACKEND_URL: JSON.stringify(backend_url)
        })
      ]
    }
  }

  module.exports = config
* The global constant is used in the following way in the code:
  const notes = useNotes(BACKEND_URL)
* If the configuration for development and production differs a lot, it may be a good idea to separate the configuration (https://webpack.js.org/guides/production/) of the two into their own files.
* We can inspect the bundled production version of the application locally by executing the following command in the build directory:
  npx static-server
* By default, the bundled application will be available at http://localhost:9080
* Internet Explorer does not support Promises used by axios. There are many other things in the standard that IE does not support, including the find (https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/find) method.
* In these situations, it is not enough to transpile the code, as transpilation simply transforms the code from a newer version of JavaScript to an older one with wider browser support. 
* IE understands Promises syntactically but it simply has not implemented their functionality. The find property of arrays in IE is simply undefined.
* If we want the application to be IE-compatible, we need to add a polyfill (https://remysharp.com/2010/10/08/what-is-a-polyfill), which is code that adds the missing functionality to older browsers.
* Polyfills can be added with the help of webpack and Babel (https://babeljs.io/docs/usage/polyfill/) or by installing one of many existing polyfill libraries.
* The polyfill provided by the promise-polyfill library is easy to use. We simply have to add the following to our existing application code:
  import PromisePolyfill from 'promise-polyfill'
  if (!window.Promise) {
    window.Promise = PromisePolyfill
  }
* If the global Promise object does not exist, meaning that the browser does not support Promises, the polyfilled Promise is stored in the global variable. If the polyfilled Promise is implemented well enough, the rest of the code should work without issues.
* One exhaustive list of existing polyfills can be found here: https://github.com/Modernizr/Modernizr/wiki/HTML5-Cross-browser-Polyfills
* The browser compatibility of different APIs can be checked by visiting https://caniuse.com or Mozilla's website (https://developer.mozilla.org/en-US/).
* Before React version 16.8, when defining a component that uses state, one had to define it using Javascript's Class syntax (https://reactjs.org/docs/state-and-lifecycle.html#converting-a-function-to-a-class).
* Stub for the class component:
  import React from 'react'
  class App extends React.Component {
    constructor(props) {
      super(props)
    }
    render() {
      return (
        <div>
          <h1>anecdote of the day</h1>
        </div>
      )
    }
  }
  export default App
* The component now has a constructor (https://react.dev/reference/react/Component#constructor), in which nothing happens at the moment, and contains the method render (https://react.dev/reference/react/Component#render). As one might guess, render defines how and what is rendered to the screen.
* Class Components only contain one state. So if the state is made up of multiple "parts", they should be stored as properties of the state. The state is initialized in the constructor:
  this.state = {
    anecdotes: [],
    current: 0
  }
* Accessing the state:
  render() {
    if (this.state.anecdotes.length === 0) {
      return <div>no anecdotes...</div>
    }
    // ...
* In Functional components (https://react.dev/reference/react/Component#adding-lifecycle-methods-to-a-class-component), the right place for fetching data from a server is inside an effect hook (https://react.dev/reference/react/useEffect), which is executed when a component renders or less frequently if necessary, e.g. only in combination with the first render.
* The lifecycle methods of Class Components offer corresponding functionality. The correct place to trigger the fetching of data from a server is inside the lifecycle method componentDidMount (https://react.dev/reference/react/Component#componentdidmount), which is executed once right after the first time a component renders:
  componentDidMount = () => {
    axios.get('http://localhost:3001/anecdotes').then(response => {
      this.setState({ anecdotes: response.data })
    })
  }
* The callback function of the HTTP request updates the component state using the method setState (https://react.dev/reference/react/Component#setstate). The method only touches the keys that have been defined in the object passed to the method as an argument. The value for the key current remains unchanged.
* Calling the method setState always triggers the rerender of the Class Component, i.e. calling the method render.
* React component types:
  - Class components: pre React 16.8, constructor and render, one state, lifecycle events, super and this
  - Functional components: React 16.8+, more concise syntax, no constructor or render, multiple states, no super or this
* The biggest difference between Functional components and Class components is mainly that the state of a Class component is a single object, and that the state is updated using the method setState, while in Functional components the state can consist of multiple different variables, with all of them having their own update function.
* In some more advanced use cases, the effect hook offers a considerably better mechanism for controlling side effects compared to the lifecycle methods of Class Components.
* A notable benefit of using Functional components is not having to deal with the self-referencing this reference of the Javascript class.
* Class components offer error boundary (https://react.dev/reference/react/Component#catching-rendering-errors-with-an-error-boundary), which is not yet available in functional components.
* When writing fresh code, there is no rational reason to use Class Components (https://reactjs.org/docs/hooks-faq.html#should-i-use-hooks-classes-or-a-mix-of-both) if the project is using React with a version number 16.8 or greater.
* On the other hand, there is currently no need to rewrite all old React code (https://reactjs.org/docs/hooks-faq.html#do-i-need-to-rewrite-all-my-class-components) as Functional components.
* In most applications, we followed the principle by which components were placed in the directory components, reducers were placed in the directory reducers, and the code responsible for communicating with the server was placed in the directory services. This way of organizing fits a smaller application just fine, but as the amount of components increases, better solutions are needed.
* There is no one correct way to organize a project. The article The 100% correct way to structure a React app (or why there’s no such thing) provides some perspective on the issue.
  - https://medium.com/hackernoon/the-100-correct-way-to-structure-a-react-app-or-why-theres-no-such-thing-3ede534ef1ed
* During the course, we have created the frontend and backend into separate repositories. This is a very typical approach. However, we did the deployment by copying the bundled frontend code into the backend repository. A possibly better approach would have been to deploy the frontend code separately.
* Sometimes, there may be a situation where the entire application is to be put into a single repository. In this case, a common approach is to put the package.json and webpack.config.js in the root directory, as well as place the frontend and backend code into their own directories, e.g. client and server.
* A sophisticated way to keep the frontend and backend data in sync is to use WebSockets (https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API) which allow for establishing a two-way communication channel between the browser and the server. In this case, the browser does not need to poll the backend, and instead only has to define callback functions for situations when the server sends data about updating state using a WebSocket.
* Instead of directly using the WebSocket API, it is advisable to use the Socket.io (https://socket.io/) library, which provides various fallback options in case the browser does not have full support for WebSockets.
* When a software developer uses React, they rarely or never directly manipulate the DOM. The function defining the React component returns a set of React elements (https://reactjs.org/docs/glossary.html#elements). Although some of the elements look like normal HTML elements
  const element = <h1>Hello, world</h1>
* The React elements defining the appearance of the components of the application make up the Virtual DOM (https://reactjs.org/docs/faq-internals.html#what-is-the-virtual-dom), which is stored in system memory during runtime.
* With the help of the ReactDOM (https://react.dev/reference/react-dom) library, the virtual DOM defined by the components is rendered to a real DOM that can be shown by the browser using the DOM API:
  ReactDOM.createRoot(document.getElementById('root')).render(<App />)
* When the state of the application changes, a new virtual DOM gets defined by the components. React has the previous version of the virtual DOM in memory and instead of directly rendering the new virtual DOM using the DOM API, React computes the optimal way to update the DOM (remove, add or modify elements in the DOM) such that the DOM reflects the new virtual DOM.
* React is primarily a library for managing the creation of views for an application. 
* If we look at the traditional Model View Controller pattern (https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller), then the domain of React would be View. React has a more narrow area of application than e.g. Angular (https://angular.io/), which is an all-encompassing Frontend MVC framework. Therefore, React is not called a framework, but a library.
* If we are using Redux, then the applications follow the Flux architecture (https://facebook.github.io/flux/docs/in-depth-overview) and the role of React is even more focused on creating the views. The business logic of the application is handled using the Redux state and action creators.
* If we're using Redux Thunk (https://fullstackopen.com/en/part6/communicating_with_server_in_a_redux_application#asynchronous-actions-and-redux-thunk) familiar from part 6, then the business logic can be almost completely separated from the React code.
* Because both React and Flux were created at Facebook, one could say that using React only as a UI library is the intended use case. 
* If we're talking about a small application or prototype, it might be a good idea to use React "wrong", since over-engineering (https://en.wikipedia.org/wiki/Overengineering) rarely yields an optimal result.
* React's hook functions useReducer and useContext provide a kind of lightweight version of Redux for state management.
* React Query, on the other hand, is a library that solves many of the problems associated with handling state on the server, eliminating the need for a React application to store data retrieved from the server directly in frontend state.
* The Open Web Application Security Project, otherwise known as OWASP (https://www.owasp.org/), publishes an annual list of the most common security risks in Web applications. The most recent list can be found at: https://owasp.org/www-project-top-ten/
* The most famous type of injection is probably SQL injection: https://stackoverflow.com/questions/332365/how-does-the-sql-injection-from-the-bobby-tables-xkcd-comic-work
* SQL injections are prevented using parameterized queries (https://security.stackexchange.com/questions/230211/why-are-stored-procedures-and-prepared-statements-the-preferred-modern-methods-f). With them, user input isn't mixed with the SQL query, but the database itself inserts the input values at placeholders in the query (usually ?).
  execute("SELECT * FROM Users WHERE name = ?", [userName])
* Injection attacks are also possible in NoSQL databases. However, mongoose prevents them by sanitizing (https://zanon.io/posts/nosql-injection-in-mongodb) the queries. More on the topic can be found e.g. here: https://web.archive.org/web/20220901024441/https://blog.websecurify.com/2014/08/hacking-nodejs-and-mongodb.html
* Cross-site scripting (XSS) is an attack where it is possible to inject malicious JavaScript code into a legitimate web application. The malicious code would then be executed in the browser of the victim.
* React takes care of sanitizing data in variables (https://reactjs.org/docs/introducing-jsx.html#jsx-prevents-injection-attacks). Some versions of React have been vulnerable (https://medium.com/dailyjs/exploiting-script-injection-flaws-in-reactjs-883fb1fe36c1) to XSS attacks. 
* One needs to remain vigilant when using libraries; if there are security updates to those libraries, it is advisable to update those libraries in one's applications. Security updates for Express are found in the library's documentation (https://expressjs.com/en/advanced/security-updates.html) and the ones for Node are found in this blog (https://nodejs.org/en/blog/).
* You can check how up-to-date your dependencies are using the command:
  npm outdated --depth 0
* The dependencies can be brought up to date by updating the file package.json. The best way to do that is by using a tool called npm-check-updates. It can be installed globally by running the command:
  npm install -g npm-check-updates
* Using this tool, the up-to-dateness of dependencies is checked in the following way:
  npm-check-updates
* The file package.json is brought up to date by running the command:
  ncu -u
* Then it is time to update the dependencies by running the command npm install. However, old versions of the dependencies are not necessarily a security risk.
* The npm audit (https://docs.npmjs.com/cli/audit) command can be used to check the security of dependencies. It compares the version numbers of the dependencies in your application to a list of the version numbers of dependencies containing known security threats in a centralized error database.
* Running npm audit:
  npm audit
* Fix security issues:
  npm audit fix
* By default, audit fix does not update dependencies if their major version number has increased. Updating these dependencies could lead to the whole application breaking down.
* Running npm audit fix --force would upgrade the library version but would also upgrade the library react-scripts and that would potentially break down the development environment.
* One of the threats mentioned in the list from OWASP is Broken Authentication and the related Broken Access Control. The token-based authentication we have been using is fairly robust if the application is being used on the traffic-encrypting HTTPS protocol.
* When implementing access control, one should e.g. remember to not only check a user's identity in the browser but also on the server. Bad security would be to prevent some actions to be taken only by hiding the execution options in the code of the browser.
* On Mozilla's MDN, there is a very good Website security guide (https://developer.mozilla.org/en-US/docs/Learn/Server-side/First_steps/Website_security), which brings up this very important topic:
  "The single most important lesson you can learn about website security is to NEVER TRUST DATA FROM THE BROWSER. This includes, but is not limited to data in URL parameters of GET requests, POST requests, HTTP headers and cookies, and user-uploaded files. Always check and sanitize all incoming data. Always assume the worst."
* For Express: Production Best Practices: Security (https://expressjs.com/en/advanced/best-practice-security.html)
* It is also recommended to add a library called Helmet (https://helmetjs.github.io/) to the backend. It includes a set of middleware that eliminates some security vulnerabilities in Express applications.
* Using the ESlint security-plugin (https://github.com/nodesecurity/eslint-plugin-security) is also worth doing.
* Sometimes, the dynamic typing (https://developer.mozilla.org/en-US/docs/Glossary/Dynamic_typing) of JavaScript variables creates annoying bugs. In part 5, we talked briefly about PropTypes: a mechanism which enables one to enforce type-checking for props passed to React components.
* Lately, there has been a notable uplift in the interest in static type checking (https://en.wikipedia.org/wiki/Type_system#Static_type_checking). At the moment, the most popular typed version of Javascript is TypeScript (https://www.typescriptlang.org/) which has been developed by Microsoft.
* The browser is not the only domain where components defined using React can be rendered. The rendering can also be done on the server (https://react.dev/reference/react-dom/server).
* This kind of approach is increasingly being used, such that, when accessing the application for the first time, the server serves a pre-rendered page made with React. From here onwards, the operation of the application continues, as usual, meaning the browser executes React, which manipulates the DOM shown by the browser. The rendering that is done on the server goes by the name: server-side rendering.
* One motivation for server-side rendering is Search Engine Optimization (SEO). Search engines have traditionally been very bad at recognizing JavaScript-rendered content. However, the tide might be turning:
  - https://www.javascriptstuff.com/react-seo/
  - https://medium.freecodecamp.org/seo-vs-react-is-it-neccessary-to-render-react-pages-in-the-backend-74ce5015c0c9
* Using the same programming language throughout the stack in theory simplifies the execution of the concept because the same code can be run on both the front- and backend.
* Along with server-side rendering, there has been talk of so-called isomorphic applications and universal code, although there has been some debate about their definitions. According to some definitions, an isomorphic web application performs rendering on both frontend and backend. On the other hand, universal code is code that can be executed in most environments, meaning both frontend and backend.
* React and Node provide a desirable option for implementing an isomorphic application as universal code.
* Writing universal code directly using React is currently still pretty cumbersome. Lately, a library called Next.js (https://github.com/vercel/next.js), which is implemented on top of React, has garnered much attention and is a good option for making universal applications.
* Progressive Web App (PWA) launched by Google web applications work on every platform and take advantage of the best parts of those platforms.
* PWAs should also work flawlessly in offline mode or with a slow internet connection. On mobile devices, they must be installable just like any other application. All the network traffic in a PWA should be encrypted.
* A monolithic backend is one application that makes up a whole and runs on a single server, serving only a few API endpoints.
* As the application grows, the monolithic backend approach starts turning problematic both in terms of performance and maintainability.
* A microservice architecture (microservices) is a way of composing the backend of an application from many separate, independent services, which communicate with each other over the network. An individual microservice's purpose is to take care of a particular logical functional whole. In a pure microservice architecture, the services do not use a shared database.
* For example, the bloglist application could consist of two services: one handling the user and another taking care of the blogs. The responsibility of the user service would be user registration and user authentication, while the blog service would take care of operations related to the blogs.
* There is often a so-called API gateway (http://microservices.io/patterns/apigateway) between the microservices and the frontend, which provides an illusion of a more traditional "everything on the same server" API.
* Microservice architectures emerged and evolved for the needs of large internet-scale applications. The trend was set by Amazon far before the appearance of the term microservice.
* Microservices by Amazon CEO Jeff Bezos:
  All teams will henceforth expose their data and functionality through service interfaces.
  Teams must communicate with each other through these interfaces.
  There will be no other form of inter-process communication allowed: no direct linking, no direct reads of another team’s data store, no shared-memory model, no back-doors whatsoever. The only communication allowed is via service interface calls over the network.
  It doesn’t matter what technology you use.
  All service interfaces, without exception, must be designed from the ground up to be externalize-able. That is to say, the team must plan and design to be able to expose the interface to developers in the outside world.
* It might make sense to go monolith first (https://martinfowler.com/bliki/MonolithFirst.html) by initially making a traditional all-encompassing backend. Or maybe not (https://martinfowler.com/articles/dont-start-monolith.html).
* After the release of Amazon's lambda (https://aws.amazon.com/lambda/) service at the end of 2014, a new trend started to emerge in web application development: serverless (https://serverless.com/).
* The main thing about Amazon Lambda (Google Cloud Functions, https://cloud.google.com/functions/ or Microsoft Azure Functions, https://azure.microsoft.com/en-us/services/functions/) is that it enables the execution of individual functions in the cloud. Before, the smallest executable unit in the cloud was a single process, e.g. a runtime environment running a Node backend.
* Using Amazon's API gateway it is possible to make serverless applications where the requests to the defined HTTP API get responses directly from cloud functions. Usually, the functions already operate using stored data in the databases of the cloud service.
* Serverless is not about there not being a server in applications, but about how the server is defined. Software developers can shift their programming efforts to a higher level of abstraction as there is no longer a need to programmatically define the routing of HTTP requests, database relations, etc., since the cloud infrastructure provides all of this. Cloud functions also lend themselves to creating a well-scaling system, e.g. Amazon's Lambda can execute a massive amount of cloud functions per second. All of this happens automatically through the infrastructure and there is no need to initiate new servers, etc.
* Useful libraries:
  - lodash: https://www.npmjs.com/package/lodash (handle comlicated data)
  - ramda: https://ramdajs.com/ (handle complicated data, functional programming style)
  - date-fns: https://github.com/date-fns/date-fns (handling dates and times)
  - React Hook Form: https://react-hook-form.com/ (complex forms)
  - recharts: http://recharts.org/en-US/ (graphs)
  - highcharts: https://github.com/highcharts/highcharts-react (graphs)
  - immer: https://github.com/mweststrate/immer (immutable implementations of some data structures)
  - redux-saga: https://redux-saga.js.org/ (async actions for Redux Thunk)
  - React Google Analytics: https://github.com/react-ga/react-ga (gathering of analytics data)
  - React Native: https://facebook.github.io/react-native/ (mobile app development)
* Reducers must be pure functions, meaning they must not modify the store's state but instead have to replace it with a new one when a change occurs.
* For single-page applications, the gathering of analytics data on the interaction between the users and the page is more challenging (https://developers.google.com/analytics/devguides/collection/gtagjs/single-page-applications) than for traditional web applications where the entire page is loaded.
* When it comes to the tools used for the management and bundling of JavaScript projects, the community has been very fickle.
  - 2011 Bower, https://www.npmjs.com/package/bower
  - 2012 Grunt, https://www.npmjs.com/package/grunt
  - 2013-2014 Gulp, https://www.npmjs.com/package/gulp
  - 2012-2014 Browserify, https://www.npmjs.com/package/browserify
  - 2015- Webpack, https://www.npmjs.com/package/webpack
  - Parcel, https://parceljs.org/
  - esbuild, https://esbuild.github.io/
* The site https://reactpatterns.com/ provides a concise list of best practices for React, some of which are already familiar from this course. Another similar list is react bits (https://vasanthk.gitbooks.io/react-bits/).
* Reactiflux (https://www.reactiflux.com/) is a big chat community of React developers on Discord. It could be one possible place to get support after the course has concluded. For example, numerous libraries have their own channels.
* One good piece of advice for both refactoring and writing new code is to take baby steps. Losing your sanity is almost guaranteed if you leave the application in a completely broken state for long periods while refactoring.
* Better solutions for the React blog app:
  App.jsx
    import { useNotification, useInitialization, useClearUser } from './hooks/index'
    import { SmallButton, Page, Navigation } from './components/styled'
    const App = () => {
      const blogFormRef = useRef()
      const stateInitializer = useInitialization()
      const clearUser = useClearUser()
      useEffect(() => {
        stateInitializer()
      }, [])
      / ...
      return (
        <Page>
          // ...
          <Togglable buttonLabel="new blog" ref={blogFormRef}>
            <NewBlog hideMe={() => blogFormRef.current.toggleVisibility()} />
          </Togglable>
        </Page>
      )
  hooks/index.js
    import { useState } from 'react'
    import { useDispatch } from 'react-redux'
    import { notify } from '../reducers/notification'
    import { initializeBlogs } from '../reducers/blogs'
    import { initializeUsers } from '../reducers/users'
    import { initUser, clearUser } from '../reducers/user'

    export const useNotification = () => {
      const dispatch = useDispatch()
      return (message, type = 'info')  => {
        dispatch(notify(message, type))
      }
    }

    export const useInitialization = () => {
      const dispatch = useDispatch()
      return ()  => {
        dispatch(initializeBlogs())
        dispatch(initializeUsers())
        dispatch(initUser())
      }
    }

    export const useClearUser = () => {
      const dispatch = useDispatch()
      return ()  => {
        dispatch(clearUser())
      }
    }

    export const useField = (type) => {
      const [value, setValue] = useState('')
      const onChange = (event) => {
        setValue(event.target.value)
      }
      return {
        type,
        value,
        onChange
      }
    }
  services/user.js
    let token = null
    const STORAGE_KEY = 'loggedBlogAppUser'
    const setUser = (user) => {
      window.localStorage.setItem(STORAGE_KEY, JSON.stringify(user))
      token = user.token
    }
    const getUser = () => {
      const loggedUserJSON = window.localStorage.getItem(STORAGE_KEY)
      if (loggedUserJSON) {
        const user = JSON.parse(loggedUserJSON)
        token = user.token
        return user
      }
      return null
    }
    const clearUser = () => {
      localStorage.clear()
      token = null
    }
    const getToken = () => token
    export default {
      setUser,
      getUser,
      clearUser,
      getToken,
    }
  services/storage.js
    const KEY = 'bloggappUser'
    const saveUser = (user) => {
      localStorage.setItem(KEY, JSON.stringify(user))
    }
    const loadUser = () => {
      return JSON.parse(window.localStorage.getItem(KEY))
    }
    const removeUser = () => {
      localStorage.removeItem(KEY)
    }
    export default {
      saveUser,
      loadUser,
      removeUser,
    }
  services/blogs.js
    const headers = {
      Authorization: storageService.loadUser()
        ? `Bearer ${storageService.loadUser().token}`
        : null,
    }
    const comment = async (id, comment) => {
      const request = await axios.post(`${baseUrl}/${id}/comments`, { comment }, { headers })
      return request.data
    }
  reducers/notification.js
    export const notify = (message, type='success') => {
      // ...
    }
  reducers/blogs.js
    set(state, { payload }) {
      return payload
    },
  components/index.js
    import styled from 'styled-components'
    export const Info = styled.div`
      color: ${(props) => (props.alert ? 'red' : 'green')};
      background: white;
      font-size: 20px;
      border-style: solid;
      border-radius: 5px;
      padding: 10px;
      margin-bottom: 10px;
      margin-top: 10px;
    `
  components/User.js
    const user = useSelector(({ users }) => users.find(u => u.id === id) )
  models/blog.js
    comments: [ String ],
  controllers/blogs.js
    router.post('/:id/comments', async (request, response) => {
      const { comment } = request.body
      const blog = await Blog.findById(request.params.id)
      blog.comments = blog.comments.concat(comment)
      await blog.save()
      response.json(blog) // status code 200
    })


Part 12: Containers
-------------------
* Containers encapsulate your application into a single package. This package will then include all of the dependencies with the application. As a result, each container can run isolated from the other containers.
* Containers prevent the application inside from accessing files and resources of the device. Developers can give the contained applications permission to access files and specify available resources. More accurately, containers are OS-level virtualization. 
* VMs are used to run multiple operating systems on a single physical machine. They have to run the whole operating system, whereas a container runs the software using the host operating system.
* There is hardly any overhead when running containers; they only need to run a single process.
* As containers are relatively lightweight, at least compared to virtual machines, they can be quick to scale. And as they isolate the software running inside, it enables the software to run identically almost anywhere. As such, they are the go-to option in any cloud environment or application with more than a handful of users.
* Cloud services like AWS, Google Cloud, and Microsoft Azure all support containers in multiple different forms.
  - Serverless options: AWS Fargate, Google Cloud Run
* You can install container runtime on most machines and run containers there yourself - including your own machine.
* Benefits of containers:
  - You can run applications in their respective containers, isolated from each other.
  - You can run applications in the same execution environment both on your machine and on the server.
* Sometimes you may hear about the "Works in my container" issue. The phrase describes a situation in which the application works fine in a container running on your machine but breaks when the container is started on a server.
* As we are dealing with OS-level virtualization, the tools will require superuser access on the computer.
* Docker (https://www.docker.com/) is a set of products that we will use for containerization and the management of containers.
* Get Docker: https://docs.docker.com/get-docker/
* Image: includes all of the code, dependencies and instructions on how to run the application.
* Container: a runtime instance of an image. Containers package software into standardized units.
* Containers only exist during runtime. 
* Images are immutable files. As a result of the immutability, you can not edit an image after you have created one.
* Docker is the most popular containerization technology and pioneered the standards most containerization technologies use today.
* Docker engine will take care of turning the immutable files called images into containers.
* For managing the Docker containers, there is also a tool called Docker Compose that allows one to orchestrate (control) multiple containers at the same time.
* Docker container run command can run a container even if the image to run is not downloaded on our device yet.
* Docker Hub is a free registry for Docker images: https://hub.docker.com/
  - hello-world: https://hub.docker.com/_/hello-world
  - node: https://hub.docker.com/_/node
  - mongo:  https://hub.docker.com/_/mongo
  - redis: https://hub.docker.com/_/redis
  - nginx: https://hub.docker.com/_/nginx
* Image names consist of multiple parts, kind of like an URL. An image name is in the following format:
  registry/organisation/image:tag (with "hello-world", the 3 missing fields defaulted to index.docker.io/library/hello-world:latest)
* In the Docker Hub url, the "library" organization is shortened to _.
* Each image has a unique digest based on the layers from which the image is built. In practice, each step or command that was used in building the image creates a unique layer.
* Docker daemon is a background service that makes sure the containers are running, and we use the Docker client to interact with the daemon.
* Start recording terminal commands:
  script [options] [file]
  script exercise12_1.txt     # text output file
  script -r exercise12_1.txt  # binary output file
* Stop recording terminal commands:
  exit
* Replay recorded terminal commands:
  cat exercise12_1.txt        # text input file
  script -p exercise12_1.txt  # binary input file
* We have two options when addressing a container. The identifier in the first column can be used to interact with the container almost always. Plus, most commands accept the container name as a more human-friendly method of working with them. The name of the container was automatically generated to be "hopeful_clarke" in my case.
* Install "nano" on Ubuntu:
  apt-get update
  apt-get -y install nano
* Install "curl" on Ubuntu:
  apt-get update
  apt-get -y install curl
* Install "nodejs" on Ubuntu:
  curl -sL https://deb.nodesource.com/setup_16.x | bash
  apt install -y nodejs
* With Node.js installed, you can execute JavaScript in the container!
* Dockerfile is a simple text file that contains all of the instructions for creating an image.
* The best location to place a Dockerfile file is usually at the root of the project.
* Example Dockerfile:
  FROM node:16
  WORKDIR /usr/src/app
  COPY ./index.js ./index.js
  CMD node index.js
* FROM instruction will tell Docker that the base for the image should be node:16.
* WORKDIR instruction will ensure we don't interfere with the contents of the image. It will guarantee all of the following commands will have /usr/src/app set as the working directory. If the directory doesn't exist in the base image, it will be automatically created.
* COPY instruction will copy the file index.js from the host machine to the file with the same name in the image.
* CMD instruction tells what happens when docker run is used. CMD is the default command that can then be overwritten with the parameter given after the image name.
* You can point to any Dockerfile, but in our case, a simple dot will mean the Dockerfile in this directory. That is why the command ends with a period.
* As images are just files, they can be moved around, downloaded and deleted.
* Override the default command, defined by the CMD in the Dockerfile, if needed. For example, open a bash session to the container:
  docker run -it fs-hello-world bash
* Create a basic Express application skeleton:
  npx express-generator  # deprecated
* The -p flag will inform Docker that a port from the host machine should be opened and directed to a port in the container. The format for is -p host-port:application-port.
* When we ran npm install on our machine, in some cases the Node package manager may install operating system specific dependencies during the install step. We may accidentally move non-functional parts to the image with the COPY instruction. This can easily happen if we copy the node_modules directory into the image.
* It's best to do most things, such as to run npm install during the build process inside the container rather than doing those prior to building.
  - Only copy files that you would push to GitHub. Build artefacts or dependencies should not be copied since those can be installed during the build process.
* The file .dockerignore is very similar to .gitignore, you can use that to prevent unwanted files from being copied to your image. The file should be placed next to the Dockerfile. Here is a possible content of a .dockerignore:
  .dockerignore
  .gitignore
  node_modules
  Dockerfile
* The npm install can be risky. Instead of using npm install, npm offers a much better tool for installing dependencies, the ci command.
* Differences between ci and install:
  - install may update the package-lock.json
  - install may install a different version of a dependency if you have ^ or ~ in the version of the dependency.
  - ci will delete the node_modules folder before installing anything
  - ci will follow the package-lock.json and does not alter any files!!!
* So in short: ci creates reliable builds based on package-lock.json, while install is the one to use when you want to install new dependencies (uses package.json).
* Even better, we can use npm ci --only=production to not waste time installing development dependencies.
* Chain two bash commands with &&.
  - When chaining commands with && if one command fails, the next ones in the chain will not be executed.
  - Example: docker build -t express-server . && docker run -p 3123:3000 express-server
* Dockerfile best practices. There are 2 rules of thumb you should follow when creating images:
  - Try to create as secure of an image as possible
  - Try to create as small of an image as possible
* Snyk has a great list of 10 best practices for Node/Express containerization: https://snyk.io/blog/10-best-practices-to-containerize-nodejs-web-applications-with-docker/
  1. Use explicit and deterministic Docker base image tags
  2. Install only production dependencies in the Node.js Docker image
  3. Optimize Node.js tooling for production
  4. Don’t run containers as root
  5. Safely terminate Node.js Docker web applications
  6. Graceful shutdown for your Node.js web applications
  7. Find and fix security vulnerabilities in your Node.js docker image
  8. Use multi-stage builds
  9. Keeping unnecessary files out of your Node.js Docker images
  10. Mounting secrets into the Docker build image
* Tip: Run an application outside of a container to examine it before starting to containerize.
* Create docker image and run the container:
  docker build -t todo-app && docker container run -p 3000:3000 --name todo-app todo-app
* Docker compose (https://docs.docker.com/compose/) is another fantastic tool, which can help us to manage containers.
  - docker-compose.yml
  - Uses the YAML syntax
  - Documentation: https://docs.docker.com/compose/compose-file/compose-file-v3/
* Note that some older Docker versions (especially in Windows ) do not support the command docker compose. One way to circumvent this problem is to install the stand alone command docker-compose that works mostly similarly to docker compose. However, the preferable fix is to update the Docker to a more recent version.
* Creating files like docker-compose.yml that declare what you want instead of script files that you need to run in a specific order / a specific number of times is often a great practice.
* Docker Hub is the default place where Docker pulls the images from, you can use other registries as well, but since we are already knee-deep in Docker it's a good choice.
* You can use -f flag to specify a file to run the Docker Compose command with. For example:
  docker compose -f docker-compose.dev.yml up
* View the output logs with docker compose -f docker-compose.dev.yml logs -f. There the -f will ensure we follow the logs.
* mongo-init.js file is used to initialize the database.
* We could create a new image FROM mongo and COPY the file inside, or we can use a bind mount to mount the file mongo-init.js to the container.
* Bind mount is the act of binding a file (or directory) on the host machine to a file (or directory) in the container.
* A bind mount is done by adding a -v flag with container run. The syntax is -v FILE-IN-HOST:FILE-IN-CONTAINER.
* The result of the bind mount is that the file mongo-init.js in the mongo folder of the host machine is the same as the mongo-init.js file in the container's /docker-entrypoint-initdb.d directory. Changes to either file will be available in the other. We don't need to make any changes during runtime.
* Be careful when using chmod since granting more privileges can be a security issue. Use the chmod only on the mongo-init.js on your computer.
* By default, containers are not going to preserve our data. When you close the Mongo container you may or may not be able to get the data back.
* There are two distinct methods to store the data:
  - Declaring a location in your filesystem (called bind mount, https://docs.docker.com/storage/bind-mounts/), recommended to avoid deleting data
  - Letting Docker decide where to store the data (volume, https://docs.docker.com/storage/volumes/)
* The below will create a directory called mongo_data to your local filesystem and map it into the container as /data/db. This means the data in /data/db is stored outside of the container but still accessible by the container! Just remember to add the directory to .gitignore.
  services:
    mongo:
      volumes:
        - ./mongo_data:/data/db
* A similar outcome can be achieved with a named volume:
  services:
    mongo:
      volumes:
        - mongo_data:/data/db
  volumes:
    mongo_data:
* Now the volume is created but managed by Docker. After starting the application (docker compose -f docker-compose.dev.yml up) you can list the volumes with docker volume ls, inspect one of them with docker volume inspect and even delete them with docker volume rm.
* The named volume is still stored in your local filesystem but figuring out where may not be as trivial as with the previous option (see docker volume inspect <VOLUME_NAME> > Mountpoint).
* Volumes in a nutshell:
  - two-way binding
  - use explicit path on the host machine
* When you write a long docker-compose.yml or Dockerfile and it does not work, you need to take a moment and think about the various ways you could confirm something is working.
* Question Everything is still applicable here. The key is to be systematic. Since the problem can exist anywhere, you must question everything, and eliminate all possible sources of error one by one.
* The Docker command exec (https://docs.docker.com/engine/reference/commandline/exec/) is a heavy hitter. It can be used to jump right into a container when it's running.
* Nginx (https://www.nginx.com/) is, among other things, a server capable of serving static HTML files. 
* When doing development, it is essential to constantly follow the container logs.
* Remember that all of the changes are lost when the container is deleted.
* Access the MongoDB database with Mongo CLI:
  mongosh -u root -p example
  show dbs
  use the_database
  show collections
  db.todos.find({})
  db.todos.insertOne({ text: 'Increase the number of tools in my toolbelt', done: false });
* Exit the MongoDB database:
  exit
* Redis (https://redis.io/) is a key-value (https://redis.com/nosql/key-value-databases/) database. In contrast to eg. MongoDB, the data stored to a key-value storage has a bit less structure, there are eg. no collections or tables, it just contains junks of data that can be fetched based on the key that was attached to the data (the value).
* By default Redis works in-memory, which means that it does not store data persistently.
* An excellent use case for Redis is to use it as a cache. Caches are often used to store data that is otherwise slow to fetch and save the data until it's no longer valid. After the cache becomes invalid, you would then fetch the data again and store it in the cache.
* Redis is an open-source, networked, in-memory, key-value data store with optional durability. 
* Start the todo-app backend with Redis:
  REDIS_URL=redis://localhost:6379 MONGO_URL=mongodb://the_username:the_password@localhost:3456/the_database npm run dev
* Redis CLI: https://redis.io/topics/rediscli
* All Redis CLI commends: https://redis.io/commands/
* Redis CLI commands:
  - Get all keys: redis-cli KEYS "*"
  - Get the value of a key: redis-cli GET "added_todos"
  - Set key to hold the string value: redis-cli SET "added_todos" "9001"
  - Remove the specified key: redis-cli DEL "added_todos"
* Exit Redis CLI:
  exit
* By default Redis does not persist the data (works with stopped containers, though). You can configure Redis to persist the data even if the container is deleted.
* In addition to the GET, SET and DEL operations on keys and values, Redis can do also a quite a lot more. It can for example automatically expire keys, that is a very useful feature when Redis is used as a cache.
* Redis can also be used to implement so called publish-subscribe (or PubSub) pattern that is a asynchronous communication mechanism for distributed software. In this scenario Redis works as a message broker between two or more services. Some of the services are publishing messages by sending those to Redis, that on arrival of a message, informs the parties that have subscribed to those messages.
* Express server for static files: https://expressjs.com/en/starter/static-files.html
* Typical location of application files (WORKDIR) in a container: /usr/src/app
* A valid option for serving static files now that we already have Node in the container is serve: https://www.npmjs.com/package/serve
* Install serve:
  npm install -g serve
* Use serve (serves static files from the "build" directory):
  serve build
* Test all run commands to be included in the Dockerfile within the container using bash.
* CMD documentation: https://docs.docker.com/engine/reference/builder/#cmd
* There are three different forms for the CMD out of which the exec form (includes square brackets) is preferred.
  CMD ["serve", "build"]
* A good goal is to create Docker images so that they do not contain anything irrelevant. With a minimal number of dependencies, images are less likely to break or become vulnerable over time.
* Multi-stage builds (https://docs.docker.com/develop/develop-images/multistage-build/) are designed for splitting the build process into many separate stages, where it is possible to limit what parts of the image files are moved between the stages.
  - Opens possibilities for limiting the size of the image since not all by-products of the build are necessary for the resulting image. Smaller images are faster to upload and download and they help reduce the number of vulnerabilities your software may have.
  - With multi-stage builds, a tried and true solution like Nginx can be used to serve static files without a lot of headaches. The Docker Hub page for Nginx (https://hub.docker.com/_/nginx) tells us the required info to open the ports and "Hosting some simple static content".
  - We have declared also another stage where only the relevant files of the first stage (the build directory, that contains the static content) are moved.
* The default port for Nginx is 80.
* Multi-stage builds also include some internal optimizations that may affect your builds. As an example, multi-stage builds skip stages that are not used. If we wish to use a stage to replace a part of a build pipeline, like testing or notifications, we must pass some data to the following stages. In some cases this is justified: copy the code from the testing stage to the build stage. This ensures that you are building the tested code.
* Setting Dynamic Environment Values: Dockerfile doesn’t provide a dynamic tool to set an ENV value during the build process. However, there’s a solution to this problem. We have to use ARG. ARG values don’t work in the same way as ENV, as we can’t access them anymore once the image is built.
  ARG name
  ENV env_name $name
* Usage:
  docker build -t baeldung_greetings --build-arg name=Baeldung .
* What if we want to change the name? All we have to do is rebuild the image with a different build-arg value.
* One interesting possibility to utilize multi-stage builds is to use a separate build stage for testing: https://docs.docker.com/language/nodejs/run-tests/
  - If the testing stage fails, the whole build process will also fail. Note that it may not be the best idea to move all testing to be done during the building of an image, but there may be some containerization-related tests where it might be worth considering.
* Run the tests with CI=true npm test. Without the env CI=true set, the create-react-app will start watching for changes and your pipeline will get stuck.
* Start Todo app frontend without Docker:
  REACT_APP_BACKEND_URL=http://localhost:3000 PORT=3001 npm run start
* Move the whole todo application development to a container, which has the following benefits among others:
  - To keep the environment similar between development and production to avoid bugs that appear only in the production environment
  - To avoid differences between developers and their personal environments that lead to difficulties in application development
  - To help new team members hop in by having them install container runtime - and requiring nothing else.
* We will need to do at least two things to move the application to a container:
  - Start the application in development mode
  - Access the files with VS Code
* Steps to access the files with VSCode (two options):
  1. The Visual Studio Code Remote - Containers extension: https://code.visualstudio.com/docs/remote/containers
  2. Volumes, the same thing we used to preserve data with the database (work with all editors, not just VS Code)
* Hot reload might work in your computer, but it is currently known to have some issues (https://github.com/facebook/create-react-app/issues/11879). So if it does not work for you, just continue without the hot reload support, and reload the browser when you change the frontend code. You may also use use The Visual Studio Code Containers extension (https://code.visualstudio.com/docs/remote/containers).
* !!! Installing new dependencies is a headache for a development setup like this. One of the better options is to install the new dependency inside the container. So instead of doing e.g. npm install axios, you have to do it in the running container e.g. docker exec hello-front-dev npm install axios, or add it to the package.json and run docker build again.
* The Docker Compose tool sets up a network between the containers and includes a DNS to easily connect two containers.
* Busybox (https://www.busybox.net/) is a small executable with multiple tools you may need. It is called "The Swiss Army Knife of Embedded Linux"
* Busybox can help us to debug our configurations. So if you get lost in the later exercises of this section, you should use Busybox to find out what works and what doesn't.
* Busybox can be added to the mix by changing docker-compose.yml to:
  services:
    debug-helper:
      image: busybox
* The Busybox container won't have any process running inside so we can not exec in there.
* Use wget (included in busybox) to make requests: https://en.wikipedia.org/wiki/Wget
  - Send requests from the debug-helper to hello-front-dev.
* With Docker Compose we can use docker compose run SERVICE COMMAND to run a service with a specific command. Command wget requires the flag -O with - to output the response to the stdout:
  docker compose run debug-helper wget -O - http://app:3000
* The app is the name of the service specified in the docker-compose.yml and the port used is the port from which the application is available in that container, also specified in the docker-compose.yml.
* The port does not need to be published for other services in the same network to be able to connect to it. The "ports" in the docker-compose file are only for external access.
* With docker compose up the application is available in http://localhost:3001 at the host machine, but still docker compose run debug-helper wget -O - http://app:3000 works since the port is still 3000 within the docker network.
* Docker compose run asks debug-helper to send the request within the network. While the browser in host machine sends the request from outside of the network.
* Build Docker images and run containers for the todo app (frontend: localhost:3001 and backend: localhost:3000):
  todo-frontend/docker compose -f docker-compose.dev.yml up --build
  todo-backend/docker compose -f docker-compose.dev.yml up --build
* A reverse proxy (https://en.wikipedia.org/wiki/Reverse_proxy) is a type of proxy server that retrieves resources on behalf of a client from one or more servers. 
* So in our case, the reverse proxy will be the single point of entry to our application, and the final goal will be to set both the React frontend and the Express backend behind the reverse proxy.
* There are multiple different options for a reverse proxy implementation, such as Traefik, Caddy, Nginx, and Apache (ordered by initial release from newer to older).
* With containers localhost is unique for each container, leading to the container itself.
* Docker Compose set up a network when we ran docker compose up. It also added all of the containers in the docker-compose.yml to the network. A DNS makes sure we can find the other container. The containers are each given two names: the service name and the container name. Since we are inside the container, we can also test the DNS!
* One more thing: we added an option depends_on to the configuration that ensures that the nginx container is not started before the frontend container app is started:
  depends_on:
    - app  
* If we do not enforce the starting order with depends_on there a risk that Nginx fails on startup since it tries to resolve all DNS names that are referred in the config file:
* Note that depends_on does not guarantee that the service in the depended container is ready for action, it just ensures that the container has been started (and the corresponding entry is added to DNS). If a service needs to wait another service to become ready before the startup, other solutions (https://docs.docker.com/compose/startup-order/) should be used.
* The proxy_pass directive has an interesting feature with a trailing slash. As we are using the path /api for location but the backend application only answers in paths / or /todos we will want the /api to be removed from the request. In other words, even though the browser will send a GET request to /api/todos/1 we want the Nginx to proxy the request to /todos/1. Do this by adding a trailing slash / to the URL at the end of proxy_pass.
  location /api/ {
    ...
  }
* More information about this common issue: https://serverfault.com/questions/562756/how-to-remove-the-path-with-an-nginx-proxy-pass
* We just need to expose the Nginx port to the host machine since the access to the backend and frontend is proxied to the right container port by Nginx. Because Nginx, frontend and backend are defined in the same Docker compose configuration, Docker puts those to the same Docker network and thanks to that, Nginx has direct access to frontend and backend containers ports.
* You can override default environment variables defined in Dockerfile in docker-compose.yml using the environment declaration.
* See todo-app/docker-compose.dev.yml and nginx.conf for working development environment setup! Pay special attention to trailing slashes and environment variables!!!!
* There are many more powerful tools than Docker Compose to run containers in production.
* Heavyweight container orchestration tools like Kubernetes allow us to manage containers on a completely new level. These tools hide away the physical machines and allow us, the developers, to worry less about the infrastructure.
* DevOps with Docker course: https://devopswithdocker.com/
* DevOps with Kubernetes course: https://devopswithkubernetes.com/
* ENV is for future running containers. ARG for building your Docker image.
* ENV is mainly meant to provide default values for your future environment variables. Running dockerized applications can access environment variables. It’s a great way to pass configuration values to your project.
* ARG values are not available after the image is built. A running container won’t have access to an ARG variable value.
* npm ci installs the same versions defined in the lock file and doesn't try to update them as npm install does.
* The --only=production flag that skips the installation of devDependencies, which we don't need in production.
* Remember to include .dockerignore to avoid copying unwanted files, especially node_modules!!!!
  .git
  .dockerignore
  .gitignore
  node_modules
  Dockerfile
  dev.Dockerfile
* If you map the full frontend or backend to the container in docker-compose.yml, remember to "exclude" node_modules from the mapping as their installations differ from one environment (your computer, macOS) to another (container, Linux):
  volumes:
    - ./backend/:/usr/src/app
    - /usr/src/app/node_modules
* Create multiple databases with mongo-init.js:
  blogApp = db.getSiblingDB('blogApp')
  blogApp.createUser({
    user: 'the_username',
    pwd: 'the_password',
    roles: [
      {
        role: 'dbOwner',
        db: 'blogApp'
      }
    ]
  })
  blogApp.createCollection('blogs')
  blogApp.createCollection('users')
  // Test database
  testBlogApp = db.getSiblingDB('testBlogApp')
  // ...
* !!! When serving React frontend app using React Router, you need to configure Nginx to redirect all requests to index.html as the client-side routing does the job:
  Dockerfile (frontend)
  COPY --from=build-stage /usr/src/app/nginx.conf /etc/nginx/conf.d/default.conf
* For more information, see:
  - https://www.barrydobson.com/post/react-router-nginx/
  - https://stackoverflow.com/questions/43951720/react-router-and-nginx
  - https://www.frontendundefined.com/posts/tutorials/nginx-react-router-404/
* Dockerfile reference: https://docs.docker.com/engine/reference/builder/
  - ADD: Add local or remote files and directories.
  - ARG: Use build-time variables.
  - CMD: Specify default commands.
  - COPY: Copy files and directories.
  - ENTRYPOINT: Specify default executable.
  - ENV: Set environment variables.
  - EXPOSE: Describe which ports your application is listening on.
  - FROM: Create a new build stage from a base image.
  - HEALTHCHECK: Check a container's health on startup.
  - LABEL: Add metadata to an image.
  - MAINTAINER: Specify the author of an image.
  - ONBUILD: Specify instructions for when the image is used in a build.
  - RUN: Execute build commands.
  - SHELL: Set the default shell of an image.
  - STOPSIGNAL: Specify the system call signal for exiting a container.
  - USER: Set user and group ID.
  - VOLUME: Create volume mounts.
  - WORKDIR: Change working directory.
* Dockerfile ADD vs. COPY: https://www.baeldung.com/ops/docker-copy-add
  - The ADD directive is more capable than COPY. While functionally similar, the ADD directive is more powerful in two ways:
    - It can handle remote URLs
    - It can auto-extract tar files
  - Prefer COPY over ADD unless we specifically need one of the two additional features of ADD.
* Dockerfile ARG vs. ENV: 
  - ARG values are not available after the image is built. A running container won’t have access to an ARG variable value.
* Dockerfile ENTRYPOINT vs. CMD: https://spacelift.io/blog/docker-entrypoint-vs-cmd
  - ENTRYPOINT sets the process to run, while CMD supplies default arguments to that process.
  - The ENTRYPOINT Dockerfile instruction sets the process that’s executed when your container starts.
  - When an image is created without an ENTRYPOINT, Docker defaults to using /bin/sh -c.
  - The somewhat misleadingly named CMD instruction sets the default arguments that are passed to the ENTRYPOINT process. It determines the final form of the command string that will be executed. In the following example, the container will run /usr/bin/my-app help:
    ENTRYPOINT ["/usr/bin/my-app"]
    CMD ["help"]
  - In the ubuntu Dockerfile, a default CMD is specified as: CMD ["bash"]
* Docker Compose file reference: https://docs.docker.com/compose/compose-file/
* Docker commands:
  - List images:
    docker image ls
  - List containers:
    docker container ls
  - List all containers (incl. stopped):
    docker container ls -a
  - Create and run a new container from an image:
    docker container run <IMAGE_NAME>
  - Create and run a new container from an image in interactive mode:
    docker container run -it <IMAGE_NAME> <COMMAND_TO_EXECUTE>
    docker container run -it <IMAGE_NAME> bash
  - Create and run a new container with a name from an image in interactive mode:
    docker container run -it --name <CONTAINER_NAME> <IMAGE_NAME>:<IMAGE_VERSION> <COMMAND_TO_EXECUTE>
  - Create and run a new container with a published port from an image:
    docker container run -p <HOST_PORT>:<CONTAINER_PORT> <IMAGE_NAME>
  - Create and run a new container with a published port and a bind mount volume from an image:
    docker container run -p <HOST_PORT>:<CONTAINER_PORT> -v <LOCAL_SOURCE_FILE_PATH>:<CONTAINER_TARGET_FILE_PATH> <IMAGE_NAME>
  - Start one or more stopped containers:
    docker container start <CONTAINER_ID_OR_CONTAINER_NAME>
  - Start one or more stopped containers in interactive mode:
    docker container start -i <CONTAINER_ID_OR_CONTAINER_NAME>
  - Kill one or more running containers (terminate ommediately):
    docker container kill <CONTAINER_ID_OR_CONTAINER_NAME>
  - Stop one or more running containers (terminate gracefully):
    docker container stop <CONTAINER_ID_OR_CONTAINER_NAME>
  - Remove one or more containers:
    docker container rm <CONTAINER_ID_OR_CONTAINER_NAME>
  - Create a new image from a container's changes:
    docker commit <CONTAINER_ID_OR_CONTAINER_NAME> <IMAGE_NAME>
  - Copy files/folders between a container and the local filesystem:
    docker container cp <LOCAL_SOURCE_FILE_PATH> <CONTAINER_ID_OR_CONTAINER_NAME>:<CONTAINER_TARGET_FILE_PATH>
  - Build an image with a name from a Dockerfile:
    docker build -t <IMAGE_NAME_WITH_OR_WITHOUT_TAG> <DOCKERFILE_FILE_PATH>
    docker build -t fs-hello-world .
  - Remove one or more images:
    docker image rm <IMAGE_NAME>
  - List volumes:
    docker volume ls
  - Display detailed information on one or more volumes:
    docker volume inspect <VOLUME_NAME>
  - Remove one or more volumes:
    docker volume rm <VOLUME_NAME>
  - Execute a command in a running container:
    docker exec -it <CONTAINER_ID_OR_CONTAINER_NAME> <COMMAND_TO_EXECUTE>
    docker exec -it wonderful_ramanujan bash
* Docker Compose commands:
  - Create and start containers by building images before starting containers:
    docker compose up --build
  - Create and start containers by running them in the background (detach):
    docker compose up -d
  - Create and start containers using a specific configuration file (defaults to docker-compose.yml):
    docker compose -f docker-compose.dev.yml up
  - Stop and remove containers, networks:
    docker compose down
  - View output from containers (and follow log output):
    docker compose logs -f
* docker-compose.yml commands:
  - version
  - services
    - "service"
      - image
      - restart
      - build
        - context
        - dockerfile
      - volumes
      - ports
      - environment
      - container_name
      - depends_on
